[
  {
    "path": "mlr_gallery/mlr-01-draft/",
    "title": "Python machine learning tour (1/5): From binary to multi-class classification",
    "description": "This is part 1 of a 5-part tour of machine learning in Python. \nIn this part I provide a high-level overview of optimization\nmethods for machine learning, and in particular, for training models. \nMost importantly, we see the motivation for gradient descent and provide \nsome justification for this hugely popular approach, which is the \nfoundation of many many other model training methods.\nAs much as possible, I rely on a \"from scratch\" approach, avoiding high-level\nlibraries like scikit-learn.",
    "author": [
      {
        "name": "Matthew Bain",
        "url": {}
      }
    ],
    "date": "2024-03-18",
    "categories": [
      "Classification"
    ],
    "contents": "\n\nContents\n1 Predicting breast cancer\n1.1 Softmax & perceptron costs\n1.2 Minimizing cost functions\n1.3 Misclassifications\n1.4 Plotting: cost and misclassifications\n1.5 Logistic regression & cross-entropy\n\n2 Spam detection\n2.1 Some basic preprocessing\n2.2 Email classification with perceptron\n2.3 Accuracy\n2.4 Confusion matrix\n\n3 Credit check\n3.1 Standard normalization\n3.2 Fitting perceptron-based classifier\n3.3 Confusion matrix\n\n4 Three-class classification\n4.1 Fitting multi-class perceptron\n4.2 Plotting the decision boundary\n\n\n\n### load dependencies\n# essentials\nimport numpy.linalg as LA           # linalg module of numpy\nimport pandas as pd                 # pandas for data manipulation\nimport autograd.numpy as np         # autograd-wrapped numpy\n\n# optimization\nfrom autograd import grad           # module for computing gradient\nfrom autograd import value_and_grad # returns grad & val of input function\n\n# plotting\nimport matplotlib.pyplot as plt     # pyplot module of matplotlib\n\n# global plotting parameters\nplt_colours = (np.array([94,255,231])/360, np.array([133,94,214])/360,\n               np.array([110,250,152])/360)\nfont_size   = 14\nfont_name   = {'fontname': 'Avenir'}\n\n1 Predicting breast cancer\nIn this problem we examine the Breast Cancer Data\nSet,\nobtained from the University of Wisconsin Hospitals, Madison from Dr.\nWilliam H. Wolberg 1.\n1.1 Softmax & perceptron costs\nIn the following we implement the softmax and perceptron cost functions.\nnotes\nclass labels are coded as \\(1\\) for benign, \\(-1\\) for malignant.\nthe dataset is arranged in columns, each corresponding to an\nindividual & each row a cellular measurement.\nClass labels are stored in the final row.\nBelow we import the dataset.\n\n### setup dataset\nimport numpy as np\n\n# data input\ncsvname = 'data/breast_cancer_data.csv'\ndata = np.loadtxt(csvname, delimiter = ',')\n\n# get input and output of dataset\nx = data[:-1, :]   # feature vectors\ny = data[-1:, :]   # class labels {1,-1}\n\nWe now define our model and complete an implementation of the softmax\nand perceptron cost functions.\n\n### define model and cost functions\n# define model (compute linear combination of input points)\ndef model(x, w):\n    a = w[0] + np.dot(x.T, w[1:])\n    return a.T\n\n## cost functions (`g`)\n# softmax cost implementation\n# note: x,y req. by cost but def. globally s.t. for given w compute cost\n# across all x,y)\ndef softmax(w):\n    # note: equivalent to softnax aoprox to perceptron cost, below\n    cost = np.sum(np.log(1 + np.exp(-y*model(x, w))))\n    return cost/float(np.size(y))\n\n# perceptron cost implementation\ndef perceptron(w):\n    # sum of pair-wise maximum between 0, model values\n    cost = np.sum(np.maximum(0, -y*model(x, w)))\n    return cost/float(np.size(y))\n\n1.2 Minimizing cost functions\nWe will now optimize these cost functions using gradient descent.\nBelow we define the standard gradient descent algorithm.\n\n### GD function\ndef gradient_descent(g, alpha, max_its, w):\n  import autograd.numpy as np\n  from autograd import grad\n\n  # define alpha based on chosen cost function\n  # alpha = 1.0 if g == softmax else .1\n  if g == softmax: alpha = 1.0\n  elif g == perceptron: alpha = .1\n  elif g == cross_entropy: alpha = .6\n\n  # compute gradient (wrt w, holding constant x,y)\n  gradient = grad(g)\n\n  # run GD loop\n  weight_history = [w] # weight history container\n  cost_history = [g(w)] # cost function history container\n  for k in range(max_its):\n    \n    # evaluate the gradient\n    grad_eval = gradient(w)\n\n    # take gradient descent step\n    w = w - alpha*grad_eval\n\n    # record weight and cost\n    weight_history.append(w)\n    cost_history.append(g(w))\n    \n  return weight_history, cost_history\n\nBelow we define our parameters and then minimize both cost functions.\n\n### optimize cost functions\nimport autograd.numpy as np\n\n# define gradient descent (GD) parameters\nmax_its = 1000\nw = 0.1*np.random.randn(9, 1) # initial starting weights\n\n# call GD (choose arb alpha for now bc based on chosen g)\nweight_history_SM, cost_history_SM = gradient_descent(softmax, 1,\n                                                      max_its, w)\nweight_history_PT, cost_history_PT = gradient_descent(perceptron, 1,\n                                                      max_its, w)\n\n1.3 Misclassifications\nWe now compute the number of misclassifications for each iteration of\ngradient descent.\n\n### compute misclassification history\nimport autograd.numpy as np\n\n# compute misclassification history\ndef miscount(w, x, y):\n    # +1 or -1 whether above or below fitted decision bound determined by w\n    y_pred = np.sign(model(x, w))\n\n    # pairwise compare vectors: 1 if model class pred == true class; sum\n    miscount_curr = np.sum(y_pred != y)\n    return miscount_curr\n\n# compute miscount history for each cost function\nmiscount_history_SM = [miscount(v, x, y) for v in weight_history_SM]\nmiscount_history_PT = [miscount(v, x, y) for v in weight_history_PT]\n\n1.4 Plotting: cost and misclassifications\nBelow we plot the cost and misclassification history for each cost\nfunction.\n\n### define function for plotting cost and misclassification hist in same figure\ndef plot_cost_and_miscount(data):\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import seaborn as sns\n    import pandas as pd\n\n    # store data\n    x_plt           = data[\"x_plt\"]\n    y_miscount_SM   = data[\"y_miscount_SM\"]\n    y_cost_SM       = data[\"y_cost_SM\"]\n    y_miscount_PT   = data[\"y_miscount_PT\"]\n    y_cost_PT       = data[\"y_cost_PT\"]\n\n    # use seaborn style\n    sns.set_theme()\n\n    # to prevent warning messages from appearing in the report\n    import warnings;\n    warnings.filterwarnings('ignore')\n\n    # set inline figure format/quality, overall params\n    # %config InlineBackend.figure_format = 'svg'\n\n    # setup plot & subplots\n    fig, axs = plt.subplots(2, 1, figsize = np.array([6.5, 8]),\n                            constrained_layout = True) # overall layout, size\n    # axs[0] = plt.subplot(1,3,(1,2), frameon = 1)\n    axs[0] = plt.subplot(211, frameon = 1)\n    axs[1] = plt.subplot(212, frameon = 1)\n\n    # set axis tick sizes\n    axs[0].xaxis.set_tick_params(labelsize = font_size - 4)\n    axs[0].yaxis.set_tick_params(labelsize = font_size - 4)\n    axs[1].xaxis.set_tick_params(labelsize = font_size - 4)\n    axs[1].yaxis.set_tick_params(labelsize = font_size - 4)\n\n    # plot overlay of misclassifications & costs for each cost over it\n    line_miscount_SM    = axs[0].plot(x_plt, y_miscount_SM,\n                                      color = plt_colours[0],\n                                      linestyle = '-', linewidth = 2)\n    line_miscount_PT    = axs[0].plot(x_plt, y_miscount_PT,\n                                      color = plt_colours[1],\n                                      linestyle = '-', linewidth = 2)\n    line_cost_SM        = axs[1].plot(x_plt, y_cost_SM,\n                                      color = plt_colours[0],\n                                      linestyle = '-', linewidth = 2)\n    line_cost_PT        = axs[1].plot(x_plt, y_cost_PT,\n                                      color = plt_colours[1],\n                                      linestyle = '-', linewidth = 2)\n\n    # add labels\n    # axs[0].set_xlabel('iteration', fontsize = font_size, **font_name)\n    axs[0].set_xlabel('iteration', fontsize = font_size)\n    axs[0].set_ylabel('misclassifications', fontsize = font_size)\n    axs[1].set_xlabel('iteration', fontsize = font_size)\n    axs[1].set_ylabel('cost', fontsize = font_size)\n\n    # plot legend\n    leg_labels = ['softmax', 'perceptron']\n    axs[0].legend([line_miscount_SM, line_miscount_PT], labels = leg_labels,\n    loc = 'upper right', frameon = 1, fontsize = font_size - 4)\n    axs[1].legend([line_cost_SM, line_cost_PT], labels = leg_labels,\n                  loc = 'upper right', frameon = 1, fontsize = font_size - 4)\n\n    plt.show()\n\n\n### store data and plot\nimport pandas as pd\n\n# store plotting data in data frame\nplot_data = pd.DataFrame(\n    {\n        \"x_plt\": np.arange(np.size(miscount_history_SM)),\n        \"y_miscount_SM\": miscount_history_SM,\n        \"y_cost_SM\": cost_history_SM,\n        \"y_miscount_PT\": miscount_history_PT,\n        \"y_cost_PT\": cost_history_PT\n    })\n\n# plot\nplot_cost_and_miscount(plot_data)\n\nBelow we identify and return the minimum number of misclassifications\nfor each cost function over all iterations of gradient descent.\n\n### identify minima\nmin_misclass_SM = min(miscount_history_SM)\nmin_misclass_PT = min(miscount_history_PT)\n\nprint(\"softmax minimum misclassifications:    \" + str(min_misclass_SM))\nprint(\"perceptron minimum misclassifications: \" + str(min_misclass_PT))\n\nBelow we modify the miscount function to consider only misclassified\nmalignant cases (i.e., cases corresponding to the class label \\(-1\\)).\n\n#### define misclassification rate\nimport autograd.numpy as np\n\n# compute misclassification history\ndef miscount_neg(w, x, y):\n\n    # +1 or -1 whether above or below fitted decision bound determined by w\n    y_pred = np.sign(model(x, w))\n\n    # consider only malignant cases\n    miscount_curr = np.sum(y_pred[y == -1] != -1)\n    return miscount_curr\n\n# compute new miscount history for each cost function\nmiscount_history_SM_neg = [miscount_neg(v, x, y) for v in weight_history_SM]\nmiscount_history_PT_neg = [miscount_neg(v, x, y) for v in weight_history_PT]\n\nBelow we again plot misclassification and cost history side-by-side,\nthis time considering only misclassified malignant cases.\n\n### store data and plot\n# import pandas for data frame capabilities\nimport pandas as pd\n\n# store plotting data in data frame\nplot_data = pd.DataFrame(\n    {\n        \"x_plt\": np.arange(np.size(miscount_history_SM_neg)),\n        \"y_miscount_SM\": miscount_history_SM_neg,\n        \"y_cost_SM\": cost_history_SM,\n        \"y_miscount_PT\": miscount_history_PT_neg,\n        \"y_cost_PT\": cost_history_PT\n    })\n\n# plot\nplot_cost_and_miscount(plot_data)\n\n1.5 Logistic regression & cross-entropy\nIn the following we compare the above results to those obtained using\nlogistic regression with a cross entropy cost.\nThe code below (ref) converts our class labels y = \\(\\{-1, 1\\}\\) to\n\\(\\{0, 1\\}\\).\n\n### setup dataset\ny_1 = np.squeeze(y) # flatten y (one dimension)\n\ny_ben = np.argwhere(y_1 > 0.9) # returns all indices where y meets condition\ny_mal = np.argwhere(y_1 < -0.9)\n\nyc = np.arange(699) # class labels (`y`) for CE (cross-entropy) cost\nyc[y_ben] = 1\nyc[y_mal] = 0\n\nThe code below (ref) implements the cross entropy cost\nfunction, with L2 regularization.\n\n### define model and cross entropy cost\n# define sigmoid function\ndef sigmoid(t):\n    return 1/(1 + np.exp(-t))\n\n## the (convex) cross-entropy cost function\nlam = 2*10**(-3) # regularization parameter\ndef cross_entropy(w):\n    # compute sigmoid of model\n    sig_eval = sigmoid(model(x, w))\n\n    # compute cost of label 0 points\n    ind_mal = np.argwhere(yc == 0)\n    cost = -np.sum(np.log(1 - sig_eval[:, ind_mal]))\n\n    # add (subtract) cost on label 1 points\n    ind_ben = np.argwhere(yc == 1)\n    cost -= np.sum(np.log(sig_eval[:, ind_ben]))\n\n    # add regularizer (* regularization parameter)\n    cost += lam*np.sum(w[1:]**2)\n\n    # compute cross-entropy\n    return cost/float(np.size(yc))\n\nBelow we run gradient descent to optimize the cross entropy cost\nfunction for logistic regression.\n\n### optimize cost function using GD\nimport autograd.numpy as np\n\n# define gradient descent parameters\nmax_its = 1000\nw = 0.1*np.random.randn(9, 1) # initial starting weights\n\n# call GD (choose arb alpha for now bc based on chosen g)\nweight_history_CE, cost_history_CE = gradient_descent(cross_entropy, 1,\n                                                      max_its, w)\n\nWe now compute misclassification history. To do so we must modify\nmiscount to compute misclassifications in a manner appropriate to\nlogistic regression. Since the sigmoid function varies between 0 and 1\nand is symmetric (about a \\(180^{\\circ}\\) rotation centered at\n\\((0, 0.5)\\)), we can use \\(y = 0.5\\) to effectively separate our\npredictions into the two classes labelled \\(\\{0, 1\\}\\). Then, as before,\nwe can determine misclassiffications by comparing the predicted classes\nacross weight_history with the true class labels.\n\n### compute misclassification history\nimport autograd.numpy as np\n\n# compute misclassification history\ndef miscount_CE(w, x, y):\n    y_pred = np.sign(model(x, w))        # 1 or 1 if eval > .5\n\n    # convert predictions to classes based on y = .5 threshold  value\n    y_pred[y_pred >= .5]    = 1\n    y_pred[y_pred < .5]     = 0\n\n    # pairwise compare vectors: 1 if model class pred == true class; sum\n    miscount_curr = np.sum(y_pred != y)\n\n    return miscount_curr\n\n# compute new miscount history for cross entropy cost\nmiscount_history_CE = [miscount_CE(v, x, yc) for v in weight_history_CE]\n\nAnd finally, below we plot cost and misclassification history for the\nlogistic regression cross entropy cost, as we did above for the softmax\nand perceptron cost functions (alongside the results for the perceptron\ncost function). First we make a couple minor modifications to generalize\nour plotting function and allow us to plot cross entropy cost in\naddition to softmax cost.\n\n### define plotting function\ndef plot_cost_and_miscount(data):\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import seaborn as sns\n    import pandas as pd\n\n    # store data\n    x_plt           = data[\"x_plt\"]\n    # y_miscount_1    = data[\"y_miscount_CE\"]\n    # y_cost_1        = data[\"y_cost_CE\"]\n    # y_miscount_2    = data[\"y_miscount_PT\"]\n    # y_cost_2        = data[\"y_cost_PT\"]\n    y_miscount_1    = data.iloc[:, 1]\n    y_cost_1        = data.iloc[:, 2]\n    y_miscount_2    = data.iloc[:, 3]\n    y_cost_2        = data.iloc[:, 4]\n\n    # use seaborn style\n    sns.set_theme()\n\n    # to prevent warning messages from appearing in the report\n    import warnings;\n    warnings.filterwarnings('ignore')\n\n    # set inline figure format/quality, overall params\n    # %config InlineBackend.figure_format = 'svg'\n\n    # setup plot & subplots\n    fig, axs = plt.subplots(2, 1, figsize = np.array([6.5, 8]),\n                            constrained_layout = True) # overall layout, size\n    # axs[0] = plt.subplot(1,3,(1,2), frameon = 1)\n    axs[0] = plt.subplot(211, frameon = 1)\n    axs[1] = plt.subplot(212, frameon = 1)\n\n    # set axis tick sizes\n    axs[0].xaxis.set_tick_params(labelsize = font_size - 4)\n    axs[0].yaxis.set_tick_params(labelsize = font_size - 4)\n    axs[1].xaxis.set_tick_params(labelsize = font_size - 4)\n    axs[1].yaxis.set_tick_params(labelsize = font_size - 4)\n\n    # plot overlay of misclassifications & costs for each cost over all it\n    line_miscount_CE    = axs[0].plot(x_plt, y_miscount_1,\n                                      color = plt_colours[0],\n                                      linestyle = '-', linewidth = 2)\n    line_miscount_PT    = axs[0].plot(x_plt, y_miscount_2,\n                                      color = plt_colours[1],\n                                      linestyle = '-', linewidth = 2)\n    line_cost_CE        = axs[1].plot(x_plt, y_cost_1,\n                                      color = plt_colours[0],\n                                      linestyle = '-', linewidth = 2)\n    line_cost_PT        = axs[1].plot(x_plt, y_cost_2,\n                                      color = plt_colours[1],\n                                      linestyle = '-', linewidth = 2)\n\n    # add labels\n    # axs[0].set_xlabel('iteration', fontsize = font_size, **font_name)\n    axs[0].set_xlabel('iteration', fontsize = font_size)\n    axs[0].set_ylabel('misclassifications', fontsize = font_size)\n    axs[1].set_xlabel('iteration', fontsize = font_size)\n    axs[1].set_ylabel('cost', fontsize = font_size)\n\n    # plot legend\n    leg_labels = ['cross entropy', 'perceptron']\n    axs[0].legend([line_miscount_CE, line_miscount_PT], labels = leg_labels,\n                  loc = 'upper right', frameon = 1, fontsize = font_size - 4)\n    axs[1].legend([line_cost_CE, line_cost_PT], labels = leg_labels,\n                  loc = 'upper right', frameon = 1, fontsize = font_size - 4)\n\n    plt.show()\n\n\n### store data and plot\nimport pandas as pd\n\n# store plotting data in data frame\nplot_data = pd.DataFrame(\n    {\n        \"x_plt\": np.arange(np.size(miscount_history_CE)),\n        \"y_miscount_CE\": miscount_history_CE,\n        \"y_cost_CE\": cost_history_CE,\n        \"y_miscount_PT\": miscount_history_PT,\n        \"y_cost_PT\": cost_history_PT\n    })\n\n# plot\nplot_cost_and_miscount(plot_data)\n\n2 Spam detection\nIn this problem we examinine the Spambase Data\nSet 2, containing\nmeasurements of spam and non-spam emails. Using the two-class\nclassification methods we explored in the above sections, we build a\nclassifier to determine if an email is likely to be spam.\nnotes\nClass labels (1 for ‘spam’, -1 for ‘not spam’) are again stored in the\nfinal row (\\(N = 58\\)) of the dataset, with each other row \\(n\\)\nrepresenting a feature (word/character frequencies, etc.) and each\ncolumn \\(p\\) a sample (\\(P = 4601\\)).\nBelow we import the dataset.\n\n### import dataset\nimport numpy as np\n\n# data input\ncsvname = 'data/spambase_data.csv'\ndata = np.loadtxt(csvname, delimiter = ',')\n\n# get input and output of dataset\nx = data[:-1, :]    # feature vectors\ny = data[-1:, :]    # class labels {1,-1}\n\n2.1 Some basic preprocessing\nWe now perform some preproc`essing to prepare the dataset for our\nanalysis. We standard normalize each feature (s.t. \\(\\mu_n = 0\\) and\n\\(\\sigma_n = 1\\), where \\(\\mu\\) represents the mean and \\(\\sigma\\) the\nstandard deviation) so that they can be treated equally by our\nclassifier. To do so, for each observation \\(x_{n,p}\\) we subtract the\ncorresponding mean \\(\\mu_n\\) and divide by the corresponding standard\ndeviation \\(\\sigma_n\\).\nTo deal with missing observations for a given feature (represented as\nNaN), we replace NaN with the corresponding feature mean \\(\\mu_n\\).\nThe following function (ref) executes the above.\n\n### perform standard normalization and fill in missing data\ndef standard_normalizer(x):\n\n    # compute the mean and standard deviation of each feature\n    x_means = np.nanmean(x, axis = 1)[:, np.newaxis]\n    x_stds  = np.nanstd(x, axis = 1)[:, np.newaxis]\n\n    # check to make sure that x_stds > small threshold; for those not\n    # divide by 1 instead of original standard deviation\n    ind = np.argwhere(x_stds < 10**(-2))\n    if len(ind) > 0:\n        ind = [v[0] for v in ind] # just keep row index\n        adjust = np.zeros((x_stds.shape)) # array of indices to replace with 1\n        adjust[ind] = 1.0\n        x_stds += adjust\n\n    # fill in any nan values with corresponding feature mean\n    ind = np.argwhere(np.isnan(x) == True)\n    for i in ind:\n        x[i[0], i[1]] = x_means[i[0]]\n\n    # create standard normalizer function\n    normalizer = lambda data: (data - x_means)/x_stds\n\n    # create inverse standard normalizer\n    inverse_normalizer = lambda data: data*x_stds + x_means\n\n    # return (inverse) normalizer\n    return normalizer, inverse_normalizer\n\n## standard normalize dataset\nnormalizer, inverse_normalizer = standard_normalizer(x) # get std norm functions\nx = normalizer(x)\n\n2.2 Email classification with perceptron\nIn the following we classify emails using the softmax and perceptron\ncost functions.\nSteps:\nWe carry out the same sequence of steps covered in detail in part 1:\nIdentify optimal decision boundary (determined by weights \\(w\\)):\nrun gradient descent to identify \\(w\\) that minimizes cost\nfunctions\nsoftmax: \\(\\alpha = 1.0\\); perceptron: \\(\\alpha = 0.1\\)\nother parameters: max its = 1000;\nw = 0.1*np.random.randn(N + 1, 1), where \\(N = 57\\)\n\nCompute misclassification histories\nPlot cost and misclassification as a function of gradient descent\niteration\n\n### 1) optimize softmax and perceptron costs over `spambase` dataset\nimport autograd.numpy as np\n\n# define gradient descent parameters\nmax_its = 1000\nw = 0.1*np.random.randn(np.shape(x)[0] + 1, 1) # initial starting weights\n\n# call GD (choose arb alpha for now bc based on chosen g)\nweight_history_SM_spam, cost_history_SM_spam = gradient_descent(softmax, 1,\n                                                        max_its, w)\nweight_history_PT_spam, cost_history_PT_spam = gradient_descent(perceptron, 1,\n                                                        max_its, w)\n\n\n### 2) compute misclassification history for each cost function\nmiscount_history_SM_spam = [miscount(v, x, y) for v in weight_history_SM_spam]\nmiscount_history_PT_spam = [miscount(v, x, y) for v in weight_history_PT_spam]\n\n\n### 3) for each cost, plot cost and misclassification as a function of iteration\n## store data and plot\nimport pandas as pd\n\n# store plotting data in data frame\nplot_data = pd.DataFrame(\n    {\n        \"x_plt\": np.arange(np.size(miscount_history_SM_spam)),\n        \"y_miscount_SM\": miscount_history_SM_spam,\n        \"y_cost_SM\": cost_history_SM_spam,\n        \"y_miscount_PT\": miscount_history_PT_spam,\n        \"y_cost_PT\": cost_history_PT_spam\n    })\n\n## plot\nplot_cost_and_miscount(plot_data)\n\nThe plots above reveal some interesting results. The perceptron cost\nappears to attain a stable minimum cost, but its misclassification\nhistory appears to fluctuate rapidly between ~250 and 750\nmisclassifications. On the other hand, the softmax cost appears to\nattain a stable, albeit higher, minimum cost, but its misclassification\nhistory reaches a similar minimum to the softmax cost and is stable\n(does not fluctate rapidly). This suggests that the perceptron cost\nfunction is not perfectly flat at the identified minimum, causing minor\nperturbations in weight to produce large deviations from the minimum. It\nis possible that different (non-standard) gradient descent schemes\n(e.g., fully normalized) would eliminate this behaviour.\n2.3 Accuracy\nIn the following we determine the misclassification minimum and convert\nit to accuracy.\nRecall: we define accuracy, \\(\\mathcal{A}\\) as\n\\[\n\\mathcal{A} = 1 - \\frac{1}{P} \\sum\\limits_{p = 1}^P I(\\hat{y}_p, y_p) ,\n\\]\nwhere \\(\\sum\\limits_{p = 1}^P I\\) represents total misclassifications,\nwhich we average over all samples \\(P\\) and subtract from 1.\n\n### determine minimum misclassifications for each cost and convert to accuracy\n# identify minima\nmin_misclass_SM_spam = min(miscount_history_SM_spam)\nmin_misclass_PT_spam = min(miscount_history_PT_spam)\n\nprint(\"softmax minimum misclassifications:    \" + str(min_misclass_SM_spam))\nprint(\"perceptron minimum misclassifications: \" + str(min_misclass_PT_spam))\n\n# convert to accuracies\naccuracy_SM_spam = 1 - (min_misclass_SM_spam)/np.shape(x)[1]\naccuracy_PT_spam = 1 - (min_misclass_PT_spam)/np.shape(x)[1]\n\nprint(\"\\nsoftmax accuracy:    \" + str(accuracy_SM_spam))\nprint(\"perceptron accuracy: \" + str(accuracy_PT_spam))\n\nAs we can see above, both classifiers, trained using a softmax and\nperceptron cost, respectively, appear to perform relatively well, with\naccuracies above 90%. However, softmax cost performs slighly better,\nwith 3 fewer misclassifications than the perceptron. This result\nreflects our expectations based on the misclassification and cost\nhistories plotted above.\n2.4 Confusion matrix\nIn the following we identify the optimal w found by the softmax cost\nand construct the corresponding confusion matrix 3.\n\n### construct confusion matrix for optimal softmax `w`\n## define model again (compute linear combination of input points)\ndef model(x, w):\n    a = w[0] + np.dot(x.T, w[1:])\n    return a.T\n\n## identify optimal `w` for cost\nw_optimal_SM_spam = weight_history_SM_spam[np.argmin(miscount_history_SM_spam)]\n# w_optimal_PT_spam = weight_history_PT_spam[np.argmin(miscount_history_PT_spam)]\n\n### function for plotting confusion matrix\ndef plot_confusion_matrix(w, x, y):\n\n    import seaborn as sns\n    import pandas as pd\n    import numpy as np\n\n    # +1 or -1 whether above or below fitted decision bound determined by w\n    y_pred = np.sign(model(x, w))\n\n    ## determine confusion matrix values (true pos/neg, false pos/neg)\n    TP = np.sum(y_pred[y == 1] == 1)\n    TN = np.sum(y_pred[y == -1] == -1)\n    FP = np.sum(y_pred[y == -1] != -1)\n    FN = np.sum(y_pred[y == 1] != 1)\n\n    # store values in dictionary, matrix for plotting\n    confusion_matrix_OP = {\"TP\": TP, \"TN\": TN, \"FP\": FP, \"FN\": FN}\n    # confusion_matrix_OP[\"TN\"] = TN\n    conf_matrix = np.array([[TP, FN],\n                            [FP, TN]])\n\n    ## plot confusion matrix\n    # set annotations for tiles based on counts\n    group_names = ['TP', 'FN', 'FP', 'TN']\n    group_counts = [\"{0:0.0f}\".format(value) for value in conf_matrix.flatten()]\n    group_percentages = [\"{0:.2%}\".format(value) for value in\n                         conf_matrix.flatten()/np.sum(conf_matrix)]\n\n    tile_labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n                   zip(group_names, group_counts, group_percentages)]\n    tile_labels = np.asarray(tile_labels).reshape(2, 2)\n\n    # plot\n    ax = sns.heatmap(conf_matrix, annot = tile_labels, fmt = '', cmap = 'Blues')\n\n    # labels\n    ax.set_xlabel('\\nPredicted Values', fontsize = font_size)\n    ax.set_ylabel('Actual Values\\n', fontsize = font_size);\n    ax.xaxis.set_ticklabels(['Spam', 'Not spam'], fontsize = font_size)\n    ax.yaxis.set_ticklabels(['Spam', 'Not spam'], fontsize = font_size)\n\n    plt.show()\n\n    return confusion_matrix_OP\n\n## plot confusion matrix for softmax and optimal weight\nconfusion_matrix = plot_confusion_matrix(w_optimal_SM_spam, x, y)\n\n3 Credit check\nIn this problem we examinine a dataset containing credit ratings,\ndescribed in Example 6.11 of Machine Learning Refined.\nnotes\nClass labels (1 for ‘good rating’, -1 for ‘bad rating’) are again\nstored in the final row of the dataset (\\(N = 20\\)), with each other\nrow \\(n\\) representing a feature (account balance, duration of\nprevious credit, etc.) and each column \\(p\\) a sample (\\(P = 1000\\)).\nBelow we import the dataset.\n\n### import dataset\nimport numpy as np\n\n# data input\ncsvname = 'data/credit_dataset.csv'\ndata = np.loadtxt(csvname, delimiter = ',')\n\n# get input and output of dataset\nx = data[:-1, :]    # feature vectors\ny = data[-1:, :]    # class labels {1,-1}\n\n3.1 Standard normalization\nBelow we standard normalize the dataset so that features can be\ncompared.\n\n### perform standard normalization\nnormalizer, inverse_normalizer = standard_normalizer(x) # get std norm functions\nx = normalizer(x)\n\n3.2 Fitting perceptron-based classifier\nBelow we fit a binary classifier using a perceptron cost.\n\n### optimize perceptron cost over `credit rating` dataset\nimport autograd.numpy as np\n\n# define gradient descent parameters\nmax_its = 1000\nw = 0.1*np.random.randn(np.shape(x)[0] + 1, 1) # initial starting weights\n\n# call GD (choose arb alpha for now bc based on chosen g)\nweight_history_PT_cred, cost_history_PT_cred = gradient_descent(perceptron, 1,\n                                                        max_its, w)\n\n\n### compute misclassification history\nmiscount_history_PT_cred = [miscount(v, x, y) for v in weight_history_PT_cred]\n\n\n### store data for plotting\nimport pandas as pd\n\n# store plotting data\nx_plt = np.arange(np.size(miscount_history_PT_cred))\ny_miscount_PT = miscount_history_PT_cred\ny_cost_PT = cost_history_PT_cred\n\n\n### plot cost and misclassification history for perceptron cost\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport pandas as pd\n\n# use seaborn style\nsns.set_theme()\n\n# to prevent warning messages from appearing in the report\nimport warnings;\nwarnings.filterwarnings('ignore')\n\n# set inline figure format/quality, overall params\n# %config InlineBackend.figure_format = 'svg'\n\n# setup plot & subplots\nfig, axs = plt.subplots(2, 1, figsize = np.array([6.5, 8]),\n                        constrained_layout = True) # overall layout, size\n# axs[0] = plt.subplot(1,3,(1,2), frameon = 1)\naxs[0] = plt.subplot(211, frameon = 1)\naxs[1] = plt.subplot(212, frameon = 1)\n\n# set axis tick sizes\naxs[0].xaxis.set_tick_params(labelsize = font_size - 4)\naxs[0].yaxis.set_tick_params(labelsize = font_size - 4)\naxs[1].xaxis.set_tick_params(labelsize = font_size - 4)\naxs[1].yaxis.set_tick_params(labelsize = font_size - 4)\n\n# plot overlay of misclassifications & costs for each cost over all it\nline_miscount_CE    = axs[0].plot(x_plt, y_miscount_PT,\n                                  color = plt_colours[0],\n                                  linestyle = '-', linewidth = 2)\nline_cost_CE        = axs[1].plot(x_plt, y_cost_PT,\n                                  color = plt_colours[0],\n                                  linestyle = '-', linewidth = 2)\n\n# add labels\n# axs[0].set_xlabel('iteration', fontsize = font_size, **font_name)\naxs[0].set_xlabel('iteration', fontsize = font_size)\naxs[0].set_ylabel('misclassifications', fontsize = font_size)\naxs[1].set_xlabel('iteration', fontsize = font_size)\naxs[1].set_ylabel('cost', fontsize = font_size)\n\nplt.show()\n\n\n### compute and output perceptron accuracy\nmin_misclass_PT_cred = min(miscount_history_PT_cred)\naccuracy_PT_cred = 1 - (min_misclass_PT_cred)/np.shape(x)[1]\nprint(\"perceptron accuracy: \" + str(accuracy_PT_cred))\n\nThe perceptron achieves a classification accuracy of ~76%, which is\nwithin the range of the accuracy achieved in Machine Learning Refined.\n3.3 Confusion matrix\nWe now plot the confusion matrix corresponding to the optimal weight\nidentified by the perceptron.\n\n### plot confusion matrix for perceptron and optimal weight\nw_optimal_PT_cred = weight_history_PT_cred[np.argmin(miscount_history_PT_cred)]\nconfusion_matrix = plot_confusion_matrix(w_optimal_PT_cred, x, y)\n\n4 Three-class classification\nIn this problem we examine a three-class toy dataset, shown in Fig. 7.9\nof Machine Learning Refined, using the multi-class perceptron.\nAdditional resources (including plotting functions) are provided in the\nofficial ‘MLR’ git repository 4.\n4.1 Fitting multi-class perceptron\nBelow we fit the multi-class perceptron to the dataset.\n\n### import dataset & standard normalize\nimport numpy as np\n\n# data input\ncsvname = 'data/3class_data.csv'\ndata = np.loadtxt(csvname, delimiter = ',')\n\n# get input and output of dataset\nx = data[:-1, :]    # feature vectors\ny = data[-1:, :]    # class labels {1,-1}\n\n## normalize\nnormalizer, inverse_normalizer = standard_normalizer(x) # get std norm functions\nx = normalizer(x)\n\n\n### define model and multi-class perceptron (ref)\n## compute C linear combinations of input point, one per classifier\ndef model(x, w):\n    a = w[0] + np.dot(x.T, w[1:])\n    return a.T\n\n## multi-class perceptron\nlam = 10**-5  # regularization paramter\ndef multiclass_perceptron(w):\n\n    # pre-compute predictions on all points\n    all_evals = model(x, w)\n\n    # compute maximum across data points\n    a = np.max(all_evals, axis = 0)\n\n    # compute cost in compact form using numpy broadcasting\n    b = all_evals[y.astype(int).flatten(), np.arange(np.size(y))]\n    cost = np.sum(a - b)\n\n    # add regularizer\n    cost = cost + lam*np.linalg.norm(w[1:, :], 'fro')**2\n\n    # return average\n    return cost/float(np.size(y))\n\n\n### fit multi-class perceptron\nimport autograd.numpy as np\n\n# define gradient descent parameters\nmax_its = 1000\nw = 0.1*np.random.randn(3, 3) # initial starting weights\n\n# call GD (choose arb alpha for now bc based on chosen g)\nweight_history_3CPT, cost_history_3CPT = gradient_descent(\n    multiclass_perceptron, .1, max_its, w)\n\n\n### plot cost history\n## store data\nx_plt = np.arange(np.shape(weight_history_3CPT)[0])\ny_cost_3CPT = cost_history_3CPT\n\n## plot\ndef plot_cost_history(x, y):\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import seaborn as sns\n    import pandas as pd\n\n    # use seaborn style\n    sns.set_theme()\n\n    # setup plot\n    fig, ax = plt.subplots(1, 1, figsize = np.array([5, 5]),\n                            constrained_layout = True) # overall layout, size\n    ax = plt.subplot(111, frameon = 1)\n\n    # set axis tick sizes\n    ax.xaxis.set_tick_params(labelsize = font_size - 4)\n    ax.yaxis.set_tick_params(labelsize = font_size - 4)\n\n    # plot cost history\n    y_cost_3CPT = ax.plot(x, y, color = plt_colours[0],\n                        linestyle = '-', linewidth = 2)\n\n    # add labels\n    ax.set_xlabel('iteration', fontsize = font_size)\n    ax.set_ylabel('cost', fontsize = font_size)\n\n    plt.show()\n\nplot_cost_history(x_plt, y_cost_3CPT)\n\n\nweight_history_3CPT[1]\nmodel(x, w)\nnp.shape(model(x, w))\n\nall_evals = model(x, weight_history_3CPT[1])\nnp.shape(all_evals)\nnp.shape(np.max(all_evals, axis = 0))\n\n\n### define new function to compute multi-class misclassification history\ndef miscount_3CPT(w, x, y):\n    # 0-2 based on weight that maximizes prediction\n    # y_pred = np.argmax(np.abs(model(x, w), axis = 0), axis = 0)\n    \n    # compute prediction for all points\n    all_evals = model(x, w)\n\n    # assign point class of DB that maximumizes distance to DB\n    y_pred = np.argmax(all_evals, axis = 0)\n        \n    # pairwise compare vectors: 1 if model class pred == true class; sum\n    miscount_curr = np.sum(y_pred != y)\n    return miscount_curr\n\n\n### compute accuracy for optimal weight (minimum misclassifications)\n# compute misclassifications\nmiscount_history_3CPT = [miscount_3CPT(v, x, y) for v in weight_history_3CPT]\n\n# find minimum misclassifications and convert to accuracy\nmin_misclass_3CPT = min(miscount_history_3CPT)\nprint(\"multi-class perceptron minimum misclassifications: \"\n      + str(min_misclass_3CPT))\n\n# convert to accuracies\naccuracy_3CPT = 1 - (min_misclass_3CPT)/np.shape(x)[1]\n\nprint(\"multi-class perceptron accuracy: \" + str(accuracy_3CPT))\n\n4.2 Plotting the decision boundary\nBelow we plot the data in the plane, along with the decision boundary\nobtained by the multi-class perceptron.\n\n# code to clone library from git repo subdirectory\n# (from Ciro Santilli @ https://stackoverflow.com/questions/600079/how-do-i-clone-a-subdirectory-only-of-a-git-repository)\n# git clone \\\n#     --depth 1  \\\n#     --filter=blob:none  \\\n#     --sparse \\\n#     https://github.com/jermwatt/machine_learning_refined \\\n# ;\n# cd machine_learning_refined\n# git sparse-checkout set mlrefined_libraries\n\n\n### plot data and decision boundary\n# import relevant MLR plotting libraries (store lib in current dir)\nfrom mlrefined_libraries import superlearn_library as superlearn\nfrom mlrefined_libraries import math_optimization_library as optlib\n\noptimizers      = optlib.optimizers\nclassif_plotter = superlearn.multi_lin_classification_demo\ncost_lib        = superlearn.cost_functions\nnormalizers     = superlearn.normalizers\n\n# store std. normalized dataset to pass to function (colours = class labels)\ndata_norm = np.append(x, y, axis = 0)\ndata_norm[-1,0] = 0\n\n# plot individual data points in plane\ndemo = superlearn.multiclass_illustrator.Visualizer(data_norm)\ndemo.show_dataset()\n\n# add DBs (pass weights defining 3 class DBs that give perfect accuracy)\ndemo.show_complete_coloring([weight_history_3CPT[-1]], cost = \n                            multiclass_perceptron)\n\nThe multi-class perceptron achieves a classification accuracy of 100%,\nyielding results that are comparable to those shown in Machine Learning\nRefined.\n\nWolberg, W. H., Street, W. N., & Mangasarian, O. L. (1992). Breast\nCancer Dataset. University of Wisconsin Hospitals, Madison.↩︎\nDua, D. and Graff, C. (2019). UCI Machine Learning Repository\n[http://archive.ics.uci.edu/ml].\nIrvine, CA: University of California, School of Information and\nComputer Science.↩︎\nWatt, J., Borhani, R., & Katsaggelos, A. K. (2020). Machine\nlearning refined: Foundations, algorithms, and applications.\nCambridge University Press.↩︎\nhttps://github.com/jermwatt/machine_learning_refined/tree/gh-pages/notes/7_Linear_multiclass_classification\n\n↩︎\n",
    "preview": {},
    "last_modified": "2024-03-18T18:04:03-04:00",
    "input_file": {}
  },
  {
    "path": "mlr_gallery/2024-03-15-mlr-01-supervised-learning-in-python/",
    "title": "Python ML tour (1/5): Supervised learning",
    "description": "This is part 1 of a 5-part tour of machine learning in Python. \nIn this part I provide a high-level overview of optimization\nmethods for machine learning, and in particular, for training models. \nMost importantly, we see the motivation for gradient descent and provide \nsome justification for this hugely popular approach, which is the \nfoundation of many many other model training methods.\nAs much as possible, I rely on a \"from scratch\" approach, avoiding high-level\nlibraries like scikit-learn.",
    "author": [
      {
        "name": "Matthew Bain",
        "url": {}
      }
    ],
    "date": "2024-03-15",
    "categories": [
      "classification"
    ],
    "contents": "\n\n\n\n",
    "preview": {},
    "last_modified": "2024-03-18T14:16:39-04:00",
    "input_file": {}
  }
]
