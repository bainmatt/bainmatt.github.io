<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { color: #00769e; background-color: #f1f3f5; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span { color: #00769e; } /* Normal */
code span.al { color: #ad0000; } /* Alert */
code span.an { color: #5e5e5e; } /* Annotation */
code span.at { color: #657422; } /* Attribute */
code span.bn { color: #ad0000; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #00769e; } /* ControlFlow */
code span.ch { color: #20794d; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #5e5e5e; } /* Comment */
code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
code span.dt { color: #ad0000; } /* DataType */
code span.dv { color: #ad0000; } /* DecVal */
code span.er { color: #ad0000; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #ad0000; } /* Float */
code span.fu { color: #4758ab; } /* Function */
code span.im { } /* Import */
code span.in { color: #5e5e5e; } /* Information */
code span.kw { color: #00769e; } /* Keyword */
code span.op { color: #5e5e5e; } /* Operator */
code span.ot { color: #00769e; } /* Other */
code span.pp { color: #ad0000; } /* Preprocessor */
code span.sc { color: #5e5e5e; } /* SpecialChar */
code span.ss { color: #20794d; } /* SpecialString */
code span.st { color: #20794d; } /* String */
code span.va { color: #111111; } /* Variable */
code span.vs { color: #20794d; } /* VerbatimString */
code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
</style>


  <!--radix_placeholder_meta_tags-->
<title>Matthew Bain: Python machine learning tour (1/5): From binary to multi-class classification (*In development*)</title>

<meta property="description" itemprop="description" content="This is part 1 of a 5-part tour of machine learning in Python. &#10;In this part I provide a high-level overview of optimization&#10;methods for machine learning, and in particular, for training models. &#10;Most importantly, we see the motivation for gradient descent and provide &#10;some justification for this hugely popular approach, which is the &#10;foundation of many many other model training methods.&#10;As much as possible, I rely on a &quot;from scratch&quot; approach, avoiding high-level&#10;libraries like scikit-learn."/>

<link rel="canonical" href="https://bainmatt.github.io/mlr_gallery/mlr-01-draft/"/>

<!--  https://schema.org/Article -->
<meta property="article:published" itemprop="datePublished" content="2024-07-29"/>
<meta property="article:created" itemprop="dateCreated" content="2024-07-29"/>
<meta name="article:author" content="Matthew Bain"/>

<!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
<meta property="og:title" content="Matthew Bain: Python machine learning tour (1/5): From binary to multi-class classification (*In development*)"/>
<meta property="og:type" content="article"/>
<meta property="og:description" content="This is part 1 of a 5-part tour of machine learning in Python. &#10;In this part I provide a high-level overview of optimization&#10;methods for machine learning, and in particular, for training models. &#10;Most importantly, we see the motivation for gradient descent and provide &#10;some justification for this hugely popular approach, which is the &#10;foundation of many many other model training methods.&#10;As much as possible, I rely on a &quot;from scratch&quot; approach, avoiding high-level&#10;libraries like scikit-learn."/>
<meta property="og:url" content="https://bainmatt.github.io/mlr_gallery/mlr-01-draft/"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:site_name" content="Matthew Bain"/>

<!--  https://dev.twitter.com/cards/types/summary -->
<meta property="twitter:card" content="summary"/>
<meta property="twitter:title" content="Matthew Bain: Python machine learning tour (1/5): From binary to multi-class classification (*In development*)"/>
<meta property="twitter:description" content="This is part 1 of a 5-part tour of machine learning in Python. &#10;In this part I provide a high-level overview of optimization&#10;methods for machine learning, and in particular, for training models. &#10;Most importantly, we see the motivation for gradient descent and provide &#10;some justification for this hugely popular approach, which is the &#10;foundation of many many other model training methods.&#10;As much as possible, I rely on a &quot;from scratch&quot; approach, avoiding high-level&#10;libraries like scikit-learn."/>
<meta property="twitter:url" content="https://bainmatt.github.io/mlr_gallery/mlr-01-draft/"/>

<!--/radix_placeholder_meta_tags-->
  
  <!--radix_placeholder_rmarkdown_metadata-->

<script type="text/json" id="radix-rmarkdown-metadata">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","date","categories","output","header-includes","bibliography","chunk_output_type","draft","canonical_url"]}},"value":[{"type":"character","attributes":{},"value":["Python machine learning tour (1/5): From binary to multi-class classification (*In development*)"]},{"type":"character","attributes":{},"value":["This is part 1 of a 5-part tour of machine learning in Python. \nIn this part I provide a high-level overview of optimization\nmethods for machine learning, and in particular, for training models. \nMost importantly, we see the motivation for gradient descent and provide \nsome justification for this hugely popular approach, which is the \nfoundation of many many other model training methods.\nAs much as possible, I rely on a \"from scratch\" approach, avoiding high-level\nlibraries like scikit-learn."]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name"]}},"value":[{"type":"character","attributes":{},"value":["Matthew Bain"]}]}]},{"type":"character","attributes":{},"value":["2024-07-29"]},{"type":"character","attributes":{},"value":["Classification"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["bookdown::html_document2"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["includes","base_format","toc","toc_depth","toc_float","number_sections","self_contained","pandoc_args"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["in_header"]}},"value":[{"type":"character","attributes":{},"value":["../../favicon.html"]}]},{"type":"character","attributes":{},"value":["distill::distill_article"]},{"type":"logical","attributes":{},"value":[true]},{"type":"integer","attributes":{},"value":[3]},{"type":"logical","attributes":{},"value":[true]},{"type":"logical","attributes":{},"value":[true]},{"type":"logical","attributes":{},"value":[false]},{"type":"character","attributes":{},"value":["--number-sections"]}]}]},{"type":"character","attributes":{},"value":["../../generic-header.tex"]},{"type":"character","attributes":{},"value":["../../generic-bib.bib"]},{"type":"character","attributes":{},"value":["inline"]},{"type":"logical","attributes":{},"value":[false]},{"type":"character","attributes":{},"value":["https://bainmatt.github.io/mlr_gallery/mlr-01-draft/"]}]}
</script>
<!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["ML_classification-basics_files/anchor-4.2.2/anchor.min.js","ML_classification-basics_files/bowser-1.9.3/bowser.min.js","ML_classification-basics_files/distill-2.2.21/template.v2.js","ML_classification-basics_files/jquery-3.6.0/jquery-3.6.0.js","ML_classification-basics_files/jquery-3.6.0/jquery-3.6.0.min.js","ML_classification-basics_files/jquery-3.6.0/jquery-3.6.0.min.map","ML_classification-basics_files/popper-2.6.0/popper.min.js","ML_classification-basics_files/tippy-6.2.7/tippy-bundle.umd.min.js","ML_classification-basics_files/tippy-6.2.7/tippy-light-border.css","ML_classification-basics_files/tippy-6.2.7/tippy.css","ML_classification-basics_files/tippy-6.2.7/tippy.umd.min.js","ML_classification-basics_files/webcomponents-2.0.0/webcomponents.js","ML_classification-basics.ipynb"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
<meta name="distill:offset" content="../.."/>

<script type="application/javascript">

  window.headroom_prevent_pin = false;

  window.document.addEventListener("DOMContentLoaded", function (event) {

    // initialize headroom for banner
    var header = $('header').get(0);
    var headerHeight = header.offsetHeight;
    var headroom = new Headroom(header, {
      tolerance: 5,
      onPin : function() {
        if (window.headroom_prevent_pin) {
          window.headroom_prevent_pin = false;
          headroom.unpin();
        }
      }
    });
    headroom.init();
    if(window.location.hash)
      headroom.unpin();
    $(header).addClass('headroom--transition');

    // offset scroll location for banner on hash change
    // (see: https://github.com/WickyNilliams/headroom.js/issues/38)
    window.addEventListener("hashchange", function(event) {
      window.scrollTo(0, window.pageYOffset - (headerHeight + 25));
    });

    // responsive menu
    $('.distill-site-header').each(function(i, val) {
      var topnav = $(this);
      var toggle = topnav.find('.nav-toggle');
      toggle.on('click', function() {
        topnav.toggleClass('responsive');
      });
    });

    // nav dropdowns
    $('.nav-dropbtn').click(function(e) {
      $(this).next('.nav-dropdown-content').toggleClass('nav-dropdown-active');
      $(this).parent().siblings('.nav-dropdown')
         .children('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $("body").click(function(e){
      $('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $(".nav-dropdown").click(function(e){
      e.stopPropagation();
    });
  });
</script>

<style type="text/css">

/* Theme (user-documented overrideables for nav appearance) */

.distill-site-nav {
  color: rgba(255, 255, 255, 0.8);
  background-color: #0F2E3D;
  font-size: 15px;
  font-weight: 300;
}

.distill-site-nav a {
  color: inherit;
  text-decoration: none;
}

.distill-site-nav a:hover {
  color: white;
}

@media print {
  .distill-site-nav {
    display: none;
  }
}

.distill-site-header {

}

.distill-site-footer {

}


/* Site Header */

.distill-site-header {
  width: 100%;
  box-sizing: border-box;
  z-index: 3;
}

.distill-site-header .nav-left {
  display: inline-block;
  margin-left: 8px;
}

@media screen and (max-width: 768px) {
  .distill-site-header .nav-left {
    margin-left: 0;
  }
}


.distill-site-header .nav-right {
  float: right;
  margin-right: 8px;
}

.distill-site-header a,
.distill-site-header .title {
  display: inline-block;
  text-align: center;
  padding: 14px 10px 14px 10px;
}

.distill-site-header .title {
  font-size: 18px;
  min-width: 150px;
}

.distill-site-header .logo {
  padding: 0;
}

.distill-site-header .logo img {
  display: none;
  max-height: 20px;
  width: auto;
  margin-bottom: -4px;
}

.distill-site-header .nav-image img {
  max-height: 18px;
  width: auto;
  display: inline-block;
  margin-bottom: -3px;
}



@media screen and (min-width: 1000px) {
  .distill-site-header .logo img {
    display: inline-block;
  }
  .distill-site-header .nav-left {
    margin-left: 20px;
  }
  .distill-site-header .nav-right {
    margin-right: 20px;
  }
  .distill-site-header .title {
    padding-left: 12px;
  }
}


.distill-site-header .nav-toggle {
  display: none;
}

.nav-dropdown {
  display: inline-block;
  position: relative;
}

.nav-dropdown .nav-dropbtn {
  border: none;
  outline: none;
  color: rgba(255, 255, 255, 0.8);
  padding: 16px 10px;
  background-color: transparent;
  font-family: inherit;
  font-size: inherit;
  font-weight: inherit;
  margin: 0;
  margin-top: 1px;
  z-index: 2;
}

.nav-dropdown-content {
  display: none;
  position: absolute;
  background-color: white;
  min-width: 200px;
  border: 1px solid rgba(0,0,0,0.15);
  border-radius: 4px;
  box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.1);
  z-index: 1;
  margin-top: 2px;
  white-space: nowrap;
  padding-top: 4px;
  padding-bottom: 4px;
}

.nav-dropdown-content hr {
  margin-top: 4px;
  margin-bottom: 4px;
  border: none;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.nav-dropdown-active {
  display: block;
}

.nav-dropdown-content a, .nav-dropdown-content .nav-dropdown-header {
  color: black;
  padding: 6px 24px;
  text-decoration: none;
  display: block;
  text-align: left;
}

.nav-dropdown-content .nav-dropdown-header {
  display: block;
  padding: 5px 24px;
  padding-bottom: 0;
  text-transform: uppercase;
  font-size: 14px;
  color: #999999;
  white-space: nowrap;
}

.nav-dropdown:hover .nav-dropbtn {
  color: white;
}

.nav-dropdown-content a:hover {
  background-color: #ddd;
  color: black;
}

.nav-right .nav-dropdown-content {
  margin-left: -45%;
  right: 0;
}

@media screen and (max-width: 768px) {
  .distill-site-header a, .distill-site-header .nav-dropdown  {display: none;}
  .distill-site-header a.nav-toggle {
    float: right;
    display: block;
  }
  .distill-site-header .title {
    margin-left: 0;
  }
  .distill-site-header .nav-right {
    margin-right: 0;
  }
  .distill-site-header {
    overflow: hidden;
  }
  .nav-right .nav-dropdown-content {
    margin-left: 0;
  }
}


@media screen and (max-width: 768px) {
  .distill-site-header.responsive {position: relative; min-height: 500px; }
  .distill-site-header.responsive a.nav-toggle {
    position: absolute;
    right: 0;
    top: 0;
  }
  .distill-site-header.responsive a,
  .distill-site-header.responsive .nav-dropdown {
    display: block;
    text-align: left;
  }
  .distill-site-header.responsive .nav-left,
  .distill-site-header.responsive .nav-right {
    width: 100%;
  }
  .distill-site-header.responsive .nav-dropdown {float: none;}
  .distill-site-header.responsive .nav-dropdown-content {position: relative;}
  .distill-site-header.responsive .nav-dropdown .nav-dropbtn {
    display: block;
    width: 100%;
    text-align: left;
  }
}

/* Site Footer */

.distill-site-footer {
  width: 100%;
  overflow: hidden;
  box-sizing: border-box;
  z-index: 3;
  margin-top: 30px;
  padding-top: 30px;
  padding-bottom: 30px;
  text-align: center;
}

/* Headroom */

d-title {
  padding-top: 6rem;
}

@media print {
  d-title {
    padding-top: 4rem;
  }
}

.headroom {
  z-index: 1000;
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
}

.headroom--transition {
  transition: all .4s ease-in-out;
}

.headroom--unpinned {
  top: -100px;
}

.headroom--pinned {
  top: 0;
}

/* adjust viewport for navbar height */
/* helps vertically center bootstrap (non-distill) content */
.min-vh-100 {
  min-height: calc(100vh - 100px) !important;
}

</style>

<script src="../../site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<link href="../../site_libs/font-awesome-6.4.2/css/all.min.css" rel="stylesheet"/>
<link href="../../site_libs/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet"/>
<script src="../../site_libs/headroom-0.9.4/headroom.min.js"></script>
<script src="../../site_libs/autocomplete-0.37.1/autocomplete.min.js"></script>
<script src="../../site_libs/fuse-6.4.1/fuse.min.js"></script>

<script type="application/javascript">

function getMeta(metaName) {
  var metas = document.getElementsByTagName('meta');
  for (let i = 0; i < metas.length; i++) {
    if (metas[i].getAttribute('name') === metaName) {
      return metas[i].getAttribute('content');
    }
  }
  return '';
}

function offsetURL(url) {
  var offset = getMeta('distill:offset');
  return offset ? offset + '/' + url : url;
}

function createFuseIndex() {

  // create fuse index
  var options = {
    keys: [
      { name: 'title', weight: 20 },
      { name: 'categories', weight: 15 },
      { name: 'description', weight: 10 },
      { name: 'contents', weight: 5 },
    ],
    ignoreLocation: true,
    threshold: 0
  };
  var fuse = new window.Fuse([], options);

  // fetch the main search.json
  return fetch(offsetURL('search.json'))
    .then(function(response) {
      if (response.status == 200) {
        return response.json().then(function(json) {
          // index main articles
          json.articles.forEach(function(article) {
            fuse.add(article);
          });
          // download collections and index their articles
          return Promise.all(json.collections.map(function(collection) {
            return fetch(offsetURL(collection)).then(function(response) {
              if (response.status === 200) {
                return response.json().then(function(articles) {
                  articles.forEach(function(article) {
                    fuse.add(article);
                  });
                })
              } else {
                return Promise.reject(
                  new Error('Unexpected status from search index request: ' +
                            response.status)
                );
              }
            });
          })).then(function() {
            return fuse;
          });
        });

      } else {
        return Promise.reject(
          new Error('Unexpected status from search index request: ' +
                      response.status)
        );
      }
    });
}

window.document.addEventListener("DOMContentLoaded", function (event) {

  // get search element (bail if we don't have one)
  var searchEl = window.document.getElementById('distill-search');
  if (!searchEl)
    return;

  createFuseIndex()
    .then(function(fuse) {

      // make search box visible
      searchEl.classList.remove('hidden');

      // initialize autocomplete
      var options = {
        autoselect: true,
        hint: false,
        minLength: 2,
      };
      window.autocomplete(searchEl, options, [{
        source: function(query, callback) {
          const searchOptions = {
            isCaseSensitive: false,
            shouldSort: true,
            minMatchCharLength: 2,
            limit: 10,
          };
          var results = fuse.search(query, searchOptions);
          callback(results
            .map(function(result) { return result.item; })
          );
        },
        templates: {
          suggestion: function(suggestion) {
            var img = suggestion.preview && Object.keys(suggestion.preview).length > 0
              ? `<img src="${offsetURL(suggestion.preview)}"</img>`
              : '';
            var html = `
              <div class="search-item">
                <h3>${suggestion.title}</h3>
                <div class="search-item-description">
                  ${suggestion.description || ''}
                </div>
                <div class="search-item-preview">
                  ${img}
                </div>
              </div>
            `;
            return html;
          }
        }
      }]).on('autocomplete:selected', function(event, suggestion) {
        window.location.href = offsetURL(suggestion.path);
      });
      // remove inline display style on autocompleter (we want to
      // manage responsive display via css)
      $('.algolia-autocomplete').css("display", "");
    })
    .catch(function(error) {
      console.log(error);
    });

});

</script>

<style type="text/css">

.nav-search {
  font-size: x-small;
}

/* Algolioa Autocomplete */

.algolia-autocomplete {
  display: inline-block;
  margin-left: 10px;
  vertical-align: sub;
  background-color: white;
  color: black;
  padding: 6px;
  padding-top: 8px;
  padding-bottom: 0;
  border-radius: 6px;
  border: 1px #0F2E3D solid;
  width: 180px;
}


@media screen and (max-width: 768px) {
  .distill-site-nav .algolia-autocomplete {
    display: none;
    visibility: hidden;
  }
  .distill-site-nav.responsive .algolia-autocomplete {
    display: inline-block;
    visibility: visible;
  }
  .distill-site-nav.responsive .algolia-autocomplete .aa-dropdown-menu {
    margin-left: 0;
    width: 400px;
    max-height: 400px;
  }
}

.algolia-autocomplete .aa-input, .algolia-autocomplete .aa-hint {
  width: 90%;
  outline: none;
  border: none;
}

.algolia-autocomplete .aa-hint {
  color: #999;
}
.algolia-autocomplete .aa-dropdown-menu {
  width: 550px;
  max-height: 70vh;
  overflow-x: visible;
  overflow-y: scroll;
  padding: 5px;
  margin-top: 3px;
  margin-left: -150px;
  background-color: #fff;
  border-radius: 5px;
  border: 1px solid #999;
  border-top: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion {
  cursor: pointer;
  padding: 5px 4px;
  border-bottom: 1px solid #eee;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion:last-of-type {
  border-bottom: none;
  margin-bottom: 2px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item {
  overflow: hidden;
  font-size: 0.8em;
  line-height: 1.4em;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item h3 {
  font-size: 1rem;
  margin-block-start: 0;
  margin-block-end: 5px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-description {
  display: inline-block;
  overflow: hidden;
  height: 2.8em;
  width: 80%;
  margin-right: 4%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview {
  display: inline-block;
  width: 15%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img {
  height: 3em;
  width: auto;
  display: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img[src] {
  display: initial;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion.aa-cursor {
  background-color: #eee;
}
.algolia-autocomplete .aa-dropdown-menu .aa-suggestion em {
  font-weight: bold;
  font-style: normal;
}

</style>


<!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

<style type="text/css">

body {
  background-color: white;
}

.pandoc-table {
  width: 100%;
}

.pandoc-table>caption {
  margin-bottom: 10px;
}

.pandoc-table th:not([align]) {
  text-align: left;
}

.pagedtable-footer {
  font-size: 15px;
}

d-byline .byline {
  grid-template-columns: 2fr 2fr;
}

d-byline .byline h3 {
  margin-block-start: 1.5em;
}

d-byline .byline .authors-affiliations h3 {
  margin-block-start: 0.5em;
}

.authors-affiliations .orcid-id {
  width: 16px;
  height:16px;
  margin-left: 4px;
  margin-right: 4px;
  vertical-align: middle;
  padding-bottom: 2px;
}

d-title .dt-tags {
  margin-top: 1em;
  grid-column: text;
}

.dt-tags .dt-tag {
  text-decoration: none;
  display: inline-block;
  color: rgba(0,0,0,0.6);
  padding: 0em 0.4em;
  margin-right: 0.5em;
  margin-bottom: 0.4em;
  font-size: 70%;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

d-article table.gt_table td,
d-article table.gt_table th {
  border-bottom: none;
  font-size: 100%;
}

.html-widget {
  margin-bottom: 2.0em;
}

.l-screen-inset {
  padding-right: 16px;
}

.l-screen .caption {
  margin-left: 10px;
}

.shaded {
  background: rgb(247, 247, 247);
  padding-top: 20px;
  padding-bottom: 20px;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .html-widget {
  margin-bottom: 0;
  border: 1px solid rgba(0, 0, 0, 0.1);
}

.shaded .shaded-content {
  background: white;
}

.text-output {
  margin-top: 0;
  line-height: 1.5em;
}

.hidden {
  display: none !important;
}

hr.section-separator {
  border: none;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  margin: 0px;
}


d-byline {
  border-top: none;
}

d-article {
  padding-top: 2.5rem;
  padding-bottom: 30px;
  border-top: none;
}

d-appendix {
  padding-top: 30px;
}

d-article>p>img {
  width: 100%;
}

d-article h2 {
  margin: 1rem 0 1.5rem 0;
}

d-article h3 {
  margin-top: 1.5rem;
}

d-article iframe {
  border: 1px solid rgba(0, 0, 0, 0.1);
  margin-bottom: 2.0em;
  width: 100%;
}

/* Tweak code blocks */

d-article div.sourceCode code,
d-article pre code {
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
}

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: auto;
}

d-article div.sourceCode {
  background-color: white;
}

d-article div.sourceCode pre {
  padding-left: 10px;
  font-size: 12px;
  border-left: 2px solid rgba(0,0,0,0.1);
}

d-article pre {
  font-size: 12px;
  color: black;
  background: none;
  margin-top: 0;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

d-article pre a {
  border-bottom: none;
}

d-article pre a:hover {
  border-bottom: none;
  text-decoration: underline;
}

d-article details {
  grid-column: text;
  margin-bottom: 0.8em;
}

@media(min-width: 768px) {

d-article pre,
d-article div.sourceCode,
d-article div.sourceCode pre {
  overflow: visible !important;
}

d-article div.sourceCode pre {
  padding-left: 18px;
  font-size: 14px;
}

/* tweak for Pandoc numbered line within distill */
d-article pre.numberSource code > span {
    left: -2em;
}

d-article pre {
  font-size: 14px;
}

}

figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

/* CSS for d-contents */

.d-contents {
  grid-column: text;
  color: rgba(0,0,0,0.8);
  font-size: 0.9em;
  padding-bottom: 1em;
  margin-bottom: 1em;
  padding-bottom: 0.5em;
  margin-bottom: 1em;
  padding-left: 0.25em;
  justify-self: start;
}

@media(min-width: 1000px) {
  .d-contents.d-contents-float {
    height: 0;
    grid-column-start: 1;
    grid-column-end: 4;
    justify-self: center;
    padding-right: 3em;
    padding-left: 2em;
  }
}

.d-contents nav h3 {
  font-size: 18px;
  margin-top: 0;
  margin-bottom: 1em;
}

.d-contents li {
  list-style-type: none
}

.d-contents nav > ul {
  padding-left: 0;
}

.d-contents ul {
  padding-left: 1em
}

.d-contents nav ul li {
  margin-top: 0.6em;
  margin-bottom: 0.2em;
}

.d-contents nav a {
  font-size: 13px;
  border-bottom: none;
  text-decoration: none
  color: rgba(0, 0, 0, 0.8);
}

.d-contents nav a:hover {
  text-decoration: underline solid rgba(0, 0, 0, 0.6)
}

.d-contents nav > ul > li > a {
  font-weight: 600;
}

.d-contents nav > ul > li > ul {
  font-weight: inherit;
}

.d-contents nav > ul > li > ul > li {
  margin-top: 0.2em;
}


.d-contents nav ul {
  margin-top: 0;
  margin-bottom: 0.25em;
}

.d-article-with-toc h2:nth-child(2) {
  margin-top: 0;
}


/* Figure */

.figure {
  position: relative;
  margin-bottom: 2.5em;
  margin-top: 1.5em;
}

.figure .caption {
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
}

.figure img.external {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

.figure .caption a {
  color: rgba(0, 0, 0, 0.6);
}

.figure .caption b,
.figure .caption strong, {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}

/* Citations */

d-article .citation {
  color: inherit;
  cursor: inherit;
}

div.hanging-indent{
  margin-left: 1em; text-indent: -1em;
}

/* Citation hover box */

.tippy-box[data-theme~=light-border] {
  background-color: rgba(250, 250, 250, 0.95);
}

.tippy-content > p {
  margin-bottom: 0;
  padding: 2px;
}


/* Tweak 1000px media break to show more text */

@media(min-width: 1000px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }

  d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
  }
  figure .caption, .figure .caption, figure figcaption {
    font-size: 13px;
  }
}

@media(min-width: 1180px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 32px;
  }

  .grid {
    grid-column-gap: 32px;
  }
}


/* Get the citation styles for the appendix (not auto-injected on render since
   we do our own rendering of the citation appendix) */

d-appendix .citation-appendix,
.d-appendix .citation-appendix {
  font-size: 11px;
  line-height: 15px;
  border-left: 1px solid rgba(0, 0, 0, 0.1);
  padding-left: 18px;
  border: 1px solid rgba(0,0,0,0.1);
  background: rgba(0, 0, 0, 0.02);
  padding: 10px 18px;
  border-radius: 3px;
  color: rgba(150, 150, 150, 1);
  overflow: hidden;
  margin-top: -12px;
  white-space: pre-wrap;
  word-wrap: break-word;
}

/* Include appendix styles here so they can be overridden */

d-appendix {
  contain: layout style;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-top: 60px;
  margin-bottom: 0;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  color: rgba(0,0,0,0.5);
  padding-top: 60px;
  padding-bottom: 48px;
}

d-appendix h3 {
  grid-column: page-start / text-start;
  font-size: 15px;
  font-weight: 500;
  margin-top: 1em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.65);
}

d-appendix h3 + * {
  margin-top: 1em;
}

d-appendix ol {
  padding: 0 0 0 15px;
}

@media (min-width: 768px) {
  d-appendix ol {
    padding: 0 0 0 30px;
    margin-left: -30px;
  }
}

d-appendix li {
  margin-bottom: 1em;
}

d-appendix a {
  color: rgba(0, 0, 0, 0.6);
}

d-appendix > * {
  grid-column: text;
}

d-appendix > d-footnote-list,
d-appendix > d-citation-list,
d-appendix > distill-appendix {
  grid-column: screen;
}

/* Include footnote styles here so they can be overridden */

d-footnote-list {
  contain: layout style;
}

d-footnote-list > * {
  grid-column: text;
}

d-footnote-list a.footnote-backlink {
  color: rgba(0,0,0,0.3);
  padding-left: 0.5em;
}



/* Anchor.js */

.anchorjs-link {
  /*transition: all .25s linear; */
  text-decoration: none;
  border-bottom: none;
}
*:hover > .anchorjs-link {
  margin-left: -1.125em !important;
  text-decoration: none;
  border-bottom: none;
}

/* Social footer */

.social_footer {
  margin-top: 30px;
  margin-bottom: 0;
  color: rgba(0,0,0,0.67);
}

.disqus-comments {
  margin-right: 30px;
}

.disqus-comment-count {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  cursor: pointer;
}

#disqus_thread {
  margin-top: 30px;
}

.article-sharing a {
  border-bottom: none;
  margin-right: 8px;
}

.article-sharing a:hover {
  border-bottom: none;
}

.sidebar-section.subscribe {
  font-size: 12px;
  line-height: 1.6em;
}

.subscribe p {
  margin-bottom: 0.5em;
}


.article-footer .subscribe {
  font-size: 15px;
  margin-top: 45px;
}


.sidebar-section.custom {
  font-size: 12px;
  line-height: 1.6em;
}

.custom p {
  margin-bottom: 0.5em;
}

/* Styles for listing layout (hide title) */
.layout-listing d-title, .layout-listing .d-title {
  display: none;
}

/* Styles for posts lists (not auto-injected) */


.posts-with-sidebar {
  padding-left: 45px;
  padding-right: 45px;
}

.posts-list .description h2,
.posts-list .description p {
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
}

.posts-list .description h2 {
  font-weight: 700;
  border-bottom: none;
  padding-bottom: 0;
}

.posts-list h2.post-tag {
  border-bottom: 1px solid rgba(0, 0, 0, 0.2);
  padding-bottom: 12px;
}
.posts-list {
  margin-top: 60px;
  margin-bottom: 24px;
}

.posts-list .post-preview {
  text-decoration: none;
  overflow: hidden;
  display: block;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  padding: 24px 0;
}

.post-preview-last {
  border-bottom: none !important;
}

.posts-list .posts-list-caption {
  grid-column: screen;
  font-weight: 400;
}

.posts-list .post-preview h2 {
  margin: 0 0 6px 0;
  line-height: 1.2em;
  font-style: normal;
  font-size: 24px;
}

.posts-list .post-preview p {
  margin: 0 0 12px 0;
  line-height: 1.4em;
  font-size: 16px;
}

.posts-list .post-preview .thumbnail {
  box-sizing: border-box;
  margin-bottom: 24px;
  position: relative;
  max-width: 500px;
}
.posts-list .post-preview img {
  width: 100%;
  display: block;
}

.posts-list .metadata {
  font-size: 12px;
  line-height: 1.4em;
  margin-bottom: 18px;
}

.posts-list .metadata > * {
  display: inline-block;
}

.posts-list .metadata .publishedDate {
  margin-right: 2em;
}

.posts-list .metadata .dt-authors {
  display: block;
  margin-top: 0.3em;
  margin-right: 2em;
}

.posts-list .dt-tags {
  display: block;
  line-height: 1em;
}

.posts-list .dt-tags .dt-tag {
  display: inline-block;
  color: rgba(0,0,0,0.6);
  padding: 0.3em 0.4em;
  margin-right: 0.2em;
  margin-bottom: 0.4em;
  font-size: 60%;
  border: 1px solid rgba(0,0,0,0.2);
  border-radius: 3px;
  text-transform: uppercase;
  font-weight: 500;
}

.posts-list img {
  opacity: 1;
}

.posts-list img[data-src] {
  opacity: 0;
}

.posts-more {
  clear: both;
}


.posts-sidebar {
  font-size: 16px;
}

.posts-sidebar h3 {
  font-size: 16px;
  margin-top: 0;
  margin-bottom: 0.5em;
  font-weight: 400;
  text-transform: uppercase;
}

.sidebar-section {
  margin-bottom: 30px;
}

.categories ul {
  list-style-type: none;
  margin: 0;
  padding: 0;
}

.categories li {
  color: rgba(0, 0, 0, 0.8);
  margin-bottom: 0;
}

.categories li>a {
  border-bottom: none;
}

.categories li>a:hover {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
}

.categories .active {
  font-weight: 600;
}

.categories .category-count {
  color: rgba(0, 0, 0, 0.4);
}


@media(min-width: 768px) {
  .posts-list .post-preview h2 {
    font-size: 26px;
  }
  .posts-list .post-preview .thumbnail {
    float: right;
    width: 30%;
    margin-bottom: 0;
  }
  .posts-list .post-preview .description {
    float: left;
    width: 45%;
  }
  .posts-list .post-preview .metadata {
    float: left;
    width: 20%;
    margin-top: 8px;
  }
  .posts-list .post-preview p {
    margin: 0 0 12px 0;
    line-height: 1.5em;
    font-size: 16px;
  }
  .posts-with-sidebar .posts-list {
    float: left;
    width: 75%;
  }
  .posts-with-sidebar .posts-sidebar {
    float: right;
    width: 20%;
    margin-top: 60px;
    padding-top: 24px;
    padding-bottom: 24px;
  }
}


/* Improve display for browsers without grid (IE/Edge <= 15) */

.downlevel {
  line-height: 1.6em;
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  margin: 0;
}

.downlevel .d-title {
  padding-top: 6rem;
  padding-bottom: 1.5rem;
}

.downlevel .d-title h1 {
  font-size: 50px;
  font-weight: 700;
  line-height: 1.1em;
  margin: 0 0 0.5rem;
}

.downlevel .d-title p {
  font-weight: 300;
  font-size: 1.2rem;
  line-height: 1.55em;
  margin-top: 0;
}

.downlevel .d-byline {
  padding-top: 0.8em;
  padding-bottom: 0.8em;
  font-size: 0.8rem;
  line-height: 1.8em;
}

.downlevel .section-separator {
  border: none;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
}

.downlevel .d-article {
  font-size: 1.06rem;
  line-height: 1.7em;
  padding-top: 1rem;
  padding-bottom: 2rem;
}


.downlevel .d-appendix {
  padding-left: 0;
  padding-right: 0;
  max-width: none;
  font-size: 0.8em;
  line-height: 1.7em;
  margin-bottom: 0;
  color: rgba(0,0,0,0.5);
  padding-top: 40px;
  padding-bottom: 48px;
}

.downlevel .footnotes ol {
  padding-left: 13px;
}

.downlevel .base-grid,
.downlevel .distill-header,
.downlevel .d-title,
.downlevel .d-abstract,
.downlevel .d-article,
.downlevel .d-appendix,
.downlevel .distill-appendix,
.downlevel .d-byline,
.downlevel .d-footnote-list,
.downlevel .d-citation-list,
.downlevel .distill-footer,
.downlevel .appendix-bottom,
.downlevel .posts-container {
  padding-left: 40px;
  padding-right: 40px;
}

@media(min-width: 768px) {
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
  padding-left: 150px;
  padding-right: 150px;
  max-width: 900px;
}
}

.downlevel pre code {
  display: block;
  border-left: 2px solid rgba(0, 0, 0, .1);
  padding: 0 0 0 20px;
  font-size: 14px;
}

.downlevel code, .downlevel pre {
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

.downlevel .posts-list .post-preview {
  color: inherit;
}



</style>

<script type="application/javascript">

function is_downlevel_browser() {
  if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                 window.navigator.userAgent)) {
    return true;
  } else {
    return window.load_distill_framework === undefined;
  }
}

// show body when load is complete
function on_load_complete() {

  // add anchors
  if (window.anchors) {
    window.anchors.options.placement = 'left';
    window.anchors.add('d-article > h2, d-article > h3, d-article > h4, d-article > h5');
  }


  // set body to visible
  document.body.style.visibility = 'visible';

  // force redraw for leaflet widgets
  if (window.HTMLWidgets) {
    var maps = window.HTMLWidgets.findAll(".leaflet");
    $.each(maps, function(i, el) {
      var map = this.getMap();
      map.invalidateSize();
      map.eachLayer(function(layer) {
        if (layer instanceof L.TileLayer)
          layer.redraw();
      });
    });
  }

  // trigger 'shown' so htmlwidgets resize
  $('d-article').trigger('shown');
}

function init_distill() {

  init_common();

  // create front matter
  var front_matter = $('<d-front-matter></d-front-matter>');
  $('#distill-front-matter').wrap(front_matter);

  // create d-title
  $('.d-title').changeElementType('d-title');

  // separator
  var separator = '<hr class="section-separator" style="clear: both"/>';
  // prepend separator above appendix
  $('.d-byline').before(separator);
  $('.d-article').before(separator);

  // create d-byline
  var byline = $('<d-byline></d-byline>');
  $('.d-byline').replaceWith(byline);

  // create d-article
  var article = $('<d-article></d-article>');
  $('.d-article').wrap(article).children().unwrap();

  // move posts container into article
  $('.posts-container').appendTo($('d-article'));

  // create d-appendix
  $('.d-appendix').changeElementType('d-appendix');

  // flag indicating that we have appendix items
  var appendix = $('.appendix-bottom').children('h3').length > 0;

  // replace footnotes with <d-footnote>
  $('.footnote-ref').each(function(i, val) {
    appendix = true;
    var href = $(this).attr('href');
    var id = href.replace('#', '');
    var fn = $('#' + id);
    var fn_p = $('#' + id + '>p');
    fn_p.find('.footnote-back').remove();
    var text = fn_p.html();
    var dtfn = $('<d-footnote></d-footnote>');
    dtfn.html(text);
    $(this).replaceWith(dtfn);
  });
  // remove footnotes
  $('.footnotes').remove();

  // move refs into #references-listing
  $('#references-listing').replaceWith($('#refs'));

  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    var id = $(this).attr('id');
    $('.d-contents a[href="#' + id + '"]').parent().remove();
    appendix = true;
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
  });

  // show d-appendix if we have appendix content
  $("d-appendix").css('display', appendix ? 'grid' : 'none');

  // localize layout chunks to just output
  $('.layout-chunk').each(function(i, val) {

    // capture layout
    var layout = $(this).attr('data-layout');

    // apply layout to markdown level block elements
    var elements = $(this).children().not('details, div.sourceCode, pre, script');
    elements.each(function(i, el) {
      var layout_div = $('<div class="' + layout + '"></div>');
      if (layout_div.hasClass('shaded')) {
        var shaded_content = $('<div class="shaded-content"></div>');
        $(this).wrap(shaded_content);
        $(this).parent().wrap(layout_div);
      } else {
        $(this).wrap(layout_div);
      }
    });


    // unwrap the layout-chunk div
    $(this).children().unwrap();
  });

  // remove code block used to force  highlighting css
  $('.distill-force-highlighting-css').parent().remove();

  // remove empty line numbers inserted by pandoc when using a
  // custom syntax highlighting theme, except when numbering line
  // in code chunk
  $('pre:not(.numberLines) code.sourceCode a:empty').remove();

  // load distill framework
  load_distill_framework();

  // wait for window.distillRunlevel == 4 to do post processing
  function distill_post_process() {

    if (!window.distillRunlevel || window.distillRunlevel < 4)
      return;

    // hide author/affiliations entirely if we have no authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
    if (!have_authors)
      $('d-byline').addClass('hidden');

    // article with toc class
    $('.d-contents').parent().addClass('d-article-with-toc');

    // strip links that point to #
    $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

    // add orcid ids
    $('.authors-affiliations').find('.author').each(function(i, el) {
      var orcid_id = front_matter.authors[i].orcidID;
      var author_name = front_matter.authors[i].author
      if (orcid_id) {
        var a = $('<a></a>');
        a.attr('href', 'https://orcid.org/' + orcid_id);
        var img = $('<img></img>');
        img.addClass('orcid-id');
        img.attr('alt', author_name ? 'ORCID ID for ' + author_name : 'ORCID ID');
        img.attr('src','data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==');
        a.append(img);
        $(this).append(a);
      }
    });

    // hide elements of author/affiliations grid that have no value
    function hide_byline_column(caption) {
      $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
    }

    // affiliations
    var have_affiliations = false;
    for (var i = 0; i<front_matter.authors.length; ++i) {
      var author = front_matter.authors[i];
      if (author.affiliation !== "&nbsp;") {
        have_affiliations = true;
        break;
      }
    }
    if (!have_affiliations)
      $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

    // published date
    if (!front_matter.publishedDate)
      hide_byline_column("Published");

    // document object identifier
    var doi = $('d-byline').find('h3:contains("DOI")');
    var doi_p = doi.next().empty();
    if (!front_matter.doi) {
      // if we have a citation and valid citationText then link to that
      if ($('#citation').length > 0 && front_matter.citationText) {
        doi.html('Citation');
        $('<a href="#citation"></a>')
          .text(front_matter.citationText)
          .appendTo(doi_p);
      } else {
        hide_byline_column("DOI");
      }
    } else {
      $('<a></a>')
         .attr('href', "https://doi.org/" + front_matter.doi)
         .html(front_matter.doi)
         .appendTo(doi_p);
    }

     // change plural form of authors/affiliations
    if (front_matter.authors.length === 1) {
      var grid = $('.authors-affiliations');
      grid.children('h3:contains("Authors")').text('Author');
      grid.children('h3:contains("Affiliations")').text('Affiliation');
    }

    // remove d-appendix and d-footnote-list local styles
    $('d-appendix > style:first-child').remove();
    $('d-footnote-list > style:first-child').remove();

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // hoverable references
    $('span.citation[data-cites]').each(function() {
      const citeChild = $(this).children()[0]
      // Do not process if @xyz has been used without escaping and without bibliography activated
      // https://github.com/rstudio/distill/issues/466
      if (citeChild === undefined) return true

      if (citeChild.nodeName == "D-FOOTNOTE") {
        var fn = citeChild
        $(this).html(fn.shadowRoot.querySelector("sup"))
        $(this).id = fn.id
        fn.remove()
      }
      var refs = $(this).attr('data-cites').split(" ");
      var refHtml = refs.map(function(ref) {
        // Could use CSS.escape too here, we insure backward compatibility in navigator
        return "<p>" + $('div[id="ref-' + ref + '"]').html() + "</p>";
      }).join("\n");
      window.tippy(this, {
        allowHTML: true,
        content: refHtml,
        maxWidth: 500,
        interactive: true,
        interactiveBorder: 10,
        theme: 'light-border',
        placement: 'bottom-start'
      });
    });

    // fix footnotes in tables (#411)
    // replacing broken distill.pub feature
    $('table d-footnote').each(function() {
      // we replace internal showAtNode methode which is triggered when hovering a footnote
      this.hoverBox.showAtNode = function(node) {
        // ported from https://github.com/distillpub/template/pull/105/files
        calcOffset = function(elem) {
            let x = elem.offsetLeft;
            let y = elem.offsetTop;
            // Traverse upwards until an `absolute` element is found or `elem`
            // becomes null.
            while (elem = elem.offsetParent && elem.style.position != 'absolute') {
                x += elem.offsetLeft;
                y += elem.offsetTop;
            }

            return { left: x, top: y };
        }
        // https://developer.mozilla.org/en-US/docs/Web/API/HTMLElement/offsetTop
        const bbox = node.getBoundingClientRect();
        const offset = calcOffset(node);
        this.show([offset.left + bbox.width, offset.top + bbox.height]);
      }
    })

    // clear polling timer
    clearInterval(tid);

    // show body now that everything is ready
    on_load_complete();
  }

  var tid = setInterval(distill_post_process, 50);
  distill_post_process();

}

function init_downlevel() {

  init_common();

   // insert hr after d-title
  $('.d-title').after($('<hr class="section-separator"/>'));

  // check if we have authors
  var front_matter = JSON.parse($("#distill-front-matter").html());
  var have_authors = front_matter.authors && front_matter.authors.length > 0;

  // manage byline/border
  if (!have_authors)
    $('.d-byline').remove();
  $('.d-byline').after($('<hr class="section-separator"/>'));
  $('.d-byline a').remove();

  // remove toc
  $('.d-contents').remove();

  // move appendix elements
  $('h1.appendix, h2.appendix').each(function(i, val) {
    $(this).changeElementType('h3');
  });
  $('h3.appendix').each(function(i, val) {
    $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
  });


  // inject headers into references and footnotes
  var refs_header = $('<h3></h3>');
  refs_header.text('References');
  $('#refs').prepend(refs_header);

  var footnotes_header = $('<h3></h3');
  footnotes_header.text('Footnotes');
  $('.footnotes').children('hr').first().replaceWith(footnotes_header);

  // move appendix-bottom entries to the bottom
  $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
  $('.appendix-bottom').remove();

  // remove appendix if it's empty
  if ($('.d-appendix').children().length === 0)
    $('.d-appendix').remove();

  // prepend separator above appendix
  $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

  // trim code
  $('pre>code').each(function(i, val) {
    $(this).html($.trim($(this).html()));
  });

  // move posts-container right before article
  $('.posts-container').insertBefore($('.d-article'));

  $('body').addClass('downlevel');

  on_load_complete();
}


function init_common() {

  // jquery plugin to change element types
  (function($) {
    $.fn.changeElementType = function(newType) {
      var attrs = {};

      $.each(this[0].attributes, function(idx, attr) {
        attrs[attr.nodeName] = attr.nodeValue;
      });

      this.replaceWith(function() {
        return $("<" + newType + "/>", attrs).append($(this).contents());
      });
    };
  })(jQuery);

  // prevent underline for linked images
  $('a > img').parent().css({'border-bottom' : 'none'});

  // mark non-body figures created by knitr chunks as 100% width
  $('.layout-chunk').each(function(i, val) {
    var figures = $(this).find('img, .html-widget');
    // ignore leaflet img layers (#106)
    figures = figures.filter(':not(img[class*="leaflet"])')
    if ($(this).attr('data-layout') !== "l-body") {
      figures.css('width', '100%');
    } else {
      figures.css('max-width', '100%');
      figures.filter("[width]").each(function(i, val) {
        var fig = $(this);
        fig.css('width', fig.attr('width') + 'px');
      });

    }
  });

  // auto-append index.html to post-preview links in file: protocol
  // and in rstudio ide preview
  $('.post-preview').each(function(i, val) {
    if (window.location.protocol === "file:")
      $(this).attr('href', $(this).attr('href') + "index.html");
  });

  // get rid of index.html references in header
  if (window.location.protocol !== "file:") {
    $('.distill-site-header a[href]').each(function(i,val) {
      $(this).attr('href', $(this).attr('href').replace(/^index[.]html/, "./"));
    });
  }

  // add class to pandoc style tables
  $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
  $('.kable-table').children('table').addClass('pandoc-table');

  // add figcaption style to table captions
  $('caption').parent('table').addClass("figcaption");

  // initialize posts list
  if (window.init_posts_list)
    window.init_posts_list();

  // implmement disqus comment link
  $('.disqus-comment-count').click(function() {
    window.headroom_prevent_pin = true;
    $('#disqus_thread').toggleClass('hidden');
    if (!$('#disqus_thread').hasClass('hidden')) {
      var offset = $(this).offset();
      $(window).resize();
      $('html, body').animate({
        scrollTop: offset.top - 35
      });
    }
  });
}

document.addEventListener('DOMContentLoaded', function() {
  if (is_downlevel_browser())
    init_downlevel();
  else
    window.addEventListener('WebComponentsReady', init_distill);
});

</script>

<style type="text/css">
/* base variables */

/* Edit the CSS properties in this file to create a custom
   Distill theme. Only edit values in the right column
   for each row; values shown are the CSS defaults.
   To return any property to the default,
   you may set its value to: unset
   All rows must end with a semi-colon.                      */

/* Optional: embed custom fonts here with `@import`          */
/* This must remain at the top of this file.                 */



html {
  /*-- Main font sizes --*/
  --title-size:      50px;
  --body-size:       1.06rem;
  --code-size:       14px;
  --aside-size:      12px;
  --fig-cap-size:    13px;
  /*-- Main font colors --*/
  --title-color:     #000000;
  --header-color:    rgba(0, 0, 0, 0.8);
  --body-color:      rgba(0, 0, 0, 0.8);
  --aside-color:     rgba(0, 0, 0, 0.6);
  --fig-cap-color:   rgba(0, 0, 0, 0.6);
  /*-- Specify custom fonts ~~~ must be imported above   --*/
  --heading-font:    sans-serif;
  --mono-font:       monospace;
  --body-font:       sans-serif;
  --navbar-font:     sans-serif;  /* websites + blogs only */
}

/*-- ARTICLE METADATA --*/
d-byline {
  --heading-size:    0.6rem;
  --heading-color:   rgba(0, 0, 0, 0.5);
  --body-size:       0.8rem;
  --body-color:      rgba(0, 0, 0, 0.8);
}

/*-- ARTICLE TABLE OF CONTENTS --*/
.d-contents {
  --heading-size:    18px;
  --contents-size:   13px;
}

/*-- ARTICLE APPENDIX --*/
d-appendix {
  --heading-size:    15px;
  --heading-color:   rgba(0, 0, 0, 0.65);
  --text-size:       0.8em;
  --text-color:      rgba(0, 0, 0, 0.5);
}

/*-- WEBSITE HEADER + FOOTER --*/
/* These properties only apply to Distill sites and blogs  */

.distill-site-header {
  --title-size:       18px;
  --text-color:       rgba(255, 255, 255, 0.8);
  --text-size:        15px;
  --hover-color:      white;
  --bkgd-color:       #0F2E3D;
}

.distill-site-footer {
  --text-color:       rgba(255, 255, 255, 0.8);
  --text-size:        15px;
  --hover-color:      white;
  --bkgd-color:       #0F2E3D;
}

/*-- Additional custom styles --*/
/* Add any additional CSS rules below                      */
</style>
<style type="text/css">/* -------------------------------------------------------------------------- */
/* 
STILL TODO:
- figure caption label bold
- favicons in pages

- ?<br> less space below description; <br> less space above footline
*/
/* -------------------------------------------------------------------------- */

/* ---------------------- */
/* --- STYLE ELEMENTS --- */
/* ---------------------- */
/* 
Text elements:
- page: title, subtitle, metadata, toc levels 1-3
- content: h1-h4, body, code, math
- site: nav bar, menu items, footer
- other: captions, asides, references/footnotes

Text properties:
- font face, size, weight, colour
- text spacing, padding below, padding above
- text alignment

List (bulleted, numbered) properties:
- vertical spacing
- bullet/number colour

Header properties:
- number padding, number colour

Nav bar properties:
- background colour, height

Page properties:
- page width
*/

/* ---------------------- */
/* --- SIMPLE REPORTS --- */
/* ---------------------- */
/* 
- Simple colours: One accent for ribbon/special (possibly slightly larger) text; one scheme
- Simple nav: No fancy TOC or subheader numbers or clickable elements
- Simple plots: Standard plots from datavis_utils with no. caps; only import, no fancy local gg
+ Label data directly if possible; possibly include concise L-aligned message as title
+ No complicated figure subtitles (just describe unclear elements)
- Simple refs: Standard hyperlinked web refs + formal citations + sparse foot/asides
- Simple bullets: No fancy icons/bullets/text resizing
- Simple layouts: No more than 2 simple columns where the information demands it
*/

/* --------------------- */
/* --- SIMPLE SLIDES --- */
/* --------------------- */
/* 
- All of the above + simple storytelling:
+ No nav bar/complicated footer (ribbon, name, company, x/y pages)
+ No slide subtitles (state message in title)
+ No (time spent on) outline 
+ No fancy tables with icons (or just a few and x's; should be linear)
+ No fancy layering (if at all; should be clean and speak for itself)
+ No footnote/hyperlink colours
*/

/* ----------------------- */
/* --- SIMPLE PALETTES --- */
/* ----------------------- */
/* 
- Generate scheme a priori/evenly spaced around colour wheel
- From scheme colours generate monochromatic/divergent/sequential maps as needed
*/

/* -------------------------------------------------------------------------- */

/* base variables */

/* Edit the CSS properties in this file to create a custom
   Distill theme. Only edit values in the right column
   for each row; values shown are the CSS defaults.
   To return any property to the default,
   you may set its value to: unset
   All rows must end with a semi-colon.                      */

/* Optional: embed custom fonts here with `@import`          */
/* This must remain at the top of this file.                 */
/* @import url('https://fonts.googleapis.com/css?family=Noto+Serif+JP:300,300i&display=swap'); */
/* @import url('https://fonts.googleapis.com/css?family=Lato:400,400i,700&display=swap'); */
/* @import url('https://fonts.googleapis.com/css?family=IBM+Plex+Mono&display=swap'); */

/* ---------------------------------- */
/* --- DEFAULT RMD CUSTOMIZATIONS --- */
/* ---------------------------------- */

/* --- GLOBAL DOCUMENT SETTINGS --- */
body {
  /* font-family:-apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif; */
  /* font-family: 'Gill Sans', 'Gill Sans MT', Calibri, 'Trebuchet MS', sans-serif; */
  /* font-family: 'Lucida Sans', 'Lucida Sans Regular', 'Lucida Grande', 'Lucida Sans Unixcode', Geneva, Verdana, sans-serif; */
  
  /* [MB] Body text line height */
  line-height: 1.7em;
}

/* --- [MB] CUSTOM DIVS -- */
/* Figure/image/proof hr container
/*  Use: Wrap in <div class="fig-border"> * 2 */
.fig-border {
  margin-top: -15px;
  padding-top: 0px;
  margin-bottom: 20px;
  padding-bottom: 20px;
  border-bottom: 1px solid lightgray; /* or #eee */
}

/* Apply horizontal scroll to a specific container */
/*  by wrapping large kable tables/math blocks in <div class="scroll-container"> ... </div>*/
.scroll-container {
  max-width: max-content;
  overflow-x: auto;
}

/* --- [MB] GENERAL CUSTOMIZATIONS -- */
/* [TODO] Enable horizontal scroll for entire page to prevent clipping */
d-article {
  overflow-x: auto;
  scrollbar-width: none;
}

/* --- [MB] [TODO] HEADER CUSTOMIZATIONS -- */
/* --- Letter spacing + line heights --- */
h1, h2, h3, h4, h5, h6 {
  letter-spacing: 2px;                            /* default: 2px */
  line-height: normal;
  font-weight: 300;                               /* default: 300 */
}

/* --- Fixed padding -- */
h1, .h1, h2, .h2, h3, .h3, h4, .h4 {
  margin-top: 40px;
}

/* --- Further Distill specifications --- */
.posts-list .posts-list-caption {
  font-weight: 500;
  line-height: normal;
  margin-bottom: .75em;
  padding-bottom: .3em;
  border-bottom: 1px solid lightgray; /* or #eee */
}

.posts-list
.description h2 {
  font-weight: 500;
  border-bottom: none;
  padding-bottom: 0;
}

/* --- Article title weight --- */
d-title h1 {
  font-weight: 500;
}

/* --- Header 1 horizontal rule and weight --- */
d-article h1 {
  margin-bottom: .75em;
  padding-bottom: .3em;
  border-bottom: 1px solid lightgray;
  font-weight: 500;
}

/* --- Header 2 size and weight --- */
d-article h2 {
  font-size: 26px; 
  font-weight: 500;
}

/* --- Set header 4 size to match body (see HTML selector below) --- */
d-article h4 {
  /* font-size: max(1.06rem, 15px); */
}

/* --- OTHER --- */
/* --- Nav bar padding */
.distill-site-header {
  padding-top: 1rem;                              /* default: 1rem */
}

/* Dropdown menu text spacing */
.nav-dropdown .nav-dropbtn {
  letter-spacing: 2px;
}

.distill-site-header.responsive .nav-dropdown .nav-dropbtn {
  letter-spacing: 2px;
}

/* --- ORDERED LISTS --- */
/* Bulletted list items padding */
ul {
  margin-top: 0; 
  margin-bottom: 0;
}

ul > li {
  margin-bottom: 2px;
}

/* Numbered list items padding */
ol {
  margin-top: 0; /* Remove default top margin for the list */
  margin-bottom: 0; /* Remove default bottom margin for the list */
}

ol > li {
  margin-bottom: 2px; /* Adjust the spacing between list items */
}

/* --- FLOATING TOC --- */
/* Change background colour */
.tocify-item {
  /* background-color: rgb(251, 250, 247); */
  font-size: 10pt;
}

.tocify-subheader {
  font-size: 9.75pt;
}

/* Ensure floating TOC idents successive lines */
.tocify-subheader > .tocify-item {
  text-indent: initial;
  padding-left: 2em;
}

/* --- OTHER --- */
/* --- Supress page title from  displaying in knit but keep metadata --- */
#header {
  display: none;
}

/* -------------------------------------- */
/* --- FURTHER DISTILL CUSTOMIZATIONS --- */
/* -------------------------------------- */
html {
  /* --- Main font sizes --- */
  --title-size:      35px;                        /* default: 50px */
  /* --body-size:       1.06rem; */                    /* default: 1.06rem; alt: 15px */          
  /* [MB] Include min body (para, inline/block math other than Bookdown) size */
  --body-size:       max(1.06rem, 15px);
  --code-size:       13.25px;                     /* default: 14px */                  
  --aside-size:      12px;                        /* default: 12px */                  
  --fig-cap-size:    13.5px;                      /* default: 13px */

  /* [MB] Bold the "Figure" or "Table" tag */
  
  
  /* --- Main font colors --- */
  /*--title-color:     #ca225e;*/                     /* default: #ca225e */
  /*--header-color:    #ca225e;*/                     /* theme: #ca225e */
  --body-color:      #404040;                     /* theme: #404040 */
  --aside-color:     rgba(0, 0, 0, 0.6);
  --fig-cap-color:   rgba(0, 0, 0, 0.6);
  
  /* --- Specify custom fonts ~~~ must be imported above --- */
  --heading-font:    "Noto Serif JP", sans-serif; /* theme */
  --mono-font:       "IBM Plex Mono", monospace;  /* theme */
  --body-font:       "Lato", sans-serif;          /* theme */
  --navbar-font:     "Lato", sans-serif;          /* theme */
  
  /*
  --heading-font:    "Amiri", serif;
  --mono-font:       "DM Mono", monospace;
  --body-font:       "Bitter", sans-serif;
  --navbar-font:     "Amiri", serif;
  */
}

/* --- ARTICLE METADATA --- */
d-byline {
  --heading-size:    0.9rem;                      /* theme: 0.9rem */
  --heading-color:   rgba(0, 0, 0, 0.5);          /* default: rgba(0, 0, 0, 0.5) */
  --body-size:       0.95rem;                     /* theme: 0.95rem */
  
  /* [MB] Hide the Author field */
  .author,
  {
    display: none;                              
  }
}

/* --- ARTICLE TABLE OF CONTENTS --- */
.d-contents {
  --heading-size:    18px;                        /* default: 18px */
  --contents-size:   13px;                        /* default: 13px */
}

/* --- ARTICLE APPENDIX --- */
d-appendix {
  --heading-size:    15px;                        /* default: 15px */
  --heading-color:   rgba(0, 0, 0, 0.65);         /* default: rgba(0, 0, 0, 0.65) */
  --text-size:       0.9rem;                      /* theme: 0.9rem */
  --text-color:      #1a162d;                     /* theme: 0.9rem */
}

/* --- WEBSITE HEADER + FOOTER --- */
/* These properties only apply to Distill sites and blogs  */
.distill-site-header {
  --title-size:       18px;                       /* default: 18px */
  --text-color:       #1f1f1f;                    /* theme: #1f1f1f */
  --text-size:        15px;                       /* default: 15px */
  --hover-color:      #787878;                    /* default: #787878 */
  --bkgd-color:       #fff;                       /* theme: #fff */
}

.distill-site-footer {
  --text-color:       #7e7b88;                    /* theme: #7e7b88 */
  --text-size:        15px;                       /* default: 15px */
  --hover-color:      white;                      /* defaultl: white */
  /*--bkgd-color:       #ca225e3d;*/                  /* theme: #ca225e3d */
}

/* --- OTHER --- */
/* Navigation bar letter case */
.distill-site-header { 
  letter-spacing: 2px;                            /* default: 2px */
  /*text-transform: uppercase;*/                      /* default: uppercase */

/* Makes logo bigger */
.distill-site-header .logo img{
  max-height: 20px;                               /* theme: 20px */
}

.distill-site-header {
  padding-top: 1rem;                              /* default: 1rem */
}

d-title h1,
d-article h2,
.posts-list .description h2,
.posts-list > h1 {
    font-weight: 300;                             /* default: 300 */
}

d-appendix {
  /*background-color: #fdf7f9;*/                      /* default: #fdf7f9 */
  /*border-top: none;*/                               /* default: none */
}

/* -------------------------------- */
/* --- ADDITIONAL CUSTOM STYLES --- */
/* -------------------------------- */
/* --- ORDERED LISTS --- */
/* Ordered list index colour */
ul > li::marker {                 
  /*color: #ca225e;*/                                 /* default: #ca225e */
}

ol > li::marker {                 
  /*color: #ca225e;*/                                 /* default: #ca225e */
}</style>
<style type="text/css">
/* base style */

/* FONT FAMILIES */

:root {
  --heading-default: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  --mono-default: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  --body-default: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
}

body,
.posts-list .post-preview p,
.posts-list .description p {
  font-family: var(--body-font), var(--body-default);
}

h1, h2, h3, h4, h5, h6,
.posts-list .post-preview h2,
.posts-list .description h2 {
  font-family: var(--heading-font), var(--heading-default);
}

d-article div.sourceCode code,
d-article pre code {
  font-family: var(--mono-font), var(--mono-default);
}


/*-- TITLE --*/
d-title h1,
.posts-list > h1 {
  color: var(--title-color, black);
}

d-title h1 {
  font-size: var(--title-size, 50px);
}

/*-- HEADERS --*/
d-article h1,
d-article h2,
d-article h3,
d-article h4,
d-article h5,
d-article h6 {
  color: var(--header-color, rgba(0, 0, 0, 0.8));
}

/*-- BODY --*/
d-article > p,  /* only text inside of <p> tags */
d-article > ul, /* lists */
d-article > ol {
  color: var(--body-color, rgba(0, 0, 0, 0.8));
  font-size: var(--body-size, 1.06rem);
}


/*-- CODE --*/
d-article div.sourceCode code,
d-article pre code {
  font-size: var(--code-size, 14px);
}

/*-- ASIDE --*/
d-article aside {
  font-size: var(--aside-size, 12px);
  color: var(--aside-color, rgba(0, 0, 0, 0.6));
}

/*-- FIGURE CAPTIONS --*/
figure .caption,
figure figcaption,
.figure .caption {
  font-size: var(--fig-cap-size, 13px);
  color: var(--fig-cap-color, rgba(0, 0, 0, 0.6));
}

/*-- METADATA --*/
d-byline h3 {
  font-size: var(--heading-size, 0.6rem);
  color: var(--heading-color, rgba(0, 0, 0, 0.5));
}

d-byline {
  font-size: var(--body-size, 0.8rem);
  color: var(--body-color, rgba(0, 0, 0, 0.8));
}

d-byline a,
d-article d-byline a {
  color: var(--body-color, rgba(0, 0, 0, 0.8));
}

/*-- TABLE OF CONTENTS --*/
.d-contents nav h3 {
  font-size: var(--heading-size, 18px);
}

.d-contents nav a {
  font-size: var(--contents-size, 13px);
}

/*-- APPENDIX --*/
d-appendix h3 {
  font-size: var(--heading-size, 15px);
  color: var(--heading-color, rgba(0, 0, 0, 0.65));
}

d-appendix {
  font-size: var(--text-size, 0.8em);
  color: var(--text-color, rgba(0, 0, 0, 0.5));
}

d-appendix d-footnote-list a.footnote-backlink {
  color: var(--text-color, rgba(0, 0, 0, 0.5));
}

/*-- WEBSITE HEADER + FOOTER --*/
.distill-site-header .title {
  font-size: var(--title-size, 18px);
  font-family: var(--navbar-font), var(--heading-default);
}

.distill-site-header a,
.nav-dropdown .nav-dropbtn {
  font-family: var(--navbar-font), var(--heading-default);
}

.nav-dropdown .nav-dropbtn {
  color: var(--text-color, rgba(255, 255, 255, 0.8));
  font-size: var(--text-size, 15px);
}

.distill-site-header a:hover,
.nav-dropdown:hover .nav-dropbtn {
  color: var(--hover-color, white);
}

.distill-site-header {
  font-size: var(--text-size, 15px);
  color: var(--text-color, rgba(255, 255, 255, 0.8));
  background-color: var(--bkgd-color, #0F2E3D);
}

.distill-site-footer {
  font-size: var(--text-size, 15px);
  color: var(--text-color, rgba(255, 255, 255, 0.8));
  background-color: var(--bkgd-color, #0F2E3D);
}

.distill-site-footer a:hover {
  color: var(--hover-color, white);
}</style>
<!--/radix_placeholder_distill-->
  <script src="../../site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
  <script src="../../site_libs/popper-2.6.0/popper.min.js"></script>
  <link href="../../site_libs/tippy-6.2.7/tippy.css" rel="stylesheet" />
  <link href="../../site_libs/tippy-6.2.7/tippy-light-border.css" rel="stylesheet" />
  <script src="../../site_libs/tippy-6.2.7/tippy.umd.min.js"></script>
  <script src="../../site_libs/anchor-4.2.2/anchor.min.js"></script>
  <script src="../../site_libs/bowser-1.9.3/bowser.min.js"></script>
  <script src="../../site_libs/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="../../site_libs/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
<!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Python machine learning tour (1/5): From binary to multi-class classification (*In development*)","description":"This is part 1 of a 5-part tour of machine learning in Python. \nIn this part I provide a high-level overview of optimization\nmethods for machine learning, and in particular, for training models. \nMost importantly, we see the motivation for gradient descent and provide \nsome justification for this hugely popular approach, which is the \nfoundation of many many other model training methods.\nAs much as possible, I rely on a \"from scratch\" approach, avoiding high-level\nlibraries like scikit-learn.","authors":[{"author":"Matthew Bain","authorURL":"#","affiliation":"&nbsp;","affiliationURL":"#","orcidID":""}],"publishedDate":"2024-07-29T00:00:00.000-04:00","citationText":"Bain, 2024"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<header class="header header--fixed" role="banner">
<nav class="distill-site-nav distill-site-header">
<div class="nav-left">
<a href="../../index.html" class="title">Matthew Bain</a>
<div class="nav-dropdown">
<button class="nav-dropbtn">
Resources
 
<span class="down-arrow">&#x25BE;</span>
</button>
<div class="nav-dropdown-content">
<a href="../../mlr_gallery.html">Machine learning tour</a>
<a href="../../roadmap_gallery.html">References &amp; docs</a>
<a href="../../demo_gallery.html">Demos</a>
</div>
</div>
<a href="../../data_stories.html">Analysis</a>
<a href="../../blog.html">Blog</a>
<a href="../../music_page.html">Music</a>
<input id="distill-search" class="nav-search hidden" type="text" placeholder="Search..."/>
</div>
<div class="nav-right">
<a href="https://github.com/mattlabcode">
<i class="fab fa-github fa-lg" aria-hidden="true"></i>
</a>
<a href="https://www.linkedin.com/in/matthew-bain314/">
<i class="fab fa-linkedin fa-lg" aria-hidden="true"></i>
</a>
<a href="https://www.youtube.com/@fujinai9/featured">
<i class="fa fa-youtube fa-lg" aria-hidden="true"></i>
</a>
<a href="javascript:void(0);" class="nav-toggle">&#9776;</a>
</div>
</nav>
</header>
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Python machine learning tour (1/5): From binary to multi-class classification (In development)</h1>

<!--radix_placeholder_categories-->
<!--/radix_placeholder_categories-->
<p><p>This is part 1 of a 5-part tour of machine learning in Python.
In this part I provide a high-level overview of optimization
methods for machine learning, and in particular, for training models.
Most importantly, we see the motivation for gradient descent and provide
some justification for this hugely popular approach, which is the
foundation of many many other model training methods.
As much as possible, I rely on a “from scratch” approach, avoiding high-level
libraries like scikit-learn.</p></p>
</div>

<div class="d-byline">
  
  Matthew Bain
  
<br/>2024-07-29
</div>

<div class="d-article">
<div class="d-contents d-contents-float">
<nav class="l-text toc figcaption" id="TOC">
<h3>Contents</h3>
<ul>
<li><a href="#predicting-breast-cancer" id="toc-predicting-breast-cancer"><span class="toc-section-number">1</span> Predicting breast cancer</a>
<ul>
<li><a href="#softmax-perceptron-costs" id="toc-softmax-perceptron-costs"><span class="toc-section-number">1.1</span> Softmax &amp; perceptron costs</a></li>
<li><a href="#minimizing-cost-functions" id="toc-minimizing-cost-functions"><span class="toc-section-number">1.2</span> Minimizing cost functions</a></li>
<li><a href="#misclassifications" id="toc-misclassifications"><span class="toc-section-number">1.3</span> Misclassifications</a></li>
<li><a href="#plotting-cost-and-misclassifications" id="toc-plotting-cost-and-misclassifications"><span class="toc-section-number">1.4</span> Plotting: cost and misclassifications</a></li>
<li><a href="#logistic-regression-cross-entropy" id="toc-logistic-regression-cross-entropy"><span class="toc-section-number">1.5</span> Logistic regression &amp; cross-entropy</a></li>
</ul></li>
<li><a href="#spam-detection" id="toc-spam-detection"><span class="toc-section-number">2</span> Spam detection</a>
<ul>
<li><a href="#some-basic-preprocessing" id="toc-some-basic-preprocessing"><span class="toc-section-number">2.1</span> Some basic preprocessing</a></li>
<li><a href="#email-classification-with-perceptron" id="toc-email-classification-with-perceptron"><span class="toc-section-number">2.2</span> Email classification with perceptron</a></li>
<li><a href="#accuracy" id="toc-accuracy"><span class="toc-section-number">2.3</span> Accuracy</a></li>
<li><a href="#confusion-matrix" id="toc-confusion-matrix"><span class="toc-section-number">2.4</span> Confusion matrix</a></li>
</ul></li>
<li><a href="#credit-check" id="toc-credit-check"><span class="toc-section-number">3</span> Credit check</a>
<ul>
<li><a href="#standard-normalization" id="toc-standard-normalization"><span class="toc-section-number">3.1</span> Standard normalization</a></li>
<li><a href="#fitting-perceptron-based-classifier" id="toc-fitting-perceptron-based-classifier"><span class="toc-section-number">3.2</span> Fitting perceptron-based classifier</a></li>
<li><a href="#confusion-matrix-1" id="toc-confusion-matrix-1"><span class="toc-section-number">3.3</span> Confusion matrix</a></li>
</ul></li>
<li><a href="#three-class-classification" id="toc-three-class-classification"><span class="toc-section-number">4</span> Three-class classification</a>
<ul>
<li><a href="#fitting-multi-class-perceptron" id="toc-fitting-multi-class-perceptron"><span class="toc-section-number">4.1</span> Fitting multi-class perceptron</a></li>
<li><a href="#plotting-the-decision-boundary" id="toc-plotting-the-decision-boundary"><span class="toc-section-number">4.2</span> Plotting the decision boundary</a></li>
</ul></li>
</ul>
</nav>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">### load dependencies</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># essentials</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy.linalg <span class="im">as</span> LA           <span class="co"># linalg module of numpy</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd                 <span class="co"># pandas for data manipulation</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autograd.numpy <span class="im">as</span> np         <span class="co"># autograd-wrapped numpy</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># optimization</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> autograd <span class="im">import</span> grad           <span class="co"># module for computing gradient</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> autograd <span class="im">import</span> value_and_grad <span class="co"># returns grad &amp; val of input function</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># plotting</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt     <span class="co"># pyplot module of matplotlib</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co"># global plotting parameters</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>plt_colours <span class="op">=</span> (np.array([<span class="dv">94</span>,<span class="dv">255</span>,<span class="dv">231</span>])<span class="op">/</span><span class="dv">360</span>, np.array([<span class="dv">133</span>,<span class="dv">94</span>,<span class="dv">214</span>])<span class="op">/</span><span class="dv">360</span>,</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>               np.array([<span class="dv">110</span>,<span class="dv">250</span>,<span class="dv">152</span>])<span class="op">/</span><span class="dv">360</span>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>font_size   <span class="op">=</span> <span class="dv">14</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>font_name   <span class="op">=</span> {<span class="st">&#39;fontname&#39;</span>: <span class="st">&#39;Avenir&#39;</span>}</span></code></pre></div>
</div>
<h1 data-number="1" id="predicting-breast-cancer"><span class="header-section-number">1</span> Predicting breast cancer</h1>
<p>In this problem we examine the <a href="https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)">Breast Cancer Data
Set</a>,
obtained from the University of Wisconsin Hospitals, Madison from Dr.
William H. Wolberg <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p>
<h2 data-number="1.1" id="softmax-perceptron-costs"><span class="header-section-number">1.1</span> Softmax &amp; perceptron costs</h2>
<p>In the following we implement the softmax and perceptron cost functions.</p>
<p><em>notes</em></p>
<ul>
<li>class labels are coded as <span class="math inline">\(1\)</span> for benign, <span class="math inline">\(-1\)</span> for malignant.</li>
<li>the dataset is arranged in columns, each corresponding to an
individual &amp; each row a cellular measurement.</li>
<li>Class labels are stored in the final row.</li>
</ul>
<p>Below we import the dataset.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">### setup dataset</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># data input</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>csvname <span class="op">=</span> <span class="st">&#39;data/breast_cancer_data.csv&#39;</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.loadtxt(csvname, delimiter <span class="op">=</span> <span class="st">&#39;,&#39;</span>)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co"># get input and output of dataset</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> data[:<span class="op">-</span><span class="dv">1</span>, :]   <span class="co"># feature vectors</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data[<span class="op">-</span><span class="dv">1</span>:, :]   <span class="co"># class labels {1,-1}</span></span></code></pre></div>
</div>
<p>We now define our model and complete an implementation of the softmax
and perceptron cost functions.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co">### define model and cost functions</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># define model (compute linear combination of input points)</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> model(x, w):</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    a <span class="op">=</span> w[<span class="dv">0</span>] <span class="op">+</span> np.dot(x.T, w[<span class="dv">1</span>:])</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> a.T</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co">## cost functions (`g`)</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co"># softmax cost implementation</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># note: x,y req. by cost but def. globally s.t. for given w compute cost</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="co"># across all x,y)</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> softmax(w):</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># note: equivalent to softnax aoprox to perceptron cost, below</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    cost <span class="op">=</span> np.<span class="bu">sum</span>(np.log(<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>y<span class="op">*</span>model(x, w))))</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> cost<span class="op">/</span><span class="bu">float</span>(np.size(y))</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="co"># perceptron cost implementation</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> perceptron(w):</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># sum of pair-wise maximum between 0, model values</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    cost <span class="op">=</span> np.<span class="bu">sum</span>(np.maximum(<span class="dv">0</span>, <span class="op">-</span>y<span class="op">*</span>model(x, w)))</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> cost<span class="op">/</span><span class="bu">float</span>(np.size(y))</span></code></pre></div>
</div>
<h2 data-number="1.2" id="minimizing-cost-functions"><span class="header-section-number">1.2</span> Minimizing cost functions</h2>
<p>We will now optimize these cost functions using gradient descent.</p>
<p>Below we define the standard gradient descent algorithm.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co">### GD function</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gradient_descent(g, alpha, max_its, w):</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  <span class="im">import</span> autograd.numpy <span class="im">as</span> np</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>  <span class="im">from</span> autograd <span class="im">import</span> grad</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># define alpha based on chosen cost function</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># alpha = 1.0 if g == softmax else .1</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> g <span class="op">==</span> softmax: alpha <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">elif</span> g <span class="op">==</span> perceptron: alpha <span class="op">=</span> <span class="fl">.1</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>  <span class="cf">elif</span> g <span class="op">==</span> cross_entropy: alpha <span class="op">=</span> <span class="fl">.6</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># compute gradient (wrt w, holding constant x,y)</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>  gradient <span class="op">=</span> grad(g)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>  <span class="co"># run GD loop</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>  weight_history <span class="op">=</span> [w] <span class="co"># weight history container</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>  cost_history <span class="op">=</span> [g(w)] <span class="co"># cost function history container</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(max_its):</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># evaluate the gradient</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>    grad_eval <span class="op">=</span> gradient(w)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># take gradient descent step</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>    w <span class="op">=</span> w <span class="op">-</span> alpha<span class="op">*</span>grad_eval</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># record weight and cost</span></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>    weight_history.append(w)</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>    cost_history.append(g(w))</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> weight_history, cost_history</span></code></pre></div>
</div>
<p>Below we define our parameters and then minimize both cost functions.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co">### optimize cost functions</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autograd.numpy <span class="im">as</span> np</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># define gradient descent (GD) parameters</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>max_its <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> <span class="fl">0.1</span><span class="op">*</span>np.random.randn(<span class="dv">9</span>, <span class="dv">1</span>) <span class="co"># initial starting weights</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co"># call GD (choose arb alpha for now bc based on chosen g)</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>weight_history_SM, cost_history_SM <span class="op">=</span> gradient_descent(softmax, <span class="dv">1</span>,</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>                                                      max_its, w)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>weight_history_PT, cost_history_PT <span class="op">=</span> gradient_descent(perceptron, <span class="dv">1</span>,</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>                                                      max_its, w)</span></code></pre></div>
</div>
<h2 data-number="1.3" id="misclassifications"><span class="header-section-number">1.3</span> Misclassifications</h2>
<p>We now compute the number of misclassifications for each iteration of
gradient descent.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">### compute misclassification history</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autograd.numpy <span class="im">as</span> np</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># compute misclassification history</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> miscount(w, x, y):</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># +1 or -1 whether above or below fitted decision bound determined by w</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> np.sign(model(x, w))</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># pairwise compare vectors: 1 if model class pred == true class; sum</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    miscount_curr <span class="op">=</span> np.<span class="bu">sum</span>(y_pred <span class="op">!=</span> y)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> miscount_curr</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co"># compute miscount history for each cost function</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>miscount_history_SM <span class="op">=</span> [miscount(v, x, y) <span class="cf">for</span> v <span class="kw">in</span> weight_history_SM]</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>miscount_history_PT <span class="op">=</span> [miscount(v, x, y) <span class="cf">for</span> v <span class="kw">in</span> weight_history_PT]</span></code></pre></div>
</div>
<h2 data-number="1.4" id="plotting-cost-and-misclassifications"><span class="header-section-number">1.4</span> Plotting: cost and misclassifications</h2>
<p>Below we plot the cost and misclassification history for each cost
function.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co">### define function for plotting cost and misclassification hist in same figure</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_cost_and_miscount(data):</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># store data</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    x_plt           <span class="op">=</span> data[<span class="st">&quot;x_plt&quot;</span>]</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    y_miscount_SM   <span class="op">=</span> data[<span class="st">&quot;y_miscount_SM&quot;</span>]</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    y_cost_SM       <span class="op">=</span> data[<span class="st">&quot;y_cost_SM&quot;</span>]</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    y_miscount_PT   <span class="op">=</span> data[<span class="st">&quot;y_miscount_PT&quot;</span>]</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    y_cost_PT       <span class="op">=</span> data[<span class="st">&quot;y_cost_PT&quot;</span>]</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># use seaborn style</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    sns.set_theme()</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># to prevent warning messages from appearing in the report</span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> warnings<span class="op">;</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>    warnings.filterwarnings(<span class="st">&#39;ignore&#39;</span>)</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># set inline figure format/quality, overall params</span></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># %config InlineBackend.figure_format = &#39;svg&#39;</span></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># setup plot &amp; subplots</span></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>    fig, axs <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>, figsize <span class="op">=</span> np.array([<span class="fl">6.5</span>, <span class="dv">8</span>]),</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>                            constrained_layout <span class="op">=</span> <span class="va">True</span>) <span class="co"># overall layout, size</span></span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># axs[0] = plt.subplot(1,3,(1,2), frameon = 1)</span></span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>] <span class="op">=</span> plt.subplot(<span class="dv">211</span>, frameon <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>] <span class="op">=</span> plt.subplot(<span class="dv">212</span>, frameon <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># set axis tick sizes</span></span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].xaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].yaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].xaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].yaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plot overlay of misclassifications &amp; costs for each cost over it</span></span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>    line_miscount_SM    <span class="op">=</span> axs[<span class="dv">0</span>].plot(x_plt, y_miscount_SM,</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>                                      color <span class="op">=</span> plt_colours[<span class="dv">0</span>],</span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>                                      linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>    line_miscount_PT    <span class="op">=</span> axs[<span class="dv">0</span>].plot(x_plt, y_miscount_PT,</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a>                                      color <span class="op">=</span> plt_colours[<span class="dv">1</span>],</span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>                                      linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>    line_cost_SM        <span class="op">=</span> axs[<span class="dv">1</span>].plot(x_plt, y_cost_SM,</span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>                                      color <span class="op">=</span> plt_colours[<span class="dv">0</span>],</span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>                                      linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a>    line_cost_PT        <span class="op">=</span> axs[<span class="dv">1</span>].plot(x_plt, y_cost_PT,</span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a>                                      color <span class="op">=</span> plt_colours[<span class="dv">1</span>],</span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>                                      linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a>    <span class="co"># add labels</span></span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a>    <span class="co"># axs[0].set_xlabel(&#39;iteration&#39;, fontsize = font_size, **font_name)</span></span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].set_xlabel(<span class="st">&#39;iteration&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].set_ylabel(<span class="st">&#39;misclassifications&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb7-56"><a href="#cb7-56" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].set_xlabel(<span class="st">&#39;iteration&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb7-57"><a href="#cb7-57" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].set_ylabel(<span class="st">&#39;cost&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb7-58"><a href="#cb7-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-59"><a href="#cb7-59" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plot legend</span></span>
<span id="cb7-60"><a href="#cb7-60" aria-hidden="true" tabindex="-1"></a>    leg_labels <span class="op">=</span> [<span class="st">&#39;softmax&#39;</span>, <span class="st">&#39;perceptron&#39;</span>]</span>
<span id="cb7-61"><a href="#cb7-61" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].legend([line_miscount_SM, line_miscount_PT], labels <span class="op">=</span> leg_labels,</span>
<span id="cb7-62"><a href="#cb7-62" aria-hidden="true" tabindex="-1"></a>    loc <span class="op">=</span> <span class="st">&#39;upper right&#39;</span>, frameon <span class="op">=</span> <span class="dv">1</span>, fontsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb7-63"><a href="#cb7-63" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].legend([line_cost_SM, line_cost_PT], labels <span class="op">=</span> leg_labels,</span>
<span id="cb7-64"><a href="#cb7-64" aria-hidden="true" tabindex="-1"></a>                  loc <span class="op">=</span> <span class="st">&#39;upper right&#39;</span>, frameon <span class="op">=</span> <span class="dv">1</span>, fontsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb7-65"><a href="#cb7-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-66"><a href="#cb7-66" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code></pre></div>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co">### store data and plot</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># store plotting data in data frame</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>plot_data <span class="op">=</span> pd.DataFrame(</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;x_plt&quot;</span>: np.arange(np.size(miscount_history_SM)),</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_miscount_SM&quot;</span>: miscount_history_SM,</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_cost_SM&quot;</span>: cost_history_SM,</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_miscount_PT&quot;</span>: miscount_history_PT,</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_cost_PT&quot;</span>: cost_history_PT</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="co"># plot</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>plot_cost_and_miscount(plot_data)</span></code></pre></div>
</div>
<p>Below we identify and return the minimum number of misclassifications
for each cost function over all iterations of gradient descent.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co">### identify minima</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>min_misclass_SM <span class="op">=</span> <span class="bu">min</span>(miscount_history_SM)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>min_misclass_PT <span class="op">=</span> <span class="bu">min</span>(miscount_history_PT)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;softmax minimum misclassifications:    &quot;</span> <span class="op">+</span> <span class="bu">str</span>(min_misclass_SM))</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;perceptron minimum misclassifications: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(min_misclass_PT))</span></code></pre></div>
</div>
<p>Below we modify the <code>miscount</code> function to consider only misclassified
malignant cases (i.e., cases corresponding to the class label <span class="math inline">\(-1\)</span>).</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co">#### define misclassification rate</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autograd.numpy <span class="im">as</span> np</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># compute misclassification history</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> miscount_neg(w, x, y):</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># +1 or -1 whether above or below fitted decision bound determined by w</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> np.sign(model(x, w))</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># consider only malignant cases</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    miscount_curr <span class="op">=</span> np.<span class="bu">sum</span>(y_pred[y <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>] <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> miscount_curr</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a><span class="co"># compute new miscount history for each cost function</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>miscount_history_SM_neg <span class="op">=</span> [miscount_neg(v, x, y) <span class="cf">for</span> v <span class="kw">in</span> weight_history_SM]</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>miscount_history_PT_neg <span class="op">=</span> [miscount_neg(v, x, y) <span class="cf">for</span> v <span class="kw">in</span> weight_history_PT]</span></code></pre></div>
</div>
<p>Below we again plot misclassification and cost history side-by-side,
this time considering only misclassified malignant cases.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co">### store data and plot</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="co"># import pandas for data frame capabilities</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># store plotting data in data frame</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>plot_data <span class="op">=</span> pd.DataFrame(</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;x_plt&quot;</span>: np.arange(np.size(miscount_history_SM_neg)),</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_miscount_SM&quot;</span>: miscount_history_SM_neg,</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_cost_SM&quot;</span>: cost_history_SM,</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_miscount_PT&quot;</span>: miscount_history_PT_neg,</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_cost_PT&quot;</span>: cost_history_PT</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="co"># plot</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>plot_cost_and_miscount(plot_data)</span></code></pre></div>
</div>
<h2 data-number="1.5" id="logistic-regression-cross-entropy"><span class="header-section-number">1.5</span> Logistic regression &amp; cross-entropy</h2>
<p>In the following we compare the above results to those obtained using
logistic regression with a cross entropy cost.</p>
<p>The code below (ref) converts our class labels <code>y</code> = <span class="math inline">\(\{-1, 1\}\)</span> to
<span class="math inline">\(\{0, 1\}\)</span>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co">### setup dataset</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>y_1 <span class="op">=</span> np.squeeze(y) <span class="co"># flatten y (one dimension)</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>y_ben <span class="op">=</span> np.argwhere(y_1 <span class="op">&gt;</span> <span class="fl">0.9</span>) <span class="co"># returns all indices where y meets condition</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>y_mal <span class="op">=</span> np.argwhere(y_1 <span class="op">&lt;</span> <span class="op">-</span><span class="fl">0.9</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>yc <span class="op">=</span> np.arange(<span class="dv">699</span>) <span class="co"># class labels (`y`) for CE (cross-entropy) cost</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>yc[y_ben] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>yc[y_mal] <span class="op">=</span> <span class="dv">0</span></span></code></pre></div>
</div>
<p>The code below (ref) implements the cross entropy cost
function, with L2 regularization.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co">### define model and cross entropy cost</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="co"># define sigmoid function</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sigmoid(t):</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>t))</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co">## the (convex) cross-entropy cost function</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>lam <span class="op">=</span> <span class="dv">2</span><span class="op">*</span><span class="dv">10</span><span class="op">**</span>(<span class="op">-</span><span class="dv">3</span>) <span class="co"># regularization parameter</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> cross_entropy(w):</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute sigmoid of model</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    sig_eval <span class="op">=</span> sigmoid(model(x, w))</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute cost of label 0 points</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    ind_mal <span class="op">=</span> np.argwhere(yc <span class="op">==</span> <span class="dv">0</span>)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>    cost <span class="op">=</span> <span class="op">-</span>np.<span class="bu">sum</span>(np.log(<span class="dv">1</span> <span class="op">-</span> sig_eval[:, ind_mal]))</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># add (subtract) cost on label 1 points</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>    ind_ben <span class="op">=</span> np.argwhere(yc <span class="op">==</span> <span class="dv">1</span>)</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>    cost <span class="op">-=</span> np.<span class="bu">sum</span>(np.log(sig_eval[:, ind_ben]))</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># add regularizer (* regularization parameter)</span></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>    cost <span class="op">+=</span> lam<span class="op">*</span>np.<span class="bu">sum</span>(w[<span class="dv">1</span>:]<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute cross-entropy</span></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> cost<span class="op">/</span><span class="bu">float</span>(np.size(yc))</span></code></pre></div>
</div>
<p>Below we run gradient descent to optimize the cross entropy cost
function for logistic regression.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co">### optimize cost function using GD</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autograd.numpy <span class="im">as</span> np</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># define gradient descent parameters</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>max_its <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> <span class="fl">0.1</span><span class="op">*</span>np.random.randn(<span class="dv">9</span>, <span class="dv">1</span>) <span class="co"># initial starting weights</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co"># call GD (choose arb alpha for now bc based on chosen g)</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>weight_history_CE, cost_history_CE <span class="op">=</span> gradient_descent(cross_entropy, <span class="dv">1</span>,</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>                                                      max_its, w)</span></code></pre></div>
</div>
<p>We now compute misclassification history. To do so we must modify
<code>miscount</code> to compute misclassifications in a manner appropriate to
logistic regression. Since the sigmoid function varies between 0 and 1
and is symmetric (about a <span class="math inline">\(180^{\circ}\)</span> rotation centered at
<span class="math inline">\((0, 0.5)\)</span>), we can use <span class="math inline">\(y = 0.5\)</span> to effectively separate our
predictions into the two classes labelled <span class="math inline">\(\{0, 1\}\)</span>. Then, as before,
we can determine misclassiffications by comparing the predicted classes
across <code>weight_history</code> with the true class labels.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co">### compute misclassification history</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autograd.numpy <span class="im">as</span> np</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co"># compute misclassification history</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> miscount_CE(w, x, y):</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> np.sign(model(x, w))        <span class="co"># 1 or 1 if eval &gt; .5</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># convert predictions to classes based on y = .5 threshold  value</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>    y_pred[y_pred <span class="op">&gt;=</span> <span class="fl">.5</span>]    <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    y_pred[y_pred <span class="op">&lt;</span> <span class="fl">.5</span>]     <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># pairwise compare vectors: 1 if model class pred == true class; sum</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>    miscount_curr <span class="op">=</span> np.<span class="bu">sum</span>(y_pred <span class="op">!=</span> y)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> miscount_curr</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a><span class="co"># compute new miscount history for cross entropy cost</span></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>miscount_history_CE <span class="op">=</span> [miscount_CE(v, x, yc) <span class="cf">for</span> v <span class="kw">in</span> weight_history_CE]</span></code></pre></div>
</div>
<p>And finally, below we plot cost and misclassification history for the
logistic regression cross entropy cost, as we did above for the softmax
and perceptron cost functions (alongside the results for the perceptron
cost function). First we make a couple minor modifications to generalize
our plotting function and allow us to plot cross entropy cost in
addition to softmax cost.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb16"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co">### define plotting function</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_cost_and_miscount(data):</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># store data</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    x_plt           <span class="op">=</span> data[<span class="st">&quot;x_plt&quot;</span>]</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># y_miscount_1    = data[&quot;y_miscount_CE&quot;]</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># y_cost_1        = data[&quot;y_cost_CE&quot;]</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># y_miscount_2    = data[&quot;y_miscount_PT&quot;]</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># y_cost_2        = data[&quot;y_cost_PT&quot;]</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    y_miscount_1    <span class="op">=</span> data.iloc[:, <span class="dv">1</span>]</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>    y_cost_1        <span class="op">=</span> data.iloc[:, <span class="dv">2</span>]</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>    y_miscount_2    <span class="op">=</span> data.iloc[:, <span class="dv">3</span>]</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>    y_cost_2        <span class="op">=</span> data.iloc[:, <span class="dv">4</span>]</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># use seaborn style</span></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>    sns.set_theme()</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># to prevent warning messages from appearing in the report</span></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> warnings<span class="op">;</span></span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>    warnings.filterwarnings(<span class="st">&#39;ignore&#39;</span>)</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># set inline figure format/quality, overall params</span></span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># %config InlineBackend.figure_format = &#39;svg&#39;</span></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># setup plot &amp; subplots</span></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>    fig, axs <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>, figsize <span class="op">=</span> np.array([<span class="fl">6.5</span>, <span class="dv">8</span>]),</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>                            constrained_layout <span class="op">=</span> <span class="va">True</span>) <span class="co"># overall layout, size</span></span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># axs[0] = plt.subplot(1,3,(1,2), frameon = 1)</span></span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>] <span class="op">=</span> plt.subplot(<span class="dv">211</span>, frameon <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>] <span class="op">=</span> plt.subplot(<span class="dv">212</span>, frameon <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># set axis tick sizes</span></span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].xaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].yaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].xaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].yaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plot overlay of misclassifications &amp; costs for each cost over all it</span></span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a>    line_miscount_CE    <span class="op">=</span> axs[<span class="dv">0</span>].plot(x_plt, y_miscount_1,</span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a>                                      color <span class="op">=</span> plt_colours[<span class="dv">0</span>],</span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a>                                      linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a>    line_miscount_PT    <span class="op">=</span> axs[<span class="dv">0</span>].plot(x_plt, y_miscount_2,</span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a>                                      color <span class="op">=</span> plt_colours[<span class="dv">1</span>],</span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a>                                      linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a>    line_cost_CE        <span class="op">=</span> axs[<span class="dv">1</span>].plot(x_plt, y_cost_1,</span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a>                                      color <span class="op">=</span> plt_colours[<span class="dv">0</span>],</span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a>                                      linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb16-52"><a href="#cb16-52" aria-hidden="true" tabindex="-1"></a>    line_cost_PT        <span class="op">=</span> axs[<span class="dv">1</span>].plot(x_plt, y_cost_2,</span>
<span id="cb16-53"><a href="#cb16-53" aria-hidden="true" tabindex="-1"></a>                                      color <span class="op">=</span> plt_colours[<span class="dv">1</span>],</span>
<span id="cb16-54"><a href="#cb16-54" aria-hidden="true" tabindex="-1"></a>                                      linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb16-55"><a href="#cb16-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-56"><a href="#cb16-56" aria-hidden="true" tabindex="-1"></a>    <span class="co"># add labels</span></span>
<span id="cb16-57"><a href="#cb16-57" aria-hidden="true" tabindex="-1"></a>    <span class="co"># axs[0].set_xlabel(&#39;iteration&#39;, fontsize = font_size, **font_name)</span></span>
<span id="cb16-58"><a href="#cb16-58" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].set_xlabel(<span class="st">&#39;iteration&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb16-59"><a href="#cb16-59" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].set_ylabel(<span class="st">&#39;misclassifications&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb16-60"><a href="#cb16-60" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].set_xlabel(<span class="st">&#39;iteration&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb16-61"><a href="#cb16-61" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].set_ylabel(<span class="st">&#39;cost&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb16-62"><a href="#cb16-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-63"><a href="#cb16-63" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plot legend</span></span>
<span id="cb16-64"><a href="#cb16-64" aria-hidden="true" tabindex="-1"></a>    leg_labels <span class="op">=</span> [<span class="st">&#39;cross entropy&#39;</span>, <span class="st">&#39;perceptron&#39;</span>]</span>
<span id="cb16-65"><a href="#cb16-65" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].legend([line_miscount_CE, line_miscount_PT], labels <span class="op">=</span> leg_labels,</span>
<span id="cb16-66"><a href="#cb16-66" aria-hidden="true" tabindex="-1"></a>                  loc <span class="op">=</span> <span class="st">&#39;upper right&#39;</span>, frameon <span class="op">=</span> <span class="dv">1</span>, fontsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb16-67"><a href="#cb16-67" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].legend([line_cost_CE, line_cost_PT], labels <span class="op">=</span> leg_labels,</span>
<span id="cb16-68"><a href="#cb16-68" aria-hidden="true" tabindex="-1"></a>                  loc <span class="op">=</span> <span class="st">&#39;upper right&#39;</span>, frameon <span class="op">=</span> <span class="dv">1</span>, fontsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb16-69"><a href="#cb16-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-70"><a href="#cb16-70" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code></pre></div>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co">### store data and plot</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># store plotting data in data frame</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>plot_data <span class="op">=</span> pd.DataFrame(</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;x_plt&quot;</span>: np.arange(np.size(miscount_history_CE)),</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_miscount_CE&quot;</span>: miscount_history_CE,</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_cost_CE&quot;</span>: cost_history_CE,</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_miscount_PT&quot;</span>: miscount_history_PT,</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_cost_PT&quot;</span>: cost_history_PT</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="co"># plot</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>plot_cost_and_miscount(plot_data)</span></code></pre></div>
</div>
<h1 data-number="2" id="spam-detection"><span class="header-section-number">2</span> Spam detection</h1>
<p>In this problem we examinine the <a href="https://archive.ics.uci.edu/ml/datasets/Spambase">Spambase Data
Set</a> <a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>, containing
measurements of spam and non-spam emails. Using the two-class
classification methods we explored in the above sections, we build a
classifier to determine if an email is likely to be spam.</p>
<p><em>notes</em></p>
<p>Class labels (1 for ‘spam’, -1 for ‘not spam’) are again stored in the
final row (<span class="math inline">\(N = 58\)</span>) of the dataset, with each other row <span class="math inline">\(n\)</span>
representing a feature (word/character frequencies, etc.) and each
column <span class="math inline">\(p\)</span> a sample (<span class="math inline">\(P = 4601\)</span>).</p>
<p>Below we import the dataset.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co">### import dataset</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co"># data input</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>csvname <span class="op">=</span> <span class="st">&#39;data/spambase_data.csv&#39;</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.loadtxt(csvname, delimiter <span class="op">=</span> <span class="st">&#39;,&#39;</span>)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co"># get input and output of dataset</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> data[:<span class="op">-</span><span class="dv">1</span>, :]    <span class="co"># feature vectors</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data[<span class="op">-</span><span class="dv">1</span>:, :]    <span class="co"># class labels {1,-1}</span></span></code></pre></div>
</div>
<h2 data-number="2.1" id="some-basic-preprocessing"><span class="header-section-number">2.1</span> Some basic preprocessing</h2>
<p>We now perform some preproc`essing to prepare the dataset for our
analysis. We standard normalize each feature (s.t. <span class="math inline">\(\mu_n = 0\)</span> and
<span class="math inline">\(\sigma_n = 1\)</span>, where <span class="math inline">\(\mu\)</span> represents the mean and <span class="math inline">\(\sigma\)</span> the
standard deviation) so that they can be treated equally by our
classifier. To do so, for each observation <span class="math inline">\(x_{n,p}\)</span> we subtract the
corresponding mean <span class="math inline">\(\mu_n\)</span> and divide by the corresponding standard
deviation <span class="math inline">\(\sigma_n\)</span>.</p>
<p>To deal with missing observations for a given feature (represented as
<code>NaN</code>), we replace <code>NaN</code> with the corresponding feature mean <span class="math inline">\(\mu_n\)</span>.</p>
<p>The following function (ref) executes the above.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb19"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co">### perform standard normalization and fill in missing data</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> standard_normalizer(x):</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute the mean and standard deviation of each feature</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    x_means <span class="op">=</span> np.nanmean(x, axis <span class="op">=</span> <span class="dv">1</span>)[:, np.newaxis]</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    x_stds  <span class="op">=</span> np.nanstd(x, axis <span class="op">=</span> <span class="dv">1</span>)[:, np.newaxis]</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># check to make sure that x_stds &gt; small threshold; for those not</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># divide by 1 instead of original standard deviation</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>    ind <span class="op">=</span> np.argwhere(x_stds <span class="op">&lt;</span> <span class="dv">10</span><span class="op">**</span>(<span class="op">-</span><span class="dv">2</span>))</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(ind) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>        ind <span class="op">=</span> [v[<span class="dv">0</span>] <span class="cf">for</span> v <span class="kw">in</span> ind] <span class="co"># just keep row index</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>        adjust <span class="op">=</span> np.zeros((x_stds.shape)) <span class="co"># array of indices to replace with 1</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>        adjust[ind] <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>        x_stds <span class="op">+=</span> adjust</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># fill in any nan values with corresponding feature mean</span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>    ind <span class="op">=</span> np.argwhere(np.isnan(x) <span class="op">==</span> <span class="va">True</span>)</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> ind:</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>        x[i[<span class="dv">0</span>], i[<span class="dv">1</span>]] <span class="op">=</span> x_means[i[<span class="dv">0</span>]]</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># create standard normalizer function</span></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>    normalizer <span class="op">=</span> <span class="kw">lambda</span> data: (data <span class="op">-</span> x_means)<span class="op">/</span>x_stds</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># create inverse standard normalizer</span></span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>    inverse_normalizer <span class="op">=</span> <span class="kw">lambda</span> data: data<span class="op">*</span>x_stds <span class="op">+</span> x_means</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># return (inverse) normalizer</span></span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> normalizer, inverse_normalizer</span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a><span class="co">## standard normalize dataset</span></span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>normalizer, inverse_normalizer <span class="op">=</span> standard_normalizer(x) <span class="co"># get std norm functions</span></span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> normalizer(x)</span></code></pre></div>
</div>
<h2 data-number="2.2" id="email-classification-with-perceptron"><span class="header-section-number">2.2</span> Email classification with perceptron</h2>
<p>In the following we classify emails using the softmax and perceptron
cost functions.</p>
<p><strong>Steps:</strong></p>
<p>We carry out the same sequence of steps covered in detail in part 1:</p>
<ol type="1">
<li><p>Identify optimal decision boundary (determined by weights <span class="math inline">\(w\)</span>):</p>
<ul>
<li>run gradient descent to identify <span class="math inline">\(w\)</span> that minimizes cost
functions</li>
<li>softmax: <span class="math inline">\(\alpha = 1.0\)</span>; perceptron: <span class="math inline">\(\alpha = 0.1\)</span></li>
<li>other parameters: <code>max its = 1000</code>;
<code>w = 0.1*np.random.randn(N + 1, 1)</code>, where <span class="math inline">\(N = 57\)</span></li>
</ul></li>
<li><p>Compute misclassification histories</p></li>
<li><p>Plot cost and misclassification as a function of gradient descent
iteration</p></li>
</ol>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb20"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co">### 1) optimize softmax and perceptron costs over `spambase` dataset</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autograd.numpy <span class="im">as</span> np</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="co"># define gradient descent parameters</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>max_its <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> <span class="fl">0.1</span><span class="op">*</span>np.random.randn(np.shape(x)[<span class="dv">0</span>] <span class="op">+</span> <span class="dv">1</span>, <span class="dv">1</span>) <span class="co"># initial starting weights</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="co"># call GD (choose arb alpha for now bc based on chosen g)</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>weight_history_SM_spam, cost_history_SM_spam <span class="op">=</span> gradient_descent(softmax, <span class="dv">1</span>,</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>                                                        max_its, w)</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>weight_history_PT_spam, cost_history_PT_spam <span class="op">=</span> gradient_descent(perceptron, <span class="dv">1</span>,</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>                                                        max_its, w)</span></code></pre></div>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co">### 2) compute misclassification history for each cost function</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>miscount_history_SM_spam <span class="op">=</span> [miscount(v, x, y) <span class="cf">for</span> v <span class="kw">in</span> weight_history_SM_spam]</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>miscount_history_PT_spam <span class="op">=</span> [miscount(v, x, y) <span class="cf">for</span> v <span class="kw">in</span> weight_history_PT_spam]</span></code></pre></div>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb22"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co">### 3) for each cost, plot cost and misclassification as a function of iteration</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="co">## store data and plot</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="co"># store plotting data in data frame</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>plot_data <span class="op">=</span> pd.DataFrame(</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;x_plt&quot;</span>: np.arange(np.size(miscount_history_SM_spam)),</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_miscount_SM&quot;</span>: miscount_history_SM_spam,</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_cost_SM&quot;</span>: cost_history_SM_spam,</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_miscount_PT&quot;</span>: miscount_history_PT_spam,</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_cost_PT&quot;</span>: cost_history_PT_spam</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="co">## plot</span></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>plot_cost_and_miscount(plot_data)</span></code></pre></div>
</div>
<p>The plots above reveal some interesting results. The perceptron cost
appears to attain a stable minimum cost, but its misclassification
history appears to fluctuate rapidly between ~250 and 750
misclassifications. On the other hand, the softmax cost appears to
attain a stable, albeit higher, minimum cost, but its misclassification
history reaches a similar minimum to the softmax cost and is stable
(does not fluctate rapidly). This suggests that the perceptron cost
function is not perfectly flat at the identified minimum, causing minor
perturbations in weight to produce large deviations from the minimum. It
is possible that different (non-standard) gradient descent schemes
(e.g., fully normalized) would eliminate this behaviour.</p>
<h2 data-number="2.3" id="accuracy"><span class="header-section-number">2.3</span> Accuracy</h2>
<p>In the following we determine the misclassification minimum and convert
it to accuracy.</p>
<p><em>Recall</em>: we define accuracy, <span class="math inline">\(\mathcal{A}\)</span> as</p>
<p><span class="math display">\[
\mathcal{A} = 1 - \frac{1}{P} \sum\limits_{p = 1}^P I(\hat{y}_p, y_p) ,
\]</span></p>
<p>where <span class="math inline">\(\sum\limits_{p = 1}^P I\)</span> represents total misclassifications,
which we average over all samples <span class="math inline">\(P\)</span> and subtract from 1.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb23"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co">### determine minimum misclassifications for each cost and convert to accuracy</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="co"># identify minima</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>min_misclass_SM_spam <span class="op">=</span> <span class="bu">min</span>(miscount_history_SM_spam)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>min_misclass_PT_spam <span class="op">=</span> <span class="bu">min</span>(miscount_history_PT_spam)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;softmax minimum misclassifications:    &quot;</span> <span class="op">+</span> <span class="bu">str</span>(min_misclass_SM_spam))</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;perceptron minimum misclassifications: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(min_misclass_PT_spam))</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="co"># convert to accuracies</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>accuracy_SM_spam <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> (min_misclass_SM_spam)<span class="op">/</span>np.shape(x)[<span class="dv">1</span>]</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>accuracy_PT_spam <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> (min_misclass_PT_spam)<span class="op">/</span>np.shape(x)[<span class="dv">1</span>]</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">softmax accuracy:    &quot;</span> <span class="op">+</span> <span class="bu">str</span>(accuracy_SM_spam))</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;perceptron accuracy: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(accuracy_PT_spam))</span></code></pre></div>
</div>
<p>As we can see above, both classifiers, trained using a softmax and
perceptron cost, respectively, appear to perform relatively well, with
accuracies above 90%. However, softmax cost performs slighly better,
with 3 fewer misclassifications than the perceptron. This result
reflects our expectations based on the misclassification and cost
histories plotted above.</p>
<h2 data-number="2.4" id="confusion-matrix"><span class="header-section-number">2.4</span> Confusion matrix</h2>
<p>In the following we identify the optimal <code>w</code> found by the softmax cost
and construct the corresponding confusion matrix <a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co">### construct confusion matrix for optimal softmax `w`</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="co">## define model again (compute linear combination of input points)</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> model(x, w):</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    a <span class="op">=</span> w[<span class="dv">0</span>] <span class="op">+</span> np.dot(x.T, w[<span class="dv">1</span>:])</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> a.T</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a><span class="co">## identify optimal `w` for cost</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>w_optimal_SM_spam <span class="op">=</span> weight_history_SM_spam[np.argmin(miscount_history_SM_spam)]</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a><span class="co"># w_optimal_PT_spam = weight_history_PT_spam[np.argmin(miscount_history_PT_spam)]</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a><span class="co">### function for plotting confusion matrix</span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_confusion_matrix(w, x, y):</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># +1 or -1 whether above or below fitted decision bound determined by w</span></span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> np.sign(model(x, w))</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>    <span class="co">## determine confusion matrix values (true pos/neg, false pos/neg)</span></span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>    TP <span class="op">=</span> np.<span class="bu">sum</span>(y_pred[y <span class="op">==</span> <span class="dv">1</span>] <span class="op">==</span> <span class="dv">1</span>)</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>    TN <span class="op">=</span> np.<span class="bu">sum</span>(y_pred[y <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>] <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>    FP <span class="op">=</span> np.<span class="bu">sum</span>(y_pred[y <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>] <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>    FN <span class="op">=</span> np.<span class="bu">sum</span>(y_pred[y <span class="op">==</span> <span class="dv">1</span>] <span class="op">!=</span> <span class="dv">1</span>)</span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># store values in dictionary, matrix for plotting</span></span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>    confusion_matrix_OP <span class="op">=</span> {<span class="st">&quot;TP&quot;</span>: TP, <span class="st">&quot;TN&quot;</span>: TN, <span class="st">&quot;FP&quot;</span>: FP, <span class="st">&quot;FN&quot;</span>: FN}</span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># confusion_matrix_OP[&quot;TN&quot;] = TN</span></span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a>    conf_matrix <span class="op">=</span> np.array([[TP, FN],</span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a>                            [FP, TN]])</span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a>    <span class="co">## plot confusion matrix</span></span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># set annotations for tiles based on counts</span></span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a>    group_names <span class="op">=</span> [<span class="st">&#39;TP&#39;</span>, <span class="st">&#39;FN&#39;</span>, <span class="st">&#39;FP&#39;</span>, <span class="st">&#39;TN&#39;</span>]</span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a>    group_counts <span class="op">=</span> [<span class="st">&quot;</span><span class="sc">{0:0.0f}</span><span class="st">&quot;</span>.<span class="bu">format</span>(value) <span class="cf">for</span> value <span class="kw">in</span> conf_matrix.flatten()]</span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a>    group_percentages <span class="op">=</span> [<span class="st">&quot;</span><span class="sc">{0:.2%}</span><span class="st">&quot;</span>.<span class="bu">format</span>(value) <span class="cf">for</span> value <span class="kw">in</span></span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a>                         conf_matrix.flatten()<span class="op">/</span>np.<span class="bu">sum</span>(conf_matrix)]</span>
<span id="cb24-39"><a href="#cb24-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-40"><a href="#cb24-40" aria-hidden="true" tabindex="-1"></a>    tile_labels <span class="op">=</span> [<span class="ss">f&quot;</span><span class="sc">{</span>v1<span class="sc">}</span><span class="ch">\n</span><span class="sc">{</span>v2<span class="sc">}</span><span class="ch">\n</span><span class="sc">{</span>v3<span class="sc">}</span><span class="ss">&quot;</span> <span class="cf">for</span> v1, v2, v3 <span class="kw">in</span></span>
<span id="cb24-41"><a href="#cb24-41" aria-hidden="true" tabindex="-1"></a>                   <span class="bu">zip</span>(group_names, group_counts, group_percentages)]</span>
<span id="cb24-42"><a href="#cb24-42" aria-hidden="true" tabindex="-1"></a>    tile_labels <span class="op">=</span> np.asarray(tile_labels).reshape(<span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb24-43"><a href="#cb24-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-44"><a href="#cb24-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plot</span></span>
<span id="cb24-45"><a href="#cb24-45" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> sns.heatmap(conf_matrix, annot <span class="op">=</span> tile_labels, fmt <span class="op">=</span> <span class="st">&#39;&#39;</span>, cmap <span class="op">=</span> <span class="st">&#39;Blues&#39;</span>)</span>
<span id="cb24-46"><a href="#cb24-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-47"><a href="#cb24-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># labels</span></span>
<span id="cb24-48"><a href="#cb24-48" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">Predicted Values&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb24-49"><a href="#cb24-49" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">&#39;Actual Values</span><span class="ch">\n</span><span class="st">&#39;</span>, fontsize <span class="op">=</span> font_size)<span class="op">;</span></span>
<span id="cb24-50"><a href="#cb24-50" aria-hidden="true" tabindex="-1"></a>    ax.xaxis.set_ticklabels([<span class="st">&#39;Spam&#39;</span>, <span class="st">&#39;Not spam&#39;</span>], fontsize <span class="op">=</span> font_size)</span>
<span id="cb24-51"><a href="#cb24-51" aria-hidden="true" tabindex="-1"></a>    ax.yaxis.set_ticklabels([<span class="st">&#39;Spam&#39;</span>, <span class="st">&#39;Not spam&#39;</span>], fontsize <span class="op">=</span> font_size)</span>
<span id="cb24-52"><a href="#cb24-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-53"><a href="#cb24-53" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb24-54"><a href="#cb24-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-55"><a href="#cb24-55" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> confusion_matrix_OP</span>
<span id="cb24-56"><a href="#cb24-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-57"><a href="#cb24-57" aria-hidden="true" tabindex="-1"></a><span class="co">## plot confusion matrix for softmax and optimal weight</span></span>
<span id="cb24-58"><a href="#cb24-58" aria-hidden="true" tabindex="-1"></a>confusion_matrix <span class="op">=</span> plot_confusion_matrix(w_optimal_SM_spam, x, y)</span></code></pre></div>
</div>
<h1 data-number="3" id="credit-check"><span class="header-section-number">3</span> Credit check</h1>
<p>In this problem we examinine a dataset containing credit ratings,
described in Example 6.11 of <em>Machine Learning Refined</em>.</p>
<p><em>notes</em></p>
<ul>
<li>Class labels (1 for ‘good rating’, -1 for ‘bad rating’) are again
stored in the final row of the dataset (<span class="math inline">\(N = 20\)</span>), with each other
row <span class="math inline">\(n\)</span> representing a feature (account balance, duration of
previous credit, etc.) and each column <span class="math inline">\(p\)</span> a sample (<span class="math inline">\(P = 1000\)</span>).</li>
</ul>
<p>Below we import the dataset.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb25"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co">### import dataset</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="co"># data input</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>csvname <span class="op">=</span> <span class="st">&#39;data/credit_dataset.csv&#39;</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.loadtxt(csvname, delimiter <span class="op">=</span> <span class="st">&#39;,&#39;</span>)</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="co"># get input and output of dataset</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> data[:<span class="op">-</span><span class="dv">1</span>, :]    <span class="co"># feature vectors</span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data[<span class="op">-</span><span class="dv">1</span>:, :]    <span class="co"># class labels {1,-1}</span></span></code></pre></div>
</div>
<h2 data-number="3.1" id="standard-normalization"><span class="header-section-number">3.1</span> Standard normalization</h2>
<p>Below we standard normalize the dataset so that features can be
compared.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb26"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co">### perform standard normalization</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>normalizer, inverse_normalizer <span class="op">=</span> standard_normalizer(x) <span class="co"># get std norm functions</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> normalizer(x)</span></code></pre></div>
</div>
<h2 data-number="3.2" id="fitting-perceptron-based-classifier"><span class="header-section-number">3.2</span> Fitting perceptron-based classifier</h2>
<p>Below we fit a binary classifier using a perceptron cost.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb27"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co">### optimize perceptron cost over `credit rating` dataset</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autograd.numpy <span class="im">as</span> np</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="co"># define gradient descent parameters</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>max_its <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> <span class="fl">0.1</span><span class="op">*</span>np.random.randn(np.shape(x)[<span class="dv">0</span>] <span class="op">+</span> <span class="dv">1</span>, <span class="dv">1</span>) <span class="co"># initial starting weights</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="co"># call GD (choose arb alpha for now bc based on chosen g)</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>weight_history_PT_cred, cost_history_PT_cred <span class="op">=</span> gradient_descent(perceptron, <span class="dv">1</span>,</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>                                                        max_its, w)</span></code></pre></div>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb28"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co">### compute misclassification history</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>miscount_history_PT_cred <span class="op">=</span> [miscount(v, x, y) <span class="cf">for</span> v <span class="kw">in</span> weight_history_PT_cred]</span></code></pre></div>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb29"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co">### store data for plotting</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="co"># store plotting data</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>x_plt <span class="op">=</span> np.arange(np.size(miscount_history_PT_cred))</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>y_miscount_PT <span class="op">=</span> miscount_history_PT_cred</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>y_cost_PT <span class="op">=</span> cost_history_PT_cred</span></code></pre></div>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb30"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co">### plot cost and misclassification history for perceptron cost</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a><span class="co"># use seaborn style</span></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>sns.set_theme()</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a><span class="co"># to prevent warning messages from appearing in the report</span></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings<span class="op">;</span></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">&#39;ignore&#39;</span>)</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a><span class="co"># set inline figure format/quality, overall params</span></span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a><span class="co"># %config InlineBackend.figure_format = &#39;svg&#39;</span></span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a><span class="co"># setup plot &amp; subplots</span></span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>, figsize <span class="op">=</span> np.array([<span class="fl">6.5</span>, <span class="dv">8</span>]),</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>                        constrained_layout <span class="op">=</span> <span class="va">True</span>) <span class="co"># overall layout, size</span></span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a><span class="co"># axs[0] = plt.subplot(1,3,(1,2), frameon = 1)</span></span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>] <span class="op">=</span> plt.subplot(<span class="dv">211</span>, frameon <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>] <span class="op">=</span> plt.subplot(<span class="dv">212</span>, frameon <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a><span class="co"># set axis tick sizes</span></span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].xaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].yaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].xaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].yaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb30-29"><a href="#cb30-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-30"><a href="#cb30-30" aria-hidden="true" tabindex="-1"></a><span class="co"># plot overlay of misclassifications &amp; costs for each cost over all it</span></span>
<span id="cb30-31"><a href="#cb30-31" aria-hidden="true" tabindex="-1"></a>line_miscount_CE    <span class="op">=</span> axs[<span class="dv">0</span>].plot(x_plt, y_miscount_PT,</span>
<span id="cb30-32"><a href="#cb30-32" aria-hidden="true" tabindex="-1"></a>                                  color <span class="op">=</span> plt_colours[<span class="dv">0</span>],</span>
<span id="cb30-33"><a href="#cb30-33" aria-hidden="true" tabindex="-1"></a>                                  linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb30-34"><a href="#cb30-34" aria-hidden="true" tabindex="-1"></a>line_cost_CE        <span class="op">=</span> axs[<span class="dv">1</span>].plot(x_plt, y_cost_PT,</span>
<span id="cb30-35"><a href="#cb30-35" aria-hidden="true" tabindex="-1"></a>                                  color <span class="op">=</span> plt_colours[<span class="dv">0</span>],</span>
<span id="cb30-36"><a href="#cb30-36" aria-hidden="true" tabindex="-1"></a>                                  linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb30-37"><a href="#cb30-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-38"><a href="#cb30-38" aria-hidden="true" tabindex="-1"></a><span class="co"># add labels</span></span>
<span id="cb30-39"><a href="#cb30-39" aria-hidden="true" tabindex="-1"></a><span class="co"># axs[0].set_xlabel(&#39;iteration&#39;, fontsize = font_size, **font_name)</span></span>
<span id="cb30-40"><a href="#cb30-40" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].set_xlabel(<span class="st">&#39;iteration&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb30-41"><a href="#cb30-41" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].set_ylabel(<span class="st">&#39;misclassifications&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb30-42"><a href="#cb30-42" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].set_xlabel(<span class="st">&#39;iteration&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb30-43"><a href="#cb30-43" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].set_ylabel(<span class="st">&#39;cost&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb30-44"><a href="#cb30-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-45"><a href="#cb30-45" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb31"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co">### compute and output perceptron accuracy</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>min_misclass_PT_cred <span class="op">=</span> <span class="bu">min</span>(miscount_history_PT_cred)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>accuracy_PT_cred <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> (min_misclass_PT_cred)<span class="op">/</span>np.shape(x)[<span class="dv">1</span>]</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;perceptron accuracy: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(accuracy_PT_cred))</span></code></pre></div>
</div>
<p>The perceptron achieves a classification accuracy of ~76%, which is
within the range of the accuracy achieved in <em>Machine Learning Refined</em>.</p>
<h2 data-number="3.3" id="confusion-matrix-1"><span class="header-section-number">3.3</span> Confusion matrix</h2>
<p>We now plot the confusion matrix corresponding to the optimal weight
identified by the perceptron.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb32"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co">### plot confusion matrix for perceptron and optimal weight</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>w_optimal_PT_cred <span class="op">=</span> weight_history_PT_cred[np.argmin(miscount_history_PT_cred)]</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>confusion_matrix <span class="op">=</span> plot_confusion_matrix(w_optimal_PT_cred, x, y)</span></code></pre></div>
</div>
<h1 data-number="4" id="three-class-classification"><span class="header-section-number">4</span> Three-class classification</h1>
<p>In this problem we examine a three-class toy dataset, shown in Fig. 7.9
of <em>Machine Learning Refined</em>, using the multi-class perceptron.
Additional resources (including plotting functions) are provided in the
official ‘MLR’ git repository <a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>.</p>
<h2 data-number="4.1" id="fitting-multi-class-perceptron"><span class="header-section-number">4.1</span> Fitting multi-class perceptron</h2>
<p>Below we fit the multi-class perceptron to the dataset.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb34"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co">### import dataset &amp; standard normalize</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="co"># data input</span></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>csvname <span class="op">=</span> <span class="st">&#39;data/3class_data.csv&#39;</span></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.loadtxt(csvname, delimiter <span class="op">=</span> <span class="st">&#39;,&#39;</span>)</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a><span class="co"># get input and output of dataset</span></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> data[:<span class="op">-</span><span class="dv">1</span>, :]    <span class="co"># feature vectors</span></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data[<span class="op">-</span><span class="dv">1</span>:, :]    <span class="co"># class labels {1,-1}</span></span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a><span class="co">## normalize</span></span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>normalizer, inverse_normalizer <span class="op">=</span> standard_normalizer(x) <span class="co"># get std norm functions</span></span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> normalizer(x)</span></code></pre></div>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co">### define model and multi-class perceptron (ref)</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="co">## compute C linear combinations of input point, one per classifier</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> model(x, w):</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>    a <span class="op">=</span> w[<span class="dv">0</span>] <span class="op">+</span> np.dot(x.T, w[<span class="dv">1</span>:])</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> a.T</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a><span class="co">## multi-class perceptron</span></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>lam <span class="op">=</span> <span class="dv">10</span><span class="op">**-</span><span class="dv">5</span>  <span class="co"># regularization paramter</span></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> multiclass_perceptron(w):</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># pre-compute predictions on all points</span></span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>    all_evals <span class="op">=</span> model(x, w)</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute maximum across data points</span></span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>    a <span class="op">=</span> np.<span class="bu">max</span>(all_evals, axis <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute cost in compact form using numpy broadcasting</span></span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>    b <span class="op">=</span> all_evals[y.astype(<span class="bu">int</span>).flatten(), np.arange(np.size(y))]</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>    cost <span class="op">=</span> np.<span class="bu">sum</span>(a <span class="op">-</span> b)</span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># add regularizer</span></span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>    cost <span class="op">=</span> cost <span class="op">+</span> lam<span class="op">*</span>np.linalg.norm(w[<span class="dv">1</span>:, :], <span class="st">&#39;fro&#39;</span>)<span class="op">**</span><span class="dv">2</span></span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># return average</span></span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> cost<span class="op">/</span><span class="bu">float</span>(np.size(y))</span></code></pre></div>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb36"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co">### fit multi-class perceptron</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autograd.numpy <span class="im">as</span> np</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a><span class="co"># define gradient descent parameters</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>max_its <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> <span class="fl">0.1</span><span class="op">*</span>np.random.randn(<span class="dv">3</span>, <span class="dv">3</span>) <span class="co"># initial starting weights</span></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a><span class="co"># call GD (choose arb alpha for now bc based on chosen g)</span></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>weight_history_3CPT, cost_history_3CPT <span class="op">=</span> gradient_descent(</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>    multiclass_perceptron, <span class="fl">.1</span>, max_its, w)</span></code></pre></div>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb37"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co">### plot cost history</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="co">## store data</span></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>x_plt <span class="op">=</span> np.arange(np.shape(weight_history_3CPT)[<span class="dv">0</span>])</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>y_cost_3CPT <span class="op">=</span> cost_history_3CPT</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a><span class="co">## plot</span></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_cost_history(x, y):</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># use seaborn style</span></span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>    sns.set_theme()</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># setup plot</span></span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize <span class="op">=</span> np.array([<span class="dv">5</span>, <span class="dv">5</span>]),</span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a>                            constrained_layout <span class="op">=</span> <span class="va">True</span>) <span class="co"># overall layout, size</span></span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> plt.subplot(<span class="dv">111</span>, frameon <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># set axis tick sizes</span></span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a>    ax.xaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a>    ax.yaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plot cost history</span></span>
<span id="cb37-26"><a href="#cb37-26" aria-hidden="true" tabindex="-1"></a>    y_cost_3CPT <span class="op">=</span> ax.plot(x, y, color <span class="op">=</span> plt_colours[<span class="dv">0</span>],</span>
<span id="cb37-27"><a href="#cb37-27" aria-hidden="true" tabindex="-1"></a>                        linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb37-28"><a href="#cb37-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-29"><a href="#cb37-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># add labels</span></span>
<span id="cb37-30"><a href="#cb37-30" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="st">&#39;iteration&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb37-31"><a href="#cb37-31" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">&#39;cost&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb37-32"><a href="#cb37-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-33"><a href="#cb37-33" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb37-34"><a href="#cb37-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-35"><a href="#cb37-35" aria-hidden="true" tabindex="-1"></a>plot_cost_history(x_plt, y_cost_3CPT)</span></code></pre></div>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb38"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>weight_history_3CPT[<span class="dv">1</span>]</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>model(x, w)</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>np.shape(model(x, w))</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>all_evals <span class="op">=</span> model(x, weight_history_3CPT[<span class="dv">1</span>])</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>np.shape(all_evals)</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>np.shape(np.<span class="bu">max</span>(all_evals, axis <span class="op">=</span> <span class="dv">0</span>))</span></code></pre></div>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb39"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co">### define new function to compute multi-class misclassification history</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> miscount_3CPT(w, x, y):</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 0-2 based on weight that maximizes prediction</span></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># y_pred = np.argmax(np.abs(model(x, w), axis = 0), axis = 0)</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute prediction for all points</span></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>    all_evals <span class="op">=</span> model(x, w)</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># assign point class of DB that maximumizes distance to DB</span></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> np.argmax(all_evals, axis <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># pairwise compare vectors: 1 if model class pred == true class; sum</span></span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>    miscount_curr <span class="op">=</span> np.<span class="bu">sum</span>(y_pred <span class="op">!=</span> y)</span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> miscount_curr</span></code></pre></div>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb40"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co">### compute accuracy for optimal weight (minimum misclassifications)</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="co"># compute misclassifications</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>miscount_history_3CPT <span class="op">=</span> [miscount_3CPT(v, x, y) <span class="cf">for</span> v <span class="kw">in</span> weight_history_3CPT]</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a><span class="co"># find minimum misclassifications and convert to accuracy</span></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>min_misclass_3CPT <span class="op">=</span> <span class="bu">min</span>(miscount_history_3CPT)</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;multi-class perceptron minimum misclassifications: &quot;</span></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>      <span class="op">+</span> <span class="bu">str</span>(min_misclass_3CPT))</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a><span class="co"># convert to accuracies</span></span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>accuracy_3CPT <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> (min_misclass_3CPT)<span class="op">/</span>np.shape(x)[<span class="dv">1</span>]</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;multi-class perceptron accuracy: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(accuracy_3CPT))</span></code></pre></div>
</div>
<h2 data-number="4.2" id="plotting-the-decision-boundary"><span class="header-section-number">4.2</span> Plotting the decision boundary</h2>
<p>Below we plot the data in the plane, along with the decision boundary
obtained by the multi-class perceptron.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb41"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># code to clone library from git repo subdirectory</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="co"># (from Ciro Santilli @ https://stackoverflow.com/questions/600079/how-do-i-clone-a-subdirectory-only-of-a-git-repository)</span></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="co"># git clone \</span></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="co">#     --depth 1  \</span></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a><span class="co">#     --filter=blob:none  \</span></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="co">#     --sparse \</span></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a><span class="co">#     https://github.com/jermwatt/machine_learning_refined \</span></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a><span class="co"># ;</span></span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a><span class="co"># cd machine_learning_refined</span></span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a><span class="co"># git sparse-checkout set mlrefined_libraries</span></span></code></pre></div>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode" id="cb42"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co">### plot data and decision boundary</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="co"># import relevant MLR plotting libraries (store lib in current dir)</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mlrefined_libraries <span class="im">import</span> superlearn_library <span class="im">as</span> superlearn</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mlrefined_libraries <span class="im">import</span> math_optimization_library <span class="im">as</span> optlib</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>optimizers      <span class="op">=</span> optlib.optimizers</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>classif_plotter <span class="op">=</span> superlearn.multi_lin_classification_demo</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>cost_lib        <span class="op">=</span> superlearn.cost_functions</span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>normalizers     <span class="op">=</span> superlearn.normalizers</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a><span class="co"># store std. normalized dataset to pass to function (colours = class labels)</span></span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>data_norm <span class="op">=</span> np.append(x, y, axis <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>data_norm[<span class="op">-</span><span class="dv">1</span>,<span class="dv">0</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a><span class="co"># plot individual data points in plane</span></span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a>demo <span class="op">=</span> superlearn.multiclass_illustrator.Visualizer(data_norm)</span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a>demo.show_dataset()</span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a><span class="co"># add DBs (pass weights defining 3 class DBs that give perfect accuracy)</span></span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a>demo.show_complete_coloring([weight_history_3CPT[<span class="op">-</span><span class="dv">1</span>]], cost <span class="op">=</span> </span>
<span id="cb42-21"><a href="#cb42-21" aria-hidden="true" tabindex="-1"></a>                            multiclass_perceptron)</span></code></pre></div>
</div>
<p>The multi-class perceptron achieves a classification accuracy of 100%,
yielding results that are comparable to those shown in <em>Machine Learning
Refined</em>.</p>
<div style="page-break-after: always;"></div>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>Wolberg, W. H., Street, W. N., &amp; Mangasarian, O. L. (1992). Breast
Cancer Dataset. <em>University of Wisconsin Hospitals, Madison</em>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Dua, D. and Graff, C. (2019). UCI Machine Learning Repository
<a href="http://archive.ics.uci.edu/ml%5D.">[http://archive.ics.uci.edu/ml].</a>
Irvine, CA: University of California, School of Information and
Computer Science.<br />
<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Watt, J., Borhani, R., &amp; Katsaggelos, A. K. (2020). Machine
learning refined: Foundations, algorithms, and applications.
Cambridge University Press.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p><a href="https://github.com/jermwatt/machine_learning_refined/tree/gh-pages/notes/7_Linear_multiclass_classification" class="uri">https://github.com/jermwatt/machine_learning_refined/tree/gh-pages/notes/7_Linear_multiclass_classification</a></p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></li>
</ol>
</section>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom">
  <h3 id="references">References</h3>
  <div id="references-listing"></div>
</div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
