<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Matthew Bain" />


<title>Two- &amp; multi-class classification in Python</title>

<script src="site_libs/header-attrs-2.16/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
<link rel="shortcut icon" href="favicon.jpg">

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>



<style type="text/css">
  code {
    white-space: pre;
  }
  .sourceCode {
    overflow: visible;
  }
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    background-color: #ffffff;
    color: #a0a0a0;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #a0a0a0;  padding-left: 4px; }
div.sourceCode
  { color: #1f1c1b; background-color: #ffffff; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span { color: #1f1c1b; } /* Normal */
code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
code span.an { color: #ca60ca; } /* Annotation */
code span.at { color: #0057ae; } /* Attribute */
code span.bn { color: #b08000; } /* BaseN */
code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
code span.ch { color: #924c9d; } /* Char */
code span.cn { color: #aa5500; } /* Constant */
code span.co { color: #898887; } /* Comment */
code span.cv { color: #0095ff; } /* CommentVar */
code span.do { color: #607880; } /* Documentation */
code span.dt { color: #0057ae; } /* DataType */
code span.dv { color: #b08000; } /* DecVal */
code span.er { color: #bf0303; text-decoration: underline; } /* Error */
code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
code span.fl { color: #b08000; } /* Float */
code span.fu { color: #644a9b; } /* Function */
code span.im { color: #ff5500; } /* Import */
code span.in { color: #b08000; } /* Information */
code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
code span.op { color: #1f1c1b; } /* Operator */
code span.ot { color: #006e28; } /* Other */
code span.pp { color: #006e28; } /* Preprocessor */
code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
code span.sc { color: #3daee9; } /* SpecialChar */
code span.ss { color: #ff5500; } /* SpecialString */
code span.st { color: #bf0303; } /* String */
code span.va { color: #0057ae; } /* Variable */
code span.vs { color: #bf0303; } /* VerbatimString */
code span.wa { color: #bf0303; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<link rel="stylesheet" href="generic-css.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">fujinai</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    data guides
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">--- tours ---</li>
    <li>
      <a href="DS_classification-basics.html">Classification in R</a>
    </li>
    <li class="dropdown-header">Classification in Python</li>
    <li class="dropdown-header">Frequentist hypothesis testing in R</li>
    <li class="dropdown-header">--- templates ---</li>
    <li>
      <a href="writing_temp_typora2rmd.html">Writing template</a>
    </li>
    <li class="dropdown-header">Plotting template</li>
    <li class="dropdown-header">--- worked ---</li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    data projects
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">[placeholder]</li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    math
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">[placeholder]</li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    machines
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">[placeholder]</li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    art
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">[placeholder]</li>
  </ul>
</li>
<li>
  <a href="music_page.html">original music</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/mattlabcode">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://www.linkedin.com/in/matthew-bain314/">
    <span class="fab fa-linkedin fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://www.youtube.com/@fujinai9/featured">
    <span class="fa fa-youtube fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://soundcloud.com/user-752823440">
    <span class="fa fa-brands fa-soundcloud"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Two- &amp; multi-class classification in
Python</h1>
<h4 class="author">Matthew Bain</h4>

</div>


<hr>
<em>This page is a placeholder.</em>
<hr>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">### load dependencies</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># essentials</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy.linalg <span class="im">as</span> LA           <span class="co"># linalg module of numpy</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd                 <span class="co"># pandas for data manipulation</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autograd.numpy <span class="im">as</span> np         <span class="co"># autograd-wrapped numpy</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># optimization</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> autograd <span class="im">import</span> grad           <span class="co"># module for computing gradient</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> autograd <span class="im">import</span> value_and_grad <span class="co"># returns grad &amp; val of input function</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># plotting</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt     <span class="co"># pyplot module of matplotlib</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co"># global plotting parameters</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>plt_colours <span class="op">=</span> (np.array([<span class="dv">94</span>,<span class="dv">255</span>,<span class="dv">231</span>])<span class="op">/</span><span class="dv">360</span>, np.array([<span class="dv">133</span>,<span class="dv">94</span>,<span class="dv">214</span>])<span class="op">/</span><span class="dv">360</span>,</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>               np.array([<span class="dv">110</span>,<span class="dv">250</span>,<span class="dv">152</span>])<span class="op">/</span><span class="dv">360</span>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>font_size   <span class="op">=</span> <span class="dv">14</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>font_name   <span class="op">=</span> {<span class="st">&#39;fontname&#39;</span>: <span class="st">&#39;Avenir&#39;</span>}</span></code></pre></div>
<div id="exercise-1-predicting-breast-cancer" class="section level1"
number="1">
<h1><span class="header-section-number">1</span> <strong>Exercise
1</strong> Predicting breast cancer</h1>
<p>In this problem we examine the <a
href="https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)">Breast
Cancer Data Set</a>, obtained from the University of Wisconsin
Hospitals, Madison from Dr. William H. Wolberg <a href="#fn1"
class="footnote-ref" id="fnref1"><sup>1</sup></a>.</p>
<div id="softmax-perceptron-costs" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> Softmax &amp;
perceptron costs</h2>
<p>In this exercise we implement the softmax and perceptron cost
functions.</p>
<p><em>notes</em></p>
<ul>
<li>class labels are coded as <span class="math inline">\(1\)</span> for
benign, <span class="math inline">\(-1\)</span> for malignant.</li>
<li>the dataset is arranged in columns, each corresponding to an
individual &amp; each row a cellular measurement.</li>
<li>Class labels are stored in the final row.</li>
</ul>
<p>Below we import the dataset.</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">### setup dataset</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># data input</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>csvname <span class="op">=</span> <span class="st">&#39;data/breast_cancer_data.csv&#39;</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.loadtxt(csvname, delimiter <span class="op">=</span> <span class="st">&#39;,&#39;</span>)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co"># get input and output of dataset</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> data[:<span class="op">-</span><span class="dv">1</span>, :]   <span class="co"># feature vectors</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data[<span class="op">-</span><span class="dv">1</span>:, :]   <span class="co"># class labels {1,-1}</span></span></code></pre></div>
<p>We now define our model and complete an implementation of the softmax
and perceptron cost functions.</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co">### define model and cost functions</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># define model (compute linear combination of input points)</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> model(x, w):</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    a <span class="op">=</span> w[<span class="dv">0</span>] <span class="op">+</span> np.dot(x.T, w[<span class="dv">1</span>:])</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> a.T</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co">## cost functions (`g`)</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co"># softmax cost implementation</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># note: x,y req. by cost but def. globally s.t. for given w compute cost</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="co"># across all x,y)</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> softmax(w):</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># note: equivalent to softnax aoprox to perceptron cost, below</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    cost <span class="op">=</span> np.<span class="bu">sum</span>(np.log(<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>y<span class="op">*</span>model(x, w))))</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> cost<span class="op">/</span><span class="bu">float</span>(np.size(y))</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="co"># perceptron cost implementation</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> perceptron(w):</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># sum of pair-wise maximum between 0, model values</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    cost <span class="op">=</span> np.<span class="bu">sum</span>(np.maximum(<span class="dv">0</span>, <span class="op">-</span>y<span class="op">*</span>model(x, w)))</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> cost<span class="op">/</span><span class="bu">float</span>(np.size(y))</span></code></pre></div>
</div>
<div id="minimizing-cost-functions" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> Minimizing cost
functions</h2>
<p>We will now optimize these cost functions using gradient descent.</p>
<p>Below we define the standard gradient descent algorithm.</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co">### GD function</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gradient_descent(g, alpha, max_its, w):</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  <span class="im">import</span> autograd.numpy <span class="im">as</span> np</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>  <span class="im">from</span> autograd <span class="im">import</span> grad</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># define alpha based on chosen cost function</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># alpha = 1.0 if g == softmax else .1</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> g <span class="op">==</span> softmax: alpha <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">elif</span> g <span class="op">==</span> perceptron: alpha <span class="op">=</span> <span class="fl">.1</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>  <span class="cf">elif</span> g <span class="op">==</span> cross_entropy: alpha <span class="op">=</span> <span class="fl">.6</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># compute gradient (wrt w, holding constant x,y)</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>  gradient <span class="op">=</span> grad(g)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>  <span class="co"># run GD loop</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>  weight_history <span class="op">=</span> [w] <span class="co"># weight history container</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>  cost_history <span class="op">=</span> [g(w)] <span class="co"># cost function history container</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(max_its):</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># evaluate the gradient</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>    grad_eval <span class="op">=</span> gradient(w)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># take gradient descent step</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>    w <span class="op">=</span> w <span class="op">-</span> alpha<span class="op">*</span>grad_eval</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># record weight and cost</span></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>    weight_history.append(w)</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>    cost_history.append(g(w))</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> weight_history, cost_history</span></code></pre></div>
<p>Below we define our parameters and then minimize both cost
functions.</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co">### optimize cost functions</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autograd.numpy <span class="im">as</span> np</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># define gradient descent (GD) parameters</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>max_its <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> <span class="fl">0.1</span><span class="op">*</span>np.random.randn(<span class="dv">9</span>, <span class="dv">1</span>) <span class="co"># initial starting weights</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co"># call GD (choose arb alpha for now bc based on chosen g)</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>weight_history_SM, cost_history_SM <span class="op">=</span> gradient_descent(softmax, <span class="dv">1</span>,</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>                                                      max_its, w)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>weight_history_PT, cost_history_PT <span class="op">=</span> gradient_descent(perceptron, <span class="dv">1</span>,</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>                                                      max_its, w)</span></code></pre></div>
</div>
<div id="misclassifications" class="section level2" number="1.3">
<h2><span class="header-section-number">1.3</span>
Misclassifications</h2>
<p>We now compute the number of misclassifications for each iteration of
gradient descent.</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">### compute misclassification history</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autograd.numpy <span class="im">as</span> np</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># compute misclassification history</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> miscount(w, x, y):</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># +1 or -1 whether above or below fitted decision bound determined by w</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> np.sign(model(x, w))</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># pairwise compare vectors: 1 if model class pred == true class; sum</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    miscount_curr <span class="op">=</span> np.<span class="bu">sum</span>(y_pred <span class="op">!=</span> y)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> miscount_curr</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co"># compute miscount history for each cost function</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>miscount_history_SM <span class="op">=</span> [miscount(v, x, y) <span class="cf">for</span> v <span class="kw">in</span> weight_history_SM]</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>miscount_history_PT <span class="op">=</span> [miscount(v, x, y) <span class="cf">for</span> v <span class="kw">in</span> weight_history_PT]</span></code></pre></div>
</div>
<div id="plotting-cost-and-misclassifications" class="section level2"
number="1.4">
<h2><span class="header-section-number">1.4</span>
<strong>Plotting</strong>: cost and misclassifications</h2>
<p>Below we plot the cost and misclassification history for each cost
function.</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co">### define function for plotting cost and misclassification hist in same figure</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_cost_and_miscount(data):</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># store data</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    x_plt           <span class="op">=</span> data[<span class="st">&quot;x_plt&quot;</span>]</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    y_miscount_SM   <span class="op">=</span> data[<span class="st">&quot;y_miscount_SM&quot;</span>]</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    y_cost_SM       <span class="op">=</span> data[<span class="st">&quot;y_cost_SM&quot;</span>]</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    y_miscount_PT   <span class="op">=</span> data[<span class="st">&quot;y_miscount_PT&quot;</span>]</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    y_cost_PT       <span class="op">=</span> data[<span class="st">&quot;y_cost_PT&quot;</span>]</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># use seaborn style</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    sns.set_theme()</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># to prevent warning messages from appearing in the report</span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> warnings<span class="op">;</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>    warnings.filterwarnings(<span class="st">&#39;ignore&#39;</span>)</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># set inline figure format/quality, overall params</span></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># %config InlineBackend.figure_format = &#39;svg&#39;</span></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># setup plot &amp; subplots</span></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>    fig, axs <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>, figsize <span class="op">=</span> np.array([<span class="fl">6.5</span>, <span class="dv">8</span>]),</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>                            constrained_layout <span class="op">=</span> <span class="va">True</span>) <span class="co"># overall layout, size</span></span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># axs[0] = plt.subplot(1,3,(1,2), frameon = 1)</span></span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>] <span class="op">=</span> plt.subplot(<span class="dv">211</span>, frameon <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>] <span class="op">=</span> plt.subplot(<span class="dv">212</span>, frameon <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># set axis tick sizes</span></span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].xaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].yaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].xaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].yaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plot overlay of misclassifications &amp; costs for each cost over it</span></span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>    line_miscount_SM    <span class="op">=</span> axs[<span class="dv">0</span>].plot(x_plt, y_miscount_SM,</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>                                      color <span class="op">=</span> plt_colours[<span class="dv">0</span>],</span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>                                      linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>    line_miscount_PT    <span class="op">=</span> axs[<span class="dv">0</span>].plot(x_plt, y_miscount_PT,</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a>                                      color <span class="op">=</span> plt_colours[<span class="dv">1</span>],</span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>                                      linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>    line_cost_SM        <span class="op">=</span> axs[<span class="dv">1</span>].plot(x_plt, y_cost_SM,</span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>                                      color <span class="op">=</span> plt_colours[<span class="dv">0</span>],</span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>                                      linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a>    line_cost_PT        <span class="op">=</span> axs[<span class="dv">1</span>].plot(x_plt, y_cost_PT,</span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a>                                      color <span class="op">=</span> plt_colours[<span class="dv">1</span>],</span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>                                      linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a>    <span class="co"># add labels</span></span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a>    <span class="co"># axs[0].set_xlabel(&#39;iteration&#39;, fontsize = font_size, **font_name)</span></span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].set_xlabel(<span class="st">&#39;iteration&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].set_ylabel(<span class="st">&#39;misclassifications&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb7-56"><a href="#cb7-56" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].set_xlabel(<span class="st">&#39;iteration&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb7-57"><a href="#cb7-57" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].set_ylabel(<span class="st">&#39;cost&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb7-58"><a href="#cb7-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-59"><a href="#cb7-59" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plot legend</span></span>
<span id="cb7-60"><a href="#cb7-60" aria-hidden="true" tabindex="-1"></a>    leg_labels <span class="op">=</span> [<span class="st">&#39;softmax&#39;</span>, <span class="st">&#39;perceptron&#39;</span>]</span>
<span id="cb7-61"><a href="#cb7-61" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].legend([line_miscount_SM, line_miscount_PT], labels <span class="op">=</span> leg_labels,</span>
<span id="cb7-62"><a href="#cb7-62" aria-hidden="true" tabindex="-1"></a>    loc <span class="op">=</span> <span class="st">&#39;upper right&#39;</span>, frameon <span class="op">=</span> <span class="dv">1</span>, fontsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb7-63"><a href="#cb7-63" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].legend([line_cost_SM, line_cost_PT], labels <span class="op">=</span> leg_labels,</span>
<span id="cb7-64"><a href="#cb7-64" aria-hidden="true" tabindex="-1"></a>                  loc <span class="op">=</span> <span class="st">&#39;upper right&#39;</span>, frameon <span class="op">=</span> <span class="dv">1</span>, fontsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb7-65"><a href="#cb7-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-66"><a href="#cb7-66" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code></pre></div>
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co">### store data and plot</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># store plotting data in data frame</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>plot_data <span class="op">=</span> pd.DataFrame(</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;x_plt&quot;</span>: np.arange(np.size(miscount_history_SM)),</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_miscount_SM&quot;</span>: miscount_history_SM,</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_cost_SM&quot;</span>: cost_history_SM,</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_miscount_PT&quot;</span>: miscount_history_PT,</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_cost_PT&quot;</span>: cost_history_PT</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="co"># plot</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>plot_cost_and_miscount(plot_data)</span></code></pre></div>
<p><img src="ML_classification-basics_files/figure-html/unnamed-chunk-8-1.png" width="624" /></p>
<p>Below we identify and return the minimum number of misclassifications
for each cost function over all iterations of gradient descent.</p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co">### identify minima</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>min_misclass_SM <span class="op">=</span> <span class="bu">min</span>(miscount_history_SM)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>min_misclass_PT <span class="op">=</span> <span class="bu">min</span>(miscount_history_PT)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;softmax minimum misclassifications:    &quot;</span> <span class="op">+</span> <span class="bu">str</span>(min_misclass_SM))</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; softmax minimum misclassifications:    21</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;perceptron minimum misclassifications: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(min_misclass_PT))</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; perceptron minimum misclassifications: 20</span></span></code></pre></div>
<p>Below we modify the <code>miscount</code> function to consider only
misclassified malignant cases (i.e., cases corresponding to the class
label <span class="math inline">\(-1\)</span>).</p>
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co">#### define misclassification rate</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autograd.numpy <span class="im">as</span> np</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># compute misclassification history</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> miscount_neg(w, x, y):</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># +1 or -1 whether above or below fitted decision bound determined by w</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> np.sign(model(x, w))</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># consider only malignant cases</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    miscount_curr <span class="op">=</span> np.<span class="bu">sum</span>(y_pred[y <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>] <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> miscount_curr</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a><span class="co"># compute new miscount history for each cost function</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>miscount_history_SM_neg <span class="op">=</span> [miscount_neg(v, x, y) <span class="cf">for</span> v <span class="kw">in</span> weight_history_SM]</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>miscount_history_PT_neg <span class="op">=</span> [miscount_neg(v, x, y) <span class="cf">for</span> v <span class="kw">in</span> weight_history_PT]</span></code></pre></div>
<p>Below we again plot misclassification and cost history side-by-side,
this time considering only misclassified malignant cases.</p>
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co">### store data and plot</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="co"># import pandas for data frame capabilities</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># store plotting data in data frame</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>plot_data <span class="op">=</span> pd.DataFrame(</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;x_plt&quot;</span>: np.arange(np.size(miscount_history_SM_neg)),</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_miscount_SM&quot;</span>: miscount_history_SM_neg,</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_cost_SM&quot;</span>: cost_history_SM,</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_miscount_PT&quot;</span>: miscount_history_PT_neg,</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_cost_PT&quot;</span>: cost_history_PT</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="co"># plot</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>plot_cost_and_miscount(plot_data)</span></code></pre></div>
<p><img src="ML_classification-basics_files/figure-html/unnamed-chunk-11-3.png" width="624" /></p>
</div>
<div id="logistic-regression-cross-entropy" class="section level2"
number="1.5">
<h2><span class="header-section-number">1.5</span> Logistic regression
&amp; cross-entropy</h2>
<p>In this exercise we compare the above results to those obtained using
logistic regression with a cross entropy cost.</p>
<p>The provided code below converts our class labels <code>y</code> =
<span class="math inline">\(\{-1, 1\}\)</span> to <span
class="math inline">\(\{0, 1\}\)</span>.</p>
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co">### setup dataset</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>y_1 <span class="op">=</span> np.squeeze(y) <span class="co"># flatten y (one dimension)</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>y_ben <span class="op">=</span> np.argwhere(y_1 <span class="op">&gt;</span> <span class="fl">0.9</span>) <span class="co"># returns all indices where y meets condition</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>y_mal <span class="op">=</span> np.argwhere(y_1 <span class="op">&lt;</span> <span class="op">-</span><span class="fl">0.9</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>yc <span class="op">=</span> np.arange(<span class="dv">699</span>) <span class="co"># class labels (`y`) for CE (cross-entropy) cost</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>yc[y_ben] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>yc[y_mal] <span class="op">=</span> <span class="dv">0</span></span></code></pre></div>
<p>The code below (provided to us) implements the cross entropy cost
function, with L2 regularization.</p>
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co">### define model and cross entropy cost</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="co"># define sigmoid function</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sigmoid(t):</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>t))</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co">## the (convex) cross-entropy cost function</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>lam <span class="op">=</span> <span class="dv">2</span><span class="op">*</span><span class="dv">10</span><span class="op">**</span>(<span class="op">-</span><span class="dv">3</span>) <span class="co"># regularization parameter</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> cross_entropy(w):</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute sigmoid of model</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    sig_eval <span class="op">=</span> sigmoid(model(x, w))</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute cost of label 0 points</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    ind_mal <span class="op">=</span> np.argwhere(yc <span class="op">==</span> <span class="dv">0</span>)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>    cost <span class="op">=</span> <span class="op">-</span>np.<span class="bu">sum</span>(np.log(<span class="dv">1</span> <span class="op">-</span> sig_eval[:, ind_mal]))</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># add (subtract) cost on label 1 points</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>    ind_ben <span class="op">=</span> np.argwhere(yc <span class="op">==</span> <span class="dv">1</span>)</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>    cost <span class="op">-=</span> np.<span class="bu">sum</span>(np.log(sig_eval[:, ind_ben]))</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># add regularizer (* regularization parameter)</span></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>    cost <span class="op">+=</span> lam<span class="op">*</span>np.<span class="bu">sum</span>(w[<span class="dv">1</span>:]<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute cross-entropy</span></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> cost<span class="op">/</span><span class="bu">float</span>(np.size(yc))</span></code></pre></div>
<p>Below we run gradient descent to optimize the cross entropy cost
function for logistic regression.</p>
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co">### optimize cost function using GD</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autograd.numpy <span class="im">as</span> np</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># define gradient descent parameters</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>max_its <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> <span class="fl">0.1</span><span class="op">*</span>np.random.randn(<span class="dv">9</span>, <span class="dv">1</span>) <span class="co"># initial starting weights</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co"># call GD (choose arb alpha for now bc based on chosen g)</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>weight_history_CE, cost_history_CE <span class="op">=</span> gradient_descent(cross_entropy, <span class="dv">1</span>,</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>                                                      max_its, w)</span></code></pre></div>
<p>We now compute misclassification history. To do so we must modify
<code>miscount</code> to compute misclassifications in a manner
appropriate to logistic regression. Since the sigmoid function varies
between 0 and 1 and is symmetric (about a <span
class="math inline">\(180^{\circ}\)</span> rotation centered at <span
class="math inline">\((0, 0.5)\)</span>), we can use <span
class="math inline">\(y = 0.5\)</span> to effectively separate our
predictions into the two classes labelled <span
class="math inline">\(\{0, 1\}\)</span>. Then, as before, we can
determine misclassiffications by comparing the predicted classes across
<code>weight_history</code> with the true class labels.</p>
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co">### compute misclassification history</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autograd.numpy <span class="im">as</span> np</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co"># compute misclassification history</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> miscount_CE(w, x, y):</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> np.sign(model(x, w))        <span class="co"># 1 or 1 if eval &gt; .5</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># convert predictions to classes based on y = .5 threshold  value</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>    y_pred[y_pred <span class="op">&gt;=</span> <span class="fl">.5</span>]    <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    y_pred[y_pred <span class="op">&lt;</span> <span class="fl">.5</span>]     <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># pairwise compare vectors: 1 if model class pred == true class; sum</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>    miscount_curr <span class="op">=</span> np.<span class="bu">sum</span>(y_pred <span class="op">!=</span> y)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> miscount_curr</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a><span class="co"># compute new miscount history for cross entropy cost</span></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>miscount_history_CE <span class="op">=</span> [miscount_CE(v, x, yc) <span class="cf">for</span> v <span class="kw">in</span> weight_history_CE]</span></code></pre></div>
<p>And finally, below we plot cost and misclassification history for the
logistic regression cross entropy cost, as we did above for the softmax
and perceptron cost functions (alongside the results for the perceptron
cost function). First we make a couple minor modifications to generalize
our plotting function and allow us to plot cross entropy cost in
addition to softmax cost.</p>
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co">### define plotting function</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_cost_and_miscount(data):</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># store data</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    x_plt           <span class="op">=</span> data[<span class="st">&quot;x_plt&quot;</span>]</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># y_miscount_1    = data[&quot;y_miscount_CE&quot;]</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># y_cost_1        = data[&quot;y_cost_CE&quot;]</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># y_miscount_2    = data[&quot;y_miscount_PT&quot;]</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># y_cost_2        = data[&quot;y_cost_PT&quot;]</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    y_miscount_1    <span class="op">=</span> data.iloc[:, <span class="dv">1</span>]</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>    y_cost_1        <span class="op">=</span> data.iloc[:, <span class="dv">2</span>]</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>    y_miscount_2    <span class="op">=</span> data.iloc[:, <span class="dv">3</span>]</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>    y_cost_2        <span class="op">=</span> data.iloc[:, <span class="dv">4</span>]</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># use seaborn style</span></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>    sns.set_theme()</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># to prevent warning messages from appearing in the report</span></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> warnings<span class="op">;</span></span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>    warnings.filterwarnings(<span class="st">&#39;ignore&#39;</span>)</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># set inline figure format/quality, overall params</span></span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># %config InlineBackend.figure_format = &#39;svg&#39;</span></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># setup plot &amp; subplots</span></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>    fig, axs <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>, figsize <span class="op">=</span> np.array([<span class="fl">6.5</span>, <span class="dv">8</span>]),</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>                            constrained_layout <span class="op">=</span> <span class="va">True</span>) <span class="co"># overall layout, size</span></span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># axs[0] = plt.subplot(1,3,(1,2), frameon = 1)</span></span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>] <span class="op">=</span> plt.subplot(<span class="dv">211</span>, frameon <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>] <span class="op">=</span> plt.subplot(<span class="dv">212</span>, frameon <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># set axis tick sizes</span></span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].xaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].yaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].xaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].yaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plot overlay of misclassifications &amp; costs for each cost over all it</span></span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a>    line_miscount_CE    <span class="op">=</span> axs[<span class="dv">0</span>].plot(x_plt, y_miscount_1,</span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a>                                      color <span class="op">=</span> plt_colours[<span class="dv">0</span>],</span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a>                                      linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a>    line_miscount_PT    <span class="op">=</span> axs[<span class="dv">0</span>].plot(x_plt, y_miscount_2,</span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a>                                      color <span class="op">=</span> plt_colours[<span class="dv">1</span>],</span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a>                                      linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a>    line_cost_CE        <span class="op">=</span> axs[<span class="dv">1</span>].plot(x_plt, y_cost_1,</span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a>                                      color <span class="op">=</span> plt_colours[<span class="dv">0</span>],</span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a>                                      linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb16-52"><a href="#cb16-52" aria-hidden="true" tabindex="-1"></a>    line_cost_PT        <span class="op">=</span> axs[<span class="dv">1</span>].plot(x_plt, y_cost_2,</span>
<span id="cb16-53"><a href="#cb16-53" aria-hidden="true" tabindex="-1"></a>                                      color <span class="op">=</span> plt_colours[<span class="dv">1</span>],</span>
<span id="cb16-54"><a href="#cb16-54" aria-hidden="true" tabindex="-1"></a>                                      linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb16-55"><a href="#cb16-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-56"><a href="#cb16-56" aria-hidden="true" tabindex="-1"></a>    <span class="co"># add labels</span></span>
<span id="cb16-57"><a href="#cb16-57" aria-hidden="true" tabindex="-1"></a>    <span class="co"># axs[0].set_xlabel(&#39;iteration&#39;, fontsize = font_size, **font_name)</span></span>
<span id="cb16-58"><a href="#cb16-58" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].set_xlabel(<span class="st">&#39;iteration&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb16-59"><a href="#cb16-59" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].set_ylabel(<span class="st">&#39;misclassifications&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb16-60"><a href="#cb16-60" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].set_xlabel(<span class="st">&#39;iteration&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb16-61"><a href="#cb16-61" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].set_ylabel(<span class="st">&#39;cost&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb16-62"><a href="#cb16-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-63"><a href="#cb16-63" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plot legend</span></span>
<span id="cb16-64"><a href="#cb16-64" aria-hidden="true" tabindex="-1"></a>    leg_labels <span class="op">=</span> [<span class="st">&#39;cross entropy&#39;</span>, <span class="st">&#39;perceptron&#39;</span>]</span>
<span id="cb16-65"><a href="#cb16-65" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].legend([line_miscount_CE, line_miscount_PT], labels <span class="op">=</span> leg_labels,</span>
<span id="cb16-66"><a href="#cb16-66" aria-hidden="true" tabindex="-1"></a>                  loc <span class="op">=</span> <span class="st">&#39;upper right&#39;</span>, frameon <span class="op">=</span> <span class="dv">1</span>, fontsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb16-67"><a href="#cb16-67" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].legend([line_cost_CE, line_cost_PT], labels <span class="op">=</span> leg_labels,</span>
<span id="cb16-68"><a href="#cb16-68" aria-hidden="true" tabindex="-1"></a>                  loc <span class="op">=</span> <span class="st">&#39;upper right&#39;</span>, frameon <span class="op">=</span> <span class="dv">1</span>, fontsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb16-69"><a href="#cb16-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-70"><a href="#cb16-70" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code></pre></div>
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co">### store data and plot</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># store plotting data in data frame</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>plot_data <span class="op">=</span> pd.DataFrame(</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;x_plt&quot;</span>: np.arange(np.size(miscount_history_CE)),</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_miscount_CE&quot;</span>: miscount_history_CE,</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_cost_CE&quot;</span>: cost_history_CE,</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_miscount_PT&quot;</span>: miscount_history_PT,</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_cost_PT&quot;</span>: cost_history_PT</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="co"># plot</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>plot_cost_and_miscount(plot_data)</span></code></pre></div>
<p><img src="ML_classification-basics_files/figure-html/unnamed-chunk-17-5.png" width="624" /></p>
</div>
</div>
<div id="exercise-2-spam-detection" class="section level1" number="2">
<h1><span class="header-section-number">2</span> <strong>Exercise
2</strong> Spam detection</h1>
<p>In this problem we examinine the <a
href="https://archive.ics.uci.edu/ml/datasets/Spambase">Spambase Data
Set</a> <a href="#fn2" class="footnote-ref"
id="fnref2"><sup>2</sup></a>, containing measurements of spam and
non-spam emails. Using the two-class classification methods we explored
in the above exercises, we build a classifier to determine if an email
is likely to be spam.</p>
<p><em>notes</em></p>
<p>Class labels (1 for ‘spam’, -1 for ‘not spam’) are again stored in
the final row (<span class="math inline">\(N = 58\)</span>) of the
dataset, with each other row <span class="math inline">\(n\)</span>
representing a feature (word/character frequencies, etc.) and each
column <span class="math inline">\(p\)</span> a sample (<span
class="math inline">\(P = 4601\)</span>).</p>
<p>Below we import the dataset.</p>
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co">### import dataset</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co"># data input</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>csvname <span class="op">=</span> <span class="st">&#39;data/spambase_data.csv&#39;</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.loadtxt(csvname, delimiter <span class="op">=</span> <span class="st">&#39;,&#39;</span>)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co"># get input and output of dataset</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> data[:<span class="op">-</span><span class="dv">1</span>, :]    <span class="co"># feature vectors</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data[<span class="op">-</span><span class="dv">1</span>:, :]    <span class="co"># class labels {1,-1}</span></span></code></pre></div>
<div id="some-basic-preprocessing" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Some basic
preprocessing</h2>
<p>We now perform some preproc`essing to prepare the dataset for our
analysis. We standard normalize each feature (s.t. <span
class="math inline">\(\mu_n = 0\)</span> and <span
class="math inline">\(\sigma_n = 1\)</span>, where <span
class="math inline">\(\mu\)</span> represents the mean and <span
class="math inline">\(\sigma\)</span> the standard deviation) so that
they can be treated equally by our classifier. To do so, for each
observation <span class="math inline">\(x_{n,p}\)</span> we subtract the
corresponding mean <span class="math inline">\(\mu_n\)</span> and divide
by the corresponding standard deviation <span
class="math inline">\(\sigma_n\)</span>.</p>
<p>To deal with missing observations for a given feature (represented as
<code>NaN</code>), we replace <code>NaN</code> with the corresponding
feature mean <span class="math inline">\(\mu_n\)</span>.</p>
<p>The following function (provided to us) executes the above.</p>
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co">### perform standard normalization and fill in missing data</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> standard_normalizer(x):</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute the mean and standard deviation of each feature</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    x_means <span class="op">=</span> np.nanmean(x, axis <span class="op">=</span> <span class="dv">1</span>)[:, np.newaxis]</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    x_stds  <span class="op">=</span> np.nanstd(x, axis <span class="op">=</span> <span class="dv">1</span>)[:, np.newaxis]</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># check to make sure that x_stds &gt; small threshold; for those not</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># divide by 1 instead of original standard deviation</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>    ind <span class="op">=</span> np.argwhere(x_stds <span class="op">&lt;</span> <span class="dv">10</span><span class="op">**</span>(<span class="op">-</span><span class="dv">2</span>))</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(ind) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>        ind <span class="op">=</span> [v[<span class="dv">0</span>] <span class="cf">for</span> v <span class="kw">in</span> ind] <span class="co"># just keep row index</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>        adjust <span class="op">=</span> np.zeros((x_stds.shape)) <span class="co"># array of indices to replace with 1</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>        adjust[ind] <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>        x_stds <span class="op">+=</span> adjust</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># fill in any nan values with corresponding feature mean</span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>    ind <span class="op">=</span> np.argwhere(np.isnan(x) <span class="op">==</span> <span class="va">True</span>)</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> ind:</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>        x[i[<span class="dv">0</span>], i[<span class="dv">1</span>]] <span class="op">=</span> x_means[i[<span class="dv">0</span>]]</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># create standard normalizer function</span></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>    normalizer <span class="op">=</span> <span class="kw">lambda</span> data: (data <span class="op">-</span> x_means)<span class="op">/</span>x_stds</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># create inverse standard normalizer</span></span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>    inverse_normalizer <span class="op">=</span> <span class="kw">lambda</span> data: data<span class="op">*</span>x_stds <span class="op">+</span> x_means</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># return (inverse) normalizer</span></span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> normalizer, inverse_normalizer</span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a><span class="co">## standard normalize dataset</span></span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>normalizer, inverse_normalizer <span class="op">=</span> standard_normalizer(x) <span class="co"># get std norm functions</span></span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> normalizer(x)</span></code></pre></div>
</div>
<div id="email-classification-with-perceptron" class="section level2"
number="2.2">
<h2><span class="header-section-number">2.2</span> Email classification
with perceptron</h2>
<p>In this exercise we classify emails using the softmax and perceptron
cost functions.</p>
<p><strong>Steps:</strong></p>
<p>We carry out the same sequence of steps covered in detail in exercise
1:</p>
<ol style="list-style-type: decimal">
<li><p>Identify optimal decision boundary (determined by weights <span
class="math inline">\(w\)</span>):</p>
<ul>
<li>run gradient descent to identify <span
class="math inline">\(w\)</span> that minimizes cost functions</li>
<li>softmax: <span class="math inline">\(\alpha = 1.0\)</span>;
perceptron: <span class="math inline">\(\alpha = 0.1\)</span></li>
<li>other parameters: <code>max its = 1000</code>;
<code>w = 0.1*np.random.randn(N + 1, 1)</code>, where <span
class="math inline">\(N = 57\)</span></li>
</ul></li>
<li><p>Compute misclassification histories</p></li>
<li><p>Plot cost and misclassification as a function of gradient descent
iteration</p></li>
</ol>
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co">### 1) optimize softmax and perceptron costs over `spambase` dataset</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autograd.numpy <span class="im">as</span> np</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="co"># define gradient descent parameters</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>max_its <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> <span class="fl">0.1</span><span class="op">*</span>np.random.randn(np.shape(x)[<span class="dv">0</span>] <span class="op">+</span> <span class="dv">1</span>, <span class="dv">1</span>) <span class="co"># initial starting weights</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="co"># call GD (choose arb alpha for now bc based on chosen g)</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>weight_history_SM_spam, cost_history_SM_spam <span class="op">=</span> gradient_descent(softmax, <span class="dv">1</span>,</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>                                                        max_its, w)</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>weight_history_PT_spam, cost_history_PT_spam <span class="op">=</span> gradient_descent(perceptron, <span class="dv">1</span>,</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>                                                        max_its, w)</span></code></pre></div>
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co">### 2) compute misclassification history for each cost function</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>miscount_history_SM_spam <span class="op">=</span> [miscount(v, x, y) <span class="cf">for</span> v <span class="kw">in</span> weight_history_SM_spam]</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>miscount_history_PT_spam <span class="op">=</span> [miscount(v, x, y) <span class="cf">for</span> v <span class="kw">in</span> weight_history_PT_spam]</span></code></pre></div>
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co">### 3) for each cost, plot cost and misclassification as a function of iteration</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="co">## store data and plot</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="co"># store plotting data in data frame</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>plot_data <span class="op">=</span> pd.DataFrame(</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;x_plt&quot;</span>: np.arange(np.size(miscount_history_SM_spam)),</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_miscount_SM&quot;</span>: miscount_history_SM_spam,</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_cost_SM&quot;</span>: cost_history_SM_spam,</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_miscount_PT&quot;</span>: miscount_history_PT_spam,</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_cost_PT&quot;</span>: cost_history_PT_spam</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="co">## plot</span></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>plot_cost_and_miscount(plot_data)</span></code></pre></div>
<p><img src="ML_classification-basics_files/figure-html/unnamed-chunk-22-7.png" width="624" /></p>
<p>The plots above reveal some interesting results. The perceptron cost
appears to attain a stable minimum cost, but its misclassification
history appears to fluctuate rapidly between ~250 and 750
misclassifications. On the other hand, the softmax cost appears to
attain a stable, albeit higher, minimum cost, but its misclassification
history reaches a similar minimum to the softmax cost and is stable
(does not fluctate rapidly). This suggests that the perceptron cost
function is not perfectly flat at the identified minimum, causing minor
perturbations in weight to produce large deviations from the minimum. It
is possible that different (non-standard) gradient descent schemes
(e.g., fully normalized) would eliminate this behaviour.</p>
</div>
<div id="accuracy" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> Accuracy</h2>
<p>In this exercise we determine the misclassification minimum and
convert it to accuracy.</p>
<p><em>Recall</em>: we define accuracy, <span
class="math inline">\(\mathcal{A}\)</span> as</p>
<p><span class="math display">\[
\mathcal{A} = 1 - \frac{1}{P} \sum\limits_{p = 1}^P I(\hat{y}_p, y_p) ,
\]</span></p>
<p>where <span class="math inline">\(\sum\limits_{p = 1}^P I\)</span>
represents total misclassifications, which we average over all samples
<span class="math inline">\(P\)</span> and subtract from 1.</p>
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co">### determine minimum misclassifications for each cost and convert to accuracy</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="co"># identify minima</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>min_misclass_SM_spam <span class="op">=</span> <span class="bu">min</span>(miscount_history_SM_spam)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>min_misclass_PT_spam <span class="op">=</span> <span class="bu">min</span>(miscount_history_PT_spam)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;softmax minimum misclassifications:    &quot;</span> <span class="op">+</span> <span class="bu">str</span>(min_misclass_SM_spam))</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; softmax minimum misclassifications:    329</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;perceptron minimum misclassifications: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(min_misclass_PT_spam))</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="co"># convert to accuracies</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; perceptron minimum misclassifications: 332</span></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>accuracy_SM_spam <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> (min_misclass_SM_spam)<span class="op">/</span>np.shape(x)[<span class="dv">1</span>]</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>accuracy_PT_spam <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> (min_misclass_PT_spam)<span class="op">/</span>np.shape(x)[<span class="dv">1</span>]</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">softmax accuracy:    &quot;</span> <span class="op">+</span> <span class="bu">str</span>(accuracy_SM_spam))</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; softmax accuracy:    0.9284938056944143</span></span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;perceptron accuracy: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(accuracy_PT_spam))</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; perceptron accuracy: 0.927841773527494</span></span></code></pre></div>
<p>As we can see above, both classifiers, trained using a softmax and
perceptron cost, respectively, appear to perform relatively well, with
accuracies above 90%. However, softmax cost performs slighly better,
with 3 fewer misclassifications than the perceptron. This result
reflects our expectations based on the misclassification and cost
histories plotted above.</p>
</div>
<div id="confusion-matrix" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> Confusion matrix</h2>
<p>In this exercise we identify the optimal <code>w</code> found by the
softmax cost and construct the corresponding confusion matrix <a
href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>.</p>
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co">### construct confusion matrix for optimal softmax `w`</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="co">## define model again (compute linear combination of input points)</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> model(x, w):</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    a <span class="op">=</span> w[<span class="dv">0</span>] <span class="op">+</span> np.dot(x.T, w[<span class="dv">1</span>:])</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> a.T</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a><span class="co">## identify optimal `w` for cost</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>w_optimal_SM_spam <span class="op">=</span> weight_history_SM_spam[np.argmin(miscount_history_SM_spam)]</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a><span class="co"># w_optimal_PT_spam = weight_history_PT_spam[np.argmin(miscount_history_PT_spam)]</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a><span class="co">### function for plotting confusion matrix</span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_confusion_matrix(w, x, y):</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># +1 or -1 whether above or below fitted decision bound determined by w</span></span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> np.sign(model(x, w))</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>    <span class="co">## determine confusion matrix values (true pos/neg, false pos/neg)</span></span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>    TP <span class="op">=</span> np.<span class="bu">sum</span>(y_pred[y <span class="op">==</span> <span class="dv">1</span>] <span class="op">==</span> <span class="dv">1</span>)</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>    TN <span class="op">=</span> np.<span class="bu">sum</span>(y_pred[y <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>] <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>    FP <span class="op">=</span> np.<span class="bu">sum</span>(y_pred[y <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>] <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>    FN <span class="op">=</span> np.<span class="bu">sum</span>(y_pred[y <span class="op">==</span> <span class="dv">1</span>] <span class="op">!=</span> <span class="dv">1</span>)</span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># store values in dictionary, matrix for plotting</span></span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>    confusion_matrix_OP <span class="op">=</span> {<span class="st">&quot;TP&quot;</span>: TP, <span class="st">&quot;TN&quot;</span>: TN, <span class="st">&quot;FP&quot;</span>: FP, <span class="st">&quot;FN&quot;</span>: FN}</span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># confusion_matrix_OP[&quot;TN&quot;] = TN</span></span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a>    conf_matrix <span class="op">=</span> np.array([[TP, FN],</span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a>                            [FP, TN]])</span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a>    <span class="co">## plot confusion matrix</span></span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># set annotations for tiles based on counts</span></span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a>    group_names <span class="op">=</span> [<span class="st">&#39;TP&#39;</span>, <span class="st">&#39;FN&#39;</span>, <span class="st">&#39;FP&#39;</span>, <span class="st">&#39;TN&#39;</span>]</span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a>    group_counts <span class="op">=</span> [<span class="st">&quot;</span><span class="sc">{0:0.0f}</span><span class="st">&quot;</span>.<span class="bu">format</span>(value) <span class="cf">for</span> value <span class="kw">in</span> conf_matrix.flatten()]</span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a>    group_percentages <span class="op">=</span> [<span class="st">&quot;</span><span class="sc">{0:.2%}</span><span class="st">&quot;</span>.<span class="bu">format</span>(value) <span class="cf">for</span> value <span class="kw">in</span></span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a>                         conf_matrix.flatten()<span class="op">/</span>np.<span class="bu">sum</span>(conf_matrix)]</span>
<span id="cb24-39"><a href="#cb24-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-40"><a href="#cb24-40" aria-hidden="true" tabindex="-1"></a>    tile_labels <span class="op">=</span> [<span class="ss">f&quot;</span><span class="sc">{</span>v1<span class="sc">}</span><span class="ch">\n</span><span class="sc">{</span>v2<span class="sc">}</span><span class="ch">\n</span><span class="sc">{</span>v3<span class="sc">}</span><span class="ss">&quot;</span> <span class="cf">for</span> v1, v2, v3 <span class="kw">in</span></span>
<span id="cb24-41"><a href="#cb24-41" aria-hidden="true" tabindex="-1"></a>                   <span class="bu">zip</span>(group_names, group_counts, group_percentages)]</span>
<span id="cb24-42"><a href="#cb24-42" aria-hidden="true" tabindex="-1"></a>    tile_labels <span class="op">=</span> np.asarray(tile_labels).reshape(<span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb24-43"><a href="#cb24-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-44"><a href="#cb24-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plot</span></span>
<span id="cb24-45"><a href="#cb24-45" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> sns.heatmap(conf_matrix, annot <span class="op">=</span> tile_labels, fmt <span class="op">=</span> <span class="st">&#39;&#39;</span>, cmap <span class="op">=</span> <span class="st">&#39;Blues&#39;</span>)</span>
<span id="cb24-46"><a href="#cb24-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-47"><a href="#cb24-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># labels</span></span>
<span id="cb24-48"><a href="#cb24-48" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">Predicted Values&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb24-49"><a href="#cb24-49" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">&#39;Actual Values</span><span class="ch">\n</span><span class="st">&#39;</span>, fontsize <span class="op">=</span> font_size)<span class="op">;</span></span>
<span id="cb24-50"><a href="#cb24-50" aria-hidden="true" tabindex="-1"></a>    ax.xaxis.set_ticklabels([<span class="st">&#39;Spam&#39;</span>, <span class="st">&#39;Not spam&#39;</span>], fontsize <span class="op">=</span> font_size)</span>
<span id="cb24-51"><a href="#cb24-51" aria-hidden="true" tabindex="-1"></a>    ax.yaxis.set_ticklabels([<span class="st">&#39;Spam&#39;</span>, <span class="st">&#39;Not spam&#39;</span>], fontsize <span class="op">=</span> font_size)</span>
<span id="cb24-52"><a href="#cb24-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-53"><a href="#cb24-53" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb24-54"><a href="#cb24-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-55"><a href="#cb24-55" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> confusion_matrix_OP</span>
<span id="cb24-56"><a href="#cb24-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-57"><a href="#cb24-57" aria-hidden="true" tabindex="-1"></a><span class="co">## plot confusion matrix for softmax and optimal weight</span></span>
<span id="cb24-58"><a href="#cb24-58" aria-hidden="true" tabindex="-1"></a>confusion_matrix <span class="op">=</span> plot_confusion_matrix(w_optimal_SM_spam, x, y)</span></code></pre></div>
<p><img src="ML_classification-basics_files/figure-html/unnamed-chunk-24-9.png" width="624" /></p>
</div>
</div>
<div id="exercise-3-credit-check" class="section level1" number="3">
<h1><span class="header-section-number">3</span> <strong>Exercise
3</strong> Credit check</h1>
<p>In this problem we examinine a dataset containing credit ratings,
described in Example 6.11 of <em>Machine Learning Refined</em>.</p>
<p><em>notes</em></p>
<ul>
<li>Class labels (1 for ‘good rating’, -1 for ‘bad rating’) are again
stored in the final row of the dataset (<span class="math inline">\(N =
20\)</span>), with each other row <span class="math inline">\(n\)</span>
representing a feature (account balance, duration of previous credit,
etc.) and each column <span class="math inline">\(p\)</span> a sample
(<span class="math inline">\(P = 1000\)</span>).</li>
</ul>
<p>Below we import the dataset.</p>
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co">### import dataset</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="co"># data input</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>csvname <span class="op">=</span> <span class="st">&#39;data/credit_dataset.csv&#39;</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.loadtxt(csvname, delimiter <span class="op">=</span> <span class="st">&#39;,&#39;</span>)</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="co"># get input and output of dataset</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> data[:<span class="op">-</span><span class="dv">1</span>, :]    <span class="co"># feature vectors</span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data[<span class="op">-</span><span class="dv">1</span>:, :]    <span class="co"># class labels {1,-1}</span></span></code></pre></div>
<div id="standard-normalization" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Standard
normalization</h2>
<p>Below we standard normalize the dataset so that features can be
compared.</p>
<div class="sourceCode" id="cb26"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co">### perform standard normalization</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>normalizer, inverse_normalizer <span class="op">=</span> standard_normalizer(x) <span class="co"># get std norm functions</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> normalizer(x)</span></code></pre></div>
</div>
<div id="fitting-perceptron-based-classifier" class="section level2"
number="3.2">
<h2><span class="header-section-number">3.2</span> Fitting
perceptron-based classifier</h2>
<p>Below we fit a binary classifier using a perceptron cost.</p>
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co">### optimize perceptron cost over `credit rating` dataset</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autograd.numpy <span class="im">as</span> np</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="co"># define gradient descent parameters</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>max_its <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> <span class="fl">0.1</span><span class="op">*</span>np.random.randn(np.shape(x)[<span class="dv">0</span>] <span class="op">+</span> <span class="dv">1</span>, <span class="dv">1</span>) <span class="co"># initial starting weights</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="co"># call GD (choose arb alpha for now bc based on chosen g)</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>weight_history_PT_cred, cost_history_PT_cred <span class="op">=</span> gradient_descent(perceptron, <span class="dv">1</span>,</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>                                                        max_its, w)</span></code></pre></div>
<div class="sourceCode" id="cb28"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co">### compute misclassification history</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>miscount_history_PT_cred <span class="op">=</span> [miscount(v, x, y) <span class="cf">for</span> v <span class="kw">in</span> weight_history_PT_cred]</span></code></pre></div>
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co">### store data for plotting</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="co"># store plotting data</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>x_plt <span class="op">=</span> np.arange(np.size(miscount_history_PT_cred))</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>y_miscount_PT <span class="op">=</span> miscount_history_PT_cred</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>y_cost_PT <span class="op">=</span> cost_history_PT_cred</span></code></pre></div>
<div class="sourceCode" id="cb30"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co">### plot cost and misclassification history for perceptron cost</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a><span class="co"># use seaborn style</span></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>sns.set_theme()</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a><span class="co"># to prevent warning messages from appearing in the report</span></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings<span class="op">;</span></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">&#39;ignore&#39;</span>)</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a><span class="co"># set inline figure format/quality, overall params</span></span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a><span class="co"># %config InlineBackend.figure_format = &#39;svg&#39;</span></span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a><span class="co"># setup plot &amp; subplots</span></span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>, figsize <span class="op">=</span> np.array([<span class="fl">6.5</span>, <span class="dv">8</span>]),</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>                        constrained_layout <span class="op">=</span> <span class="va">True</span>) <span class="co"># overall layout, size</span></span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a><span class="co"># axs[0] = plt.subplot(1,3,(1,2), frameon = 1)</span></span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>] <span class="op">=</span> plt.subplot(<span class="dv">211</span>, frameon <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>] <span class="op">=</span> plt.subplot(<span class="dv">212</span>, frameon <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a><span class="co"># set axis tick sizes</span></span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].xaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].yaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].xaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].yaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb30-29"><a href="#cb30-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-30"><a href="#cb30-30" aria-hidden="true" tabindex="-1"></a><span class="co"># plot overlay of misclassifications &amp; costs for each cost over all it</span></span>
<span id="cb30-31"><a href="#cb30-31" aria-hidden="true" tabindex="-1"></a>line_miscount_CE    <span class="op">=</span> axs[<span class="dv">0</span>].plot(x_plt, y_miscount_PT,</span>
<span id="cb30-32"><a href="#cb30-32" aria-hidden="true" tabindex="-1"></a>                                  color <span class="op">=</span> plt_colours[<span class="dv">0</span>],</span>
<span id="cb30-33"><a href="#cb30-33" aria-hidden="true" tabindex="-1"></a>                                  linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb30-34"><a href="#cb30-34" aria-hidden="true" tabindex="-1"></a>line_cost_CE        <span class="op">=</span> axs[<span class="dv">1</span>].plot(x_plt, y_cost_PT,</span>
<span id="cb30-35"><a href="#cb30-35" aria-hidden="true" tabindex="-1"></a>                                  color <span class="op">=</span> plt_colours[<span class="dv">0</span>],</span>
<span id="cb30-36"><a href="#cb30-36" aria-hidden="true" tabindex="-1"></a>                                  linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb30-37"><a href="#cb30-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-38"><a href="#cb30-38" aria-hidden="true" tabindex="-1"></a><span class="co"># add labels</span></span>
<span id="cb30-39"><a href="#cb30-39" aria-hidden="true" tabindex="-1"></a><span class="co"># axs[0].set_xlabel(&#39;iteration&#39;, fontsize = font_size, **font_name)</span></span>
<span id="cb30-40"><a href="#cb30-40" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].set_xlabel(<span class="st">&#39;iteration&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb30-41"><a href="#cb30-41" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].set_ylabel(<span class="st">&#39;misclassifications&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb30-42"><a href="#cb30-42" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].set_xlabel(<span class="st">&#39;iteration&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb30-43"><a href="#cb30-43" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].set_ylabel(<span class="st">&#39;cost&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb30-44"><a href="#cb30-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-45"><a href="#cb30-45" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<p><img src="ML_classification-basics_files/figure-html/unnamed-chunk-30-11.png" width="624" /></p>
<div class="sourceCode" id="cb31"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co">### compute and output perceptron accuracy</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>min_misclass_PT_cred <span class="op">=</span> <span class="bu">min</span>(miscount_history_PT_cred)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>accuracy_PT_cred <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> (min_misclass_PT_cred)<span class="op">/</span>np.shape(x)[<span class="dv">1</span>]</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;perceptron accuracy: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(accuracy_PT_cred))</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; perceptron accuracy: 0.768</span></span></code></pre></div>
<p>The perceptron achieves a classification accuracy of ~76%, which is
within the range of the accuracy achieved in <em>Machine Learning
Refined</em>.</p>
</div>
<div id="confusion-matrix-1" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Confusion matrix</h2>
<p>We now plot the confusion matrix corresponding to the optimal weight
identified by the perceptron.</p>
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co">### plot confusion matrix for perceptron and optimal weight</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>w_optimal_PT_cred <span class="op">=</span> weight_history_PT_cred[np.argmin(miscount_history_PT_cred)]</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>confusion_matrix <span class="op">=</span> plot_confusion_matrix(w_optimal_PT_cred, x, y)</span></code></pre></div>
<p><img src="ML_classification-basics_files/figure-html/unnamed-chunk-32-13.png" width="624" /></p>
</div>
</div>
<div id="exercise-4-three-class-classification" class="section level1"
number="4">
<h1><span class="header-section-number">4</span> <strong>Exercise
4</strong> Three-class classification</h1>
<p>In this problem we examine a three-class toy dataset, shown in Fig.
7.9 of <em>Machine Learning Refined</em>, using the multi-class
perceptron. Additional resources (including plotting functions) are
provided in the official ‘MLR’ git repository <a href="#fn4"
class="footnote-ref" id="fnref4"><sup>4</sup></a>.</p>
<div id="fitting-multi-class-perceptron" class="section level2"
number="4.1">
<h2><span class="header-section-number">4.1</span> Fitting multi-class
perceptron</h2>
<p>Below we fit the multi-class perceptron to the dataset.</p>
<div class="sourceCode" id="cb33"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co">### import dataset &amp; standard normalize</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="co"># data input</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>csvname <span class="op">=</span> <span class="st">&#39;data/3class_data.csv&#39;</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.loadtxt(csvname, delimiter <span class="op">=</span> <span class="st">&#39;,&#39;</span>)</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="co"># get input and output of dataset</span></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> data[:<span class="op">-</span><span class="dv">1</span>, :]    <span class="co"># feature vectors</span></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data[<span class="op">-</span><span class="dv">1</span>:, :]    <span class="co"># class labels {1,-1}</span></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a><span class="co">## normalize</span></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>normalizer, inverse_normalizer <span class="op">=</span> standard_normalizer(x) <span class="co"># get std norm functions</span></span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> normalizer(x)</span></code></pre></div>
<div class="sourceCode" id="cb34"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co">### define model and multi-class perceptron (*provided code*)</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="co">## compute C linear combinations of input point, one per classifier</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> model(x, w):</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>    a <span class="op">=</span> w[<span class="dv">0</span>] <span class="op">+</span> np.dot(x.T, w[<span class="dv">1</span>:])</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> a.T</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a><span class="co">## multi-class perceptron</span></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>lam <span class="op">=</span> <span class="dv">10</span><span class="op">**-</span><span class="dv">5</span>  <span class="co"># regularization paramter</span></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> multiclass_perceptron(w):</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># pre-compute predictions on all points</span></span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>    all_evals <span class="op">=</span> model(x, w)</span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute maximum across data points</span></span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a>    a <span class="op">=</span> np.<span class="bu">max</span>(all_evals, axis <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute cost in compact form using numpy broadcasting</span></span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a>    b <span class="op">=</span> all_evals[y.astype(<span class="bu">int</span>).flatten(), np.arange(np.size(y))]</span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a>    cost <span class="op">=</span> np.<span class="bu">sum</span>(a <span class="op">-</span> b)</span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># add regularizer</span></span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a>    cost <span class="op">=</span> cost <span class="op">+</span> lam<span class="op">*</span>np.linalg.norm(w[<span class="dv">1</span>:, :], <span class="st">&#39;fro&#39;</span>)<span class="op">**</span><span class="dv">2</span></span>
<span id="cb34-23"><a href="#cb34-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-24"><a href="#cb34-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># return average</span></span>
<span id="cb34-25"><a href="#cb34-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> cost<span class="op">/</span><span class="bu">float</span>(np.size(y))</span></code></pre></div>
<div class="sourceCode" id="cb35"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co">### fit multi-class perceptron</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autograd.numpy <span class="im">as</span> np</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="co"># define gradient descent parameters</span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>max_its <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> <span class="fl">0.1</span><span class="op">*</span>np.random.randn(<span class="dv">3</span>, <span class="dv">3</span>) <span class="co"># initial starting weights</span></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a><span class="co"># call GD (choose arb alpha for now bc based on chosen g)</span></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>weight_history_3CPT, cost_history_3CPT <span class="op">=</span> gradient_descent(</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>    multiclass_perceptron, <span class="fl">.1</span>, max_its, w)</span></code></pre></div>
<div class="sourceCode" id="cb36"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co">### plot cost history</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="co">## store data</span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>x_plt <span class="op">=</span> np.arange(np.shape(weight_history_3CPT)[<span class="dv">0</span>])</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>y_cost_3CPT <span class="op">=</span> cost_history_3CPT</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a><span class="co">## plot</span></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_cost_history(x, y):</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># use seaborn style</span></span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a>    sns.set_theme()</span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># setup plot</span></span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize <span class="op">=</span> np.array([<span class="dv">5</span>, <span class="dv">5</span>]),</span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a>                            constrained_layout <span class="op">=</span> <span class="va">True</span>) <span class="co"># overall layout, size</span></span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> plt.subplot(<span class="dv">111</span>, frameon <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb36-20"><a href="#cb36-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-21"><a href="#cb36-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># set axis tick sizes</span></span>
<span id="cb36-22"><a href="#cb36-22" aria-hidden="true" tabindex="-1"></a>    ax.xaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb36-23"><a href="#cb36-23" aria-hidden="true" tabindex="-1"></a>    ax.yaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb36-24"><a href="#cb36-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-25"><a href="#cb36-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plot cost history</span></span>
<span id="cb36-26"><a href="#cb36-26" aria-hidden="true" tabindex="-1"></a>    y_cost_3CPT <span class="op">=</span> ax.plot(x, y, color <span class="op">=</span> plt_colours[<span class="dv">0</span>],</span>
<span id="cb36-27"><a href="#cb36-27" aria-hidden="true" tabindex="-1"></a>                        linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb36-28"><a href="#cb36-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-29"><a href="#cb36-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># add labels</span></span>
<span id="cb36-30"><a href="#cb36-30" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="st">&#39;iteration&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb36-31"><a href="#cb36-31" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">&#39;cost&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb36-32"><a href="#cb36-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-33"><a href="#cb36-33" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb36-34"><a href="#cb36-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-35"><a href="#cb36-35" aria-hidden="true" tabindex="-1"></a>plot_cost_history(x_plt, y_cost_3CPT)</span></code></pre></div>
<p><img src="ML_classification-basics_files/figure-html/unnamed-chunk-36-15.png" width="480" /></p>
<div class="sourceCode" id="cb37"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>weight_history_3CPT[<span class="dv">1</span>]</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; array([[ 0.06573661,  0.01541691,  0.20276985],</span></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        [-0.02465962, -0.1375957 , -0.05824389],</span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        [ 0.02797428,  0.09216265, -0.15160187]])</span></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>model(x, w)</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; array([[ 0.02671998,  0.01185122,  0.02747747,  0.04776334,  0.05285182,</span></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;          0.04383541,  0.03613223,  0.04295764,  0.03019206,  0.01846417,</span></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;          0.11328256,  0.09353925,  0.11479853,  0.09061231,  0.0807937 ,</span></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;          0.06893522,  0.07141272,  0.10814671,  0.10072803,  0.11749133,</span></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;          0.01754971,  0.0155085 ,  0.03217638,  0.02676368,  0.00493056,</span></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;          0.02829916,  0.00556571,  0.00828726, -0.00706251,  0.04209431],</span></span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        [ 0.35283678,  0.37264722,  0.27534822,  0.34120135,  0.2203831 ,</span></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;          0.29876139,  0.41624608,  0.18707278,  0.18164218,  0.26270757,</span></span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;         -0.08492133, -0.06352734, -0.28541782, -0.24401699, -0.17614886,</span></span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;         -0.05671885, -0.22639049, -0.35451466, -0.16407254, -0.22641744,</span></span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;         -0.07352672,  0.02353862, -0.07828907, -0.25497499, -0.13349932,</span></span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;         -0.16924497, -0.00675535,  0.11092433,  0.11532398, -0.19768949],</span></span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        [ 0.15707047,  0.22108698,  0.19363217,  0.05792917,  0.09540129,</span></span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;          0.0996643 ,  0.07699936,  0.16220907,  0.22885443,  0.24527345,</span></span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;         -0.04773089,  0.03982989,  0.04908961,  0.14844376,  0.16218981,</span></span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;          0.1592851 ,  0.23524811,  0.11832232,  0.05624597,  0.00490607,</span></span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;          0.42492329,  0.38458551,  0.35428148,  0.47334156,  0.51923687,</span></span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;          0.42102546,  0.45006561,  0.37518389,  0.44962947,  0.36687197]])</span></span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a>np.shape(model(x, w))</span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; (3, 30)</span></span>
<span id="cb37-26"><a href="#cb37-26" aria-hidden="true" tabindex="-1"></a>all_evals <span class="op">=</span> model(x, weight_history_3CPT[<span class="dv">1</span>])</span>
<span id="cb37-27"><a href="#cb37-27" aria-hidden="true" tabindex="-1"></a>np.shape(all_evals)</span>
<span id="cb37-28"><a href="#cb37-28" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; (3, 30)</span></span>
<span id="cb37-29"><a href="#cb37-29" aria-hidden="true" tabindex="-1"></a>np.shape(np.<span class="bu">max</span>(all_evals, axis <span class="op">=</span> <span class="dv">0</span>))</span>
<span id="cb37-30"><a href="#cb37-30" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; (30,)</span></span></code></pre></div>
<div class="sourceCode" id="cb38"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co">### define new function to compute multi-class misclassification history</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> miscount_3CPT(w, x, y):</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 0-2 based on weight that maximizes prediction</span></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># y_pred = np.argmax(np.abs(model(x, w), axis = 0), axis = 0)</span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute prediction for all points</span></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>    all_evals <span class="op">=</span> model(x, w)</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># assign point class of DB that maximumizes distance to DB</span></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> np.argmax(all_evals, axis <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># pairwise compare vectors: 1 if model class pred == true class; sum</span></span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>    miscount_curr <span class="op">=</span> np.<span class="bu">sum</span>(y_pred <span class="op">!=</span> y)</span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> miscount_curr</span></code></pre></div>
<div class="sourceCode" id="cb39"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co">### compute accuracy for optimal weight (minimum misclassifications)</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="co"># compute misclassifications</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>miscount_history_3CPT <span class="op">=</span> [miscount_3CPT(v, x, y) <span class="cf">for</span> v <span class="kw">in</span> weight_history_3CPT]</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="co"># find minimum misclassifications and convert to accuracy</span></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>min_misclass_3CPT <span class="op">=</span> <span class="bu">min</span>(miscount_history_3CPT)</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;multi-class perceptron minimum misclassifications: &quot;</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>      <span class="op">+</span> <span class="bu">str</span>(min_misclass_3CPT))</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a><span class="co"># convert to accuracies</span></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; multi-class perceptron minimum misclassifications: 0</span></span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>accuracy_3CPT <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> (min_misclass_3CPT)<span class="op">/</span>np.shape(x)[<span class="dv">1</span>]</span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;multi-class perceptron accuracy: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(accuracy_3CPT))</span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; multi-class perceptron accuracy: 1.0</span></span></code></pre></div>
</div>
<div id="plotting-the-decision-boundary" class="section level2"
number="4.2">
<h2><span class="header-section-number">4.2</span> Plotting the decision
boundary</h2>
<p>Below we plot the data in the plane, along with the decision boundary
obtained by the multi-class perceptron.</p>
<div class="sourceCode" id="cb40"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># code to clone library from git repo subdirectory</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="co"># (from Ciro Santilli @ https://stackoverflow.com/questions/600079/how-do-i-clone-a-subdirectory-only-of-a-git-repository)</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="co"># git clone \</span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="co">#     --depth 1  \</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a><span class="co">#     --filter=blob:none  \</span></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a><span class="co">#     --sparse \</span></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a><span class="co">#     https://github.com/jermwatt/machine_learning_refined \</span></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a><span class="co"># ;</span></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a><span class="co"># cd machine_learning_refined</span></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a><span class="co"># git sparse-checkout set mlrefined_libraries</span></span></code></pre></div>
<div class="sourceCode" id="cb41"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co">### plot data and decision boundary</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="co"># import relevant MLR plotting libraries (store lib in current dir)</span></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mlrefined_libraries <span class="im">import</span> superlearn_library <span class="im">as</span> superlearn</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mlrefined_libraries <span class="im">import</span> math_optimization_library <span class="im">as</span> optlib</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>optimizers      <span class="op">=</span> optlib.optimizers</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>classif_plotter <span class="op">=</span> superlearn.multi_lin_classification_demo</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>cost_lib        <span class="op">=</span> superlearn.cost_functions</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>normalizers     <span class="op">=</span> superlearn.normalizers</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a><span class="co"># store std. normalized dataset to pass to function (colours = class labels)</span></span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>data_norm <span class="op">=</span> np.append(x, y, axis <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>data_norm[<span class="op">-</span><span class="dv">1</span>,<span class="dv">0</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a><span class="co"># plot individual data points in plane</span></span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a>demo <span class="op">=</span> superlearn.multiclass_illustrator.Visualizer(data_norm)</span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a>demo.show_dataset()</span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a><span class="co"># add DBs (pass weights defining 3 class DBs that give perfect accuracy)</span></span></code></pre></div>
<p><img src="ML_classification-basics_files/figure-html/unnamed-chunk-41-17.png" width="768" /></p>
<div class="sourceCode" id="cb42"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>demo.show_complete_coloring([weight_history_3CPT[<span class="op">-</span><span class="dv">1</span>]], cost <span class="op">=</span> </span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>                            multiclass_perceptron)</span></code></pre></div>
<p>The multi-class perceptron achieves a classification accuracy of
100%, yielding results that are comparable to those shown in <em>Machine
Learning Refined</em>.</p>
<div style="page-break-after: always;"></div>
</div>
</div>
<div id="references" class="section level1" number="5">
<h1><span class="header-section-number">5</span> References</h1>
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>Wolberg, W. H., Street, W. N., &amp; Mangasarian, O. L.
(1992). Breast Cancer Dataset. <em>University of Wisconsin Hospitals,
Madison</em>.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>Dua, D. and Graff, C. (2019). UCI Machine Learning
Repository <a
href="http://archive.ics.uci.edu/ml%5D.">[http://archive.ics.uci.edu/ml].</a>
Irvine, CA: University of California, School of Information and Computer
Science.<br />
<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>Watt, J., Borhani, R., &amp; Katsaggelos, A. K. (2020).
Machine learning refined: Foundations, algorithms, and applications.
Cambridge University Press.<a href="#fnref3"
class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p><a
href="https://github.com/jermwatt/machine_learning_refined/tree/gh-pages/notes/7_Linear_multiclass_classification"
class="uri">https://github.com/jermwatt/machine_learning_refined/tree/gh-pages/notes/7_Linear_multiclass_classification</a><a
href="#fnref4" class="footnote-back">↩︎</a></p></li>
</ol>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
