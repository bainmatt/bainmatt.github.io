<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Matthew Bain" />


<title>Two- &amp; multi-class classification in Python</title>

<!--radix_placeholder_navigation_in_header-->
<meta name="distill:offset" content=""/>

<script type="application/javascript">

  window.headroom_prevent_pin = false;

  window.document.addEventListener("DOMContentLoaded", function (event) {

    // initialize headroom for banner
    var header = $('header').get(0);
    var headerHeight = header.offsetHeight;
    var headroom = new Headroom(header, {
      tolerance: 5,
      onPin : function() {
        if (window.headroom_prevent_pin) {
          window.headroom_prevent_pin = false;
          headroom.unpin();
        }
      }
    });
    headroom.init();
    if(window.location.hash)
      headroom.unpin();
    $(header).addClass('headroom--transition');

    // offset scroll location for banner on hash change
    // (see: https://github.com/WickyNilliams/headroom.js/issues/38)
    window.addEventListener("hashchange", function(event) {
      window.scrollTo(0, window.pageYOffset - (headerHeight + 25));
    });

    // responsive menu
    $('.distill-site-header').each(function(i, val) {
      var topnav = $(this);
      var toggle = topnav.find('.nav-toggle');
      toggle.on('click', function() {
        topnav.toggleClass('responsive');
      });
    });

    // nav dropdowns
    $('.nav-dropbtn').click(function(e) {
      $(this).next('.nav-dropdown-content').toggleClass('nav-dropdown-active');
      $(this).parent().siblings('.nav-dropdown')
         .children('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $("body").click(function(e){
      $('.nav-dropdown-content').removeClass('nav-dropdown-active');
    });
    $(".nav-dropdown").click(function(e){
      e.stopPropagation();
    });
  });
</script>

<style type="text/css">

/* Theme (user-documented overrideables for nav appearance) */

.distill-site-nav {
  color: rgba(255, 255, 255, 0.8);
  background-color: #0F2E3D;
  font-size: 15px;
  font-weight: 300;
}

.distill-site-nav a {
  color: inherit;
  text-decoration: none;
}

.distill-site-nav a:hover {
  color: white;
}

@media print {
  .distill-site-nav {
    display: none;
  }
}

.distill-site-header {

}

.distill-site-footer {

}


/* Site Header */

.distill-site-header {
  width: 100%;
  box-sizing: border-box;
  z-index: 3;
}

.distill-site-header .nav-left {
  display: inline-block;
  margin-left: 8px;
}

@media screen and (max-width: 768px) {
  .distill-site-header .nav-left {
    margin-left: 0;
  }
}


.distill-site-header .nav-right {
  float: right;
  margin-right: 8px;
}

.distill-site-header a,
.distill-site-header .title {
  display: inline-block;
  text-align: center;
  padding: 14px 10px 14px 10px;
}

.distill-site-header .title {
  font-size: 18px;
  min-width: 150px;
}

.distill-site-header .logo {
  padding: 0;
}

.distill-site-header .logo img {
  display: none;
  max-height: 20px;
  width: auto;
  margin-bottom: -4px;
}

.distill-site-header .nav-image img {
  max-height: 18px;
  width: auto;
  display: inline-block;
  margin-bottom: -3px;
}



@media screen and (min-width: 1000px) {
  .distill-site-header .logo img {
    display: inline-block;
  }
  .distill-site-header .nav-left {
    margin-left: 20px;
  }
  .distill-site-header .nav-right {
    margin-right: 20px;
  }
  .distill-site-header .title {
    padding-left: 12px;
  }
}


.distill-site-header .nav-toggle {
  display: none;
}

.nav-dropdown {
  display: inline-block;
  position: relative;
}

.nav-dropdown .nav-dropbtn {
  border: none;
  outline: none;
  color: rgba(255, 255, 255, 0.8);
  padding: 16px 10px;
  background-color: transparent;
  font-family: inherit;
  font-size: inherit;
  font-weight: inherit;
  margin: 0;
  margin-top: 1px;
  z-index: 2;
}

.nav-dropdown-content {
  display: none;
  position: absolute;
  background-color: white;
  min-width: 200px;
  border: 1px solid rgba(0,0,0,0.15);
  border-radius: 4px;
  box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.1);
  z-index: 1;
  margin-top: 2px;
  white-space: nowrap;
  padding-top: 4px;
  padding-bottom: 4px;
}

.nav-dropdown-content hr {
  margin-top: 4px;
  margin-bottom: 4px;
  border: none;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
}

.nav-dropdown-active {
  display: block;
}

.nav-dropdown-content a, .nav-dropdown-content .nav-dropdown-header {
  color: black;
  padding: 6px 24px;
  text-decoration: none;
  display: block;
  text-align: left;
}

.nav-dropdown-content .nav-dropdown-header {
  display: block;
  padding: 5px 24px;
  padding-bottom: 0;
  text-transform: uppercase;
  font-size: 14px;
  color: #999999;
  white-space: nowrap;
}

.nav-dropdown:hover .nav-dropbtn {
  color: white;
}

.nav-dropdown-content a:hover {
  background-color: #ddd;
  color: black;
}

.nav-right .nav-dropdown-content {
  margin-left: -45%;
  right: 0;
}

@media screen and (max-width: 768px) {
  .distill-site-header a, .distill-site-header .nav-dropdown  {display: none;}
  .distill-site-header a.nav-toggle {
    float: right;
    display: block;
  }
  .distill-site-header .title {
    margin-left: 0;
  }
  .distill-site-header .nav-right {
    margin-right: 0;
  }
  .distill-site-header {
    overflow: hidden;
  }
  .nav-right .nav-dropdown-content {
    margin-left: 0;
  }
}


@media screen and (max-width: 768px) {
  .distill-site-header.responsive {position: relative; min-height: 500px; }
  .distill-site-header.responsive a.nav-toggle {
    position: absolute;
    right: 0;
    top: 0;
  }
  .distill-site-header.responsive a,
  .distill-site-header.responsive .nav-dropdown {
    display: block;
    text-align: left;
  }
  .distill-site-header.responsive .nav-left,
  .distill-site-header.responsive .nav-right {
    width: 100%;
  }
  .distill-site-header.responsive .nav-dropdown {float: none;}
  .distill-site-header.responsive .nav-dropdown-content {position: relative;}
  .distill-site-header.responsive .nav-dropdown .nav-dropbtn {
    display: block;
    width: 100%;
    text-align: left;
  }
}

/* Site Footer */

.distill-site-footer {
  width: 100%;
  overflow: hidden;
  box-sizing: border-box;
  z-index: 3;
  margin-top: 30px;
  padding-top: 30px;
  padding-bottom: 30px;
  text-align: center;
}

/* Headroom */

d-title {
  padding-top: 6rem;
}

@media print {
  d-title {
    padding-top: 4rem;
  }
}

.headroom {
  z-index: 1000;
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
}

.headroom--transition {
  transition: all .4s ease-in-out;
}

.headroom--unpinned {
  top: -100px;
}

.headroom--pinned {
  top: 0;
}

/* adjust viewport for navbar height */
/* helps vertically center bootstrap (non-distill) content */
.min-vh-100 {
  min-height: calc(100vh - 100px) !important;
}

</style>

<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<link href="site_libs/font-awesome-6.4.2/css/all.min.css" rel="stylesheet"/>
<link href="site_libs/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet"/>
<script src="site_libs/headroom-0.9.4/headroom.min.js"></script>
<script src="site_libs/autocomplete-0.37.1/autocomplete.min.js"></script>
<script src="site_libs/fuse-6.4.1/fuse.min.js"></script>

<script type="application/javascript">

function getMeta(metaName) {
  var metas = document.getElementsByTagName('meta');
  for (let i = 0; i < metas.length; i++) {
    if (metas[i].getAttribute('name') === metaName) {
      return metas[i].getAttribute('content');
    }
  }
  return '';
}

function offsetURL(url) {
  var offset = getMeta('distill:offset');
  return offset ? offset + '/' + url : url;
}

function createFuseIndex() {

  // create fuse index
  var options = {
    keys: [
      { name: 'title', weight: 20 },
      { name: 'categories', weight: 15 },
      { name: 'description', weight: 10 },
      { name: 'contents', weight: 5 },
    ],
    ignoreLocation: true,
    threshold: 0
  };
  var fuse = new window.Fuse([], options);

  // fetch the main search.json
  return fetch(offsetURL('search.json'))
    .then(function(response) {
      if (response.status == 200) {
        return response.json().then(function(json) {
          // index main articles
          json.articles.forEach(function(article) {
            fuse.add(article);
          });
          // download collections and index their articles
          return Promise.all(json.collections.map(function(collection) {
            return fetch(offsetURL(collection)).then(function(response) {
              if (response.status === 200) {
                return response.json().then(function(articles) {
                  articles.forEach(function(article) {
                    fuse.add(article);
                  });
                })
              } else {
                return Promise.reject(
                  new Error('Unexpected status from search index request: ' +
                            response.status)
                );
              }
            });
          })).then(function() {
            return fuse;
          });
        });

      } else {
        return Promise.reject(
          new Error('Unexpected status from search index request: ' +
                      response.status)
        );
      }
    });
}

window.document.addEventListener("DOMContentLoaded", function (event) {

  // get search element (bail if we don't have one)
  var searchEl = window.document.getElementById('distill-search');
  if (!searchEl)
    return;

  createFuseIndex()
    .then(function(fuse) {

      // make search box visible
      searchEl.classList.remove('hidden');

      // initialize autocomplete
      var options = {
        autoselect: true,
        hint: false,
        minLength: 2,
      };
      window.autocomplete(searchEl, options, [{
        source: function(query, callback) {
          const searchOptions = {
            isCaseSensitive: false,
            shouldSort: true,
            minMatchCharLength: 2,
            limit: 10,
          };
          var results = fuse.search(query, searchOptions);
          callback(results
            .map(function(result) { return result.item; })
          );
        },
        templates: {
          suggestion: function(suggestion) {
            var img = suggestion.preview && Object.keys(suggestion.preview).length > 0
              ? `<img src="${offsetURL(suggestion.preview)}"</img>`
              : '';
            var html = `
              <div class="search-item">
                <h3>${suggestion.title}</h3>
                <div class="search-item-description">
                  ${suggestion.description || ''}
                </div>
                <div class="search-item-preview">
                  ${img}
                </div>
              </div>
            `;
            return html;
          }
        }
      }]).on('autocomplete:selected', function(event, suggestion) {
        window.location.href = offsetURL(suggestion.path);
      });
      // remove inline display style on autocompleter (we want to
      // manage responsive display via css)
      $('.algolia-autocomplete').css("display", "");
    })
    .catch(function(error) {
      console.log(error);
    });

});

</script>

<style type="text/css">

.nav-search {
  font-size: x-small;
}

/* Algolioa Autocomplete */

.algolia-autocomplete {
  display: inline-block;
  margin-left: 10px;
  vertical-align: sub;
  background-color: white;
  color: black;
  padding: 6px;
  padding-top: 8px;
  padding-bottom: 0;
  border-radius: 6px;
  border: 1px #0F2E3D solid;
  width: 180px;
}


@media screen and (max-width: 768px) {
  .distill-site-nav .algolia-autocomplete {
    display: none;
    visibility: hidden;
  }
  .distill-site-nav.responsive .algolia-autocomplete {
    display: inline-block;
    visibility: visible;
  }
  .distill-site-nav.responsive .algolia-autocomplete .aa-dropdown-menu {
    margin-left: 0;
    width: 400px;
    max-height: 400px;
  }
}

.algolia-autocomplete .aa-input, .algolia-autocomplete .aa-hint {
  width: 90%;
  outline: none;
  border: none;
}

.algolia-autocomplete .aa-hint {
  color: #999;
}
.algolia-autocomplete .aa-dropdown-menu {
  width: 550px;
  max-height: 70vh;
  overflow-x: visible;
  overflow-y: scroll;
  padding: 5px;
  margin-top: 3px;
  margin-left: -150px;
  background-color: #fff;
  border-radius: 5px;
  border: 1px solid #999;
  border-top: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion {
  cursor: pointer;
  padding: 5px 4px;
  border-bottom: 1px solid #eee;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion:last-of-type {
  border-bottom: none;
  margin-bottom: 2px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item {
  overflow: hidden;
  font-size: 0.8em;
  line-height: 1.4em;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item h3 {
  font-size: 1rem;
  margin-block-start: 0;
  margin-block-end: 5px;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-description {
  display: inline-block;
  overflow: hidden;
  height: 2.8em;
  width: 80%;
  margin-right: 4%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview {
  display: inline-block;
  width: 15%;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img {
  height: 3em;
  width: auto;
  display: none;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img[src] {
  display: initial;
}

.algolia-autocomplete .aa-dropdown-menu .aa-suggestion.aa-cursor {
  background-color: #eee;
}
.algolia-autocomplete .aa-dropdown-menu .aa-suggestion em {
  font-weight: bold;
  font-style: normal;
}

</style>


<!--/radix_placeholder_navigation_in_header-->
<!--radix_placeholder_site_in_header-->
<!--/radix_placeholder_site_in_header-->

<style type="text/css">
body {
  padding-top: 60px;
}
</style>
<style type="text/css">
/* base variables */

/* Edit the CSS properties in this file to create a custom
   Distill theme. Only edit values in the right column
   for each row; values shown are the CSS defaults.
   To return any property to the default,
   you may set its value to: unset
   All rows must end with a semi-colon.                      */

/* Optional: embed custom fonts here with `@import`          */
/* This must remain at the top of this file.                 */



html {
  /*-- Main font sizes --*/
  --title-size:      50px;
  --body-size:       1.06rem;
  --code-size:       14px;
  --aside-size:      12px;
  --fig-cap-size:    13px;
  /*-- Main font colors --*/
  --title-color:     #000000;
  --header-color:    rgba(0, 0, 0, 0.8);
  --body-color:      rgba(0, 0, 0, 0.8);
  --aside-color:     rgba(0, 0, 0, 0.6);
  --fig-cap-color:   rgba(0, 0, 0, 0.6);
  /*-- Specify custom fonts ~~~ must be imported above   --*/
  --heading-font:    sans-serif;
  --mono-font:       monospace;
  --body-font:       sans-serif;
  --navbar-font:     sans-serif;  /* websites + blogs only */
}

/*-- ARTICLE METADATA --*/
d-byline {
  --heading-size:    0.6rem;
  --heading-color:   rgba(0, 0, 0, 0.5);
  --body-size:       0.8rem;
  --body-color:      rgba(0, 0, 0, 0.8);
}

/*-- ARTICLE TABLE OF CONTENTS --*/
.d-contents {
  --heading-size:    18px;
  --contents-size:   13px;
}

/*-- ARTICLE APPENDIX --*/
d-appendix {
  --heading-size:    15px;
  --heading-color:   rgba(0, 0, 0, 0.65);
  --text-size:       0.8em;
  --text-color:      rgba(0, 0, 0, 0.5);
}

/*-- WEBSITE HEADER + FOOTER --*/
/* These properties only apply to Distill sites and blogs  */

.distill-site-header {
  --title-size:       18px;
  --text-color:       rgba(255, 255, 255, 0.8);
  --text-size:        15px;
  --hover-color:      white;
  --bkgd-color:       #0F2E3D;
}

.distill-site-footer {
  --text-color:       rgba(255, 255, 255, 0.8);
  --text-size:        15px;
  --hover-color:      white;
  --bkgd-color:       #0F2E3D;
}

/*-- Additional custom styles --*/
/* Add any additional CSS rules below                      */
</style>
<style type="text/css">/* ---------------------------------- */
/* --- DEFAULT RMD CUSTOMIZATIONS --- */
/* ---------------------------------- */

/* --- GLOBAL DOCUMENT SETTINGS --- */
body {
    /* font-family:-apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif; */
    /* font-family: 'Gill Sans', 'Gill Sans MT', Calibri, 'Trebuchet MS', sans-serif; */
    /* font-family: 'Lucida Sans', 'Lucida Sans Regular', 'Lucida Grande', 'Lucida Sans Unixcode', Geneva, Verdana, sans-serif; */
    /* font-size: 12pt; */  
    /* font-weight: 100; */
}

/* --- HEADERS --- */
h1, h2, h3 {
  /* padding-top: 10em; */
  padding-bottom: .3em;
  /* margin-top: 10em; */
  margin-bottom: .75em;
  /* border-top: 10px; */
  border-bottom: 1px solid #eee; /* add horizontal rule under each header */
  /* font-size: 14pt, 13pt, 12pt, 11pt; */
  /* font-weight: 320; */
}

h1 {
  font-size: 19pt;                                    /* alt: 19pt */
}

h2 {
  font-size: 16pt;                                    /* alt: 16pt */
}

h3 {
  font-size: 13pt;                                    /* alt: 13pt */
}

/* --- CODE --- */
code {
  /* font-size: 12px; */
  /* font-weight: 550; */
}

/* --- ORDERED LISTS --- */
/* Bulletted list items padding */
ul {
  margin-top: 0; 
  margin-bottom: 0;
}

ul > li {
  margin-bottom: 2px;
}

/* Numbered list items padding */
ol {
  margin-top: 0; /* Remove default top margin for the list */
  margin-bottom: 0; /* Remove default bottom margin for the list */
}

ol > li {
  margin-bottom: 2px; /* Adjust the spacing between list items as needed */
}

/* --- OTHER --- */
/* --- Supress page title from  displaying in knit but keep metadata --- */
#header {
  display: none;
}

/* --- FLOATING TOC --- */
/* Change background colour */
.tocify-item {
    /* background-color: rgb(251, 250, 247); */
    font-size: 10pt;
}

.tocify-subheader {
    font-size: 9.75pt;
}

/* Ensure floating TOC idents successive lines */
.tocify-subheader > .tocify-item {
    text-indent: initial;
    padding-left: 2em;
}

/*
scope {
  --a-property:       50px;
  --another-property: #fff;
}
*/

/* -------------------------------------- */
/* --- FURTHER DISTILL CUSTOMIZATIONS --- */
/* -------------------------------------- */

/* base variables */

/* Edit the CSS properties in this file to create a custom
   Distill theme. Only edit values in the right column
   for each row; values shown are the CSS defaults.
   To return any property to the default,
   you may set its value to: unset
   All rows must end with a semi-colon.                      */

/* Optional: embed custom fonts here with `@import`          */
/* This must remain at the top of this file.                 */
@import url('https://fonts.googleapis.com/css?family=Noto+Serif+JP:300, 300i&display=swap');
@import url('https://fonts.googleapis.com/css?family=Lato:400,400i,700&display=swap');
@import url('https://fonts.googleapis.com/css?family=IBM+Plex+Mono&display=swap');

html {
  /*-- Main font sizes --*/
  --title-size:      44px;                        /* default: 50px */
  --body-size:       1.06rem;                      /* default: 1.06rem */                  
  --code-size:       13.25px;                     /* default: 14px */                  
  --aside-size:      12px;                        /* default: 12px */                  
  --fig-cap-size:    13.5px;                        /* default: 13px */
  
  /* [MB] Left justify figure captions */


  /* [MB] Bold the "Figure" or "Table" tag */

  
  /*
  --title-size:      30x;                         
  --body-size:       0.9rem;                    
  --code-size:       13.25px;                     
  --aside-size:      11px;                        
  --fig-cap-size:    12px;                        
  */
  
  /*-- Main font colors --*/
  --title-color:     #ca225e;                     /* default: #ca225e */
  --header-color:    #ca225e;                     /* theme: #ca225e */
  --body-color:      #404040;                     /* theme: #404040 */
  --aside-color:     rgba(0, 0, 0, 0.6);
  --fig-cap-color:   rgba(0, 0, 0, 0.6);
  /*-- Specify custom fonts ~~~ must be imported above   --*/
  --heading-font:    "Noto Serif JP", sans-serif; /* theme */
  --mono-font:       "IBM Plex Mono", monospace;  /* theme */
  --body-font:       "Lato", sans-serif;          /* theme */
  --navbar-font:     "Lato", sans-serif;          /* theme */
  
  /*
  --heading-font:    "Amiri", serif;
  --mono-font:       "DM Mono", monospace;
  --body-font:       "Bitter", sans-serif;
  --navbar-font:     "Amiri", serif;
  */
}

/*-- ARTICLE METADATA --*/
d-byline {
  --heading-size:    0.9rem;                      /* theme: 0.9rem */
  --heading-color:   rgba(0, 0, 0, 0.5);          /* default: rgba(0, 0, 0, 0.5) */
  --body-size:       0.95rem;                     /* theme: 0.95rem */
  --body-color:      rgba(0, 0, 0, 0.8);          /* default: rgba(0, 0, 0, 0.8) */
  
  /* [MB] Hide the Author field */
  .author,
  {
    display: none;                              
  }
}

/*-- ARTICLE TABLE OF CONTENTS --*/
.d-contents {
  --heading-size:    18px;                        /* default: 18px */
  --contents-size:   13px;                        /* default: 13px */
}

/*-- ARTICLE APPENDIX --*/
d-appendix {
  --heading-size:    15px;                        /* default: 15px */
  --heading-color:   rgba(0, 0, 0, 0.65);         /* default: rgba(0, 0, 0, 0.65) */
  --text-size:       0.9rem;                      /* theme: 0.9rem */
  --text-color:      #1a162d;                     /* theme: 0.9rem */
}

/*-- WEBSITE HEADER + FOOTER --*/
/* These properties only apply to Distill sites and blogs  */
.distill-site-header {
  --title-size:       18px;                       /* default: 18px */
  --text-color:       #1f1f1f;                    /* theme: #1f1f1f */
  --text-size:        15px;                       /* default: 15px */
  --hover-color:      #787878;                    /* default: #787878 */
  --bkgd-color:       #fff;                       /* theme: #fff */
  
  /*
  --title-size:       18px;    
  --text-color:       #ff414b;
  --text-size:        15px;
  --hover-color:      #dd424c;
  --bkgd-color:       #ffd8db;
  */
}

.distill-site-footer {
  --text-color:       #7e7b88;                    /* theme: #7e7b88 */
  --text-size:        15px;                       /* default: 15px */
  --hover-color:      white;                      /* defaultl: white */
  --bkgd-color:       #ca225e3d;                  /* theme: #ca225e3d */
}

/*-- ADDITIONAL CUSTOM STYLES --*/
/* Ordered list index colour */
ul > li::marker {                 
  color: #ca225e;                                 /* default: #ca225e */
}

ol > li::marker {                 
  color: #ca225e;                                 /* default: #ca225e */
}

/* Navigation bar letter case */
.distill-site-header { 
  letter-spacing: 2px;                            /* default: 2px */
  /*text-transform: uppercase;*/                      /* default: uppercase */
}

/* Font weights and letter spacing */
h1, h2, h3, h4, h5, h6 {
  letter-spacing: 2px;                            /* default: 2px */
  font-weight: 300;                               /* default: 300 */
}

/* Makes logo bigger */
.distill-site-header .logo img{
  max-height: 40px;                               /* theme: 20px */
}

.distill-site-header {
  padding-top: 1rem;                              /* default: 1rem */
}

d-title h1,
d-article h2,
.posts-list .description h2,
.posts-list > h1 {
    font-weight: 300;                             /* default: 300 */
}

d-appendix {
  background-color: #fdf7f9;                      /* default: #fdf7f9 */
  border-top: none;                               /* default: none */
}</style>
<style type="text/css">
/* base style */

/* FONT FAMILIES */

:root {
  --heading-default: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  --mono-default: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  --body-default: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
}

body,
.posts-list .post-preview p,
.posts-list .description p {
  font-family: var(--body-font), var(--body-default);
}

h1, h2, h3, h4, h5, h6,
.posts-list .post-preview h2,
.posts-list .description h2 {
  font-family: var(--heading-font), var(--heading-default);
}

d-article div.sourceCode code,
d-article pre code {
  font-family: var(--mono-font), var(--mono-default);
}


/*-- TITLE --*/
d-title h1,
.posts-list > h1 {
  color: var(--title-color, black);
}

d-title h1 {
  font-size: var(--title-size, 50px);
}

/*-- HEADERS --*/
d-article h1,
d-article h2,
d-article h3,
d-article h4,
d-article h5,
d-article h6 {
  color: var(--header-color, rgba(0, 0, 0, 0.8));
}

/*-- BODY --*/
d-article > p,  /* only text inside of <p> tags */
d-article > ul, /* lists */
d-article > ol {
  color: var(--body-color, rgba(0, 0, 0, 0.8));
  font-size: var(--body-size, 1.06rem);
}


/*-- CODE --*/
d-article div.sourceCode code,
d-article pre code {
  font-size: var(--code-size, 14px);
}

/*-- ASIDE --*/
d-article aside {
  font-size: var(--aside-size, 12px);
  color: var(--aside-color, rgba(0, 0, 0, 0.6));
}

/*-- FIGURE CAPTIONS --*/
figure .caption,
figure figcaption,
.figure .caption {
  font-size: var(--fig-cap-size, 13px);
  color: var(--fig-cap-color, rgba(0, 0, 0, 0.6));
}

/*-- METADATA --*/
d-byline h3 {
  font-size: var(--heading-size, 0.6rem);
  color: var(--heading-color, rgba(0, 0, 0, 0.5));
}

d-byline {
  font-size: var(--body-size, 0.8rem);
  color: var(--body-color, rgba(0, 0, 0, 0.8));
}

d-byline a,
d-article d-byline a {
  color: var(--body-color, rgba(0, 0, 0, 0.8));
}

/*-- TABLE OF CONTENTS --*/
.d-contents nav h3 {
  font-size: var(--heading-size, 18px);
}

.d-contents nav a {
  font-size: var(--contents-size, 13px);
}

/*-- APPENDIX --*/
d-appendix h3 {
  font-size: var(--heading-size, 15px);
  color: var(--heading-color, rgba(0, 0, 0, 0.65));
}

d-appendix {
  font-size: var(--text-size, 0.8em);
  color: var(--text-color, rgba(0, 0, 0, 0.5));
}

d-appendix d-footnote-list a.footnote-backlink {
  color: var(--text-color, rgba(0, 0, 0, 0.5));
}

/*-- WEBSITE HEADER + FOOTER --*/
.distill-site-header .title {
  font-size: var(--title-size, 18px);
  font-family: var(--navbar-font), var(--heading-default);
}

.distill-site-header a,
.nav-dropdown .nav-dropbtn {
  font-family: var(--navbar-font), var(--heading-default);
}

.nav-dropdown .nav-dropbtn {
  color: var(--text-color, rgba(255, 255, 255, 0.8));
  font-size: var(--text-size, 15px);
}

.distill-site-header a:hover,
.nav-dropdown:hover .nav-dropbtn {
  color: var(--hover-color, white);
}

.distill-site-header {
  font-size: var(--text-size, 15px);
  color: var(--text-color, rgba(255, 255, 255, 0.8));
  background-color: var(--bkgd-color, #0F2E3D);
}

.distill-site-footer {
  font-size: var(--text-size, 15px);
  color: var(--text-color, rgba(255, 255, 255, 0.8));
  background-color: var(--bkgd-color, #0F2E3D);
}

.distill-site-footer a:hover {
  color: var(--hover-color, white);
}</style>
<script src="/Users/matthewbain/Library/R/arm64/4.3/library/rmarkdown/rmd/h/pandoc/header-attrs.js"></script>
<script src="/Users/matthewbain/Library/R/arm64/4.3/library/jquerylib/lib/3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="/Users/matthewbain/Library/R/arm64/4.3/library/rmarkdown/rmd/h/bootstrap/css/cosmo.min.css" rel="stylesheet" />
<script src="/Users/matthewbain/Library/R/arm64/4.3/library/rmarkdown/rmd/h/bootstrap/js/bootstrap.min.js"></script>
<script src="/Users/matthewbain/Library/R/arm64/4.3/library/rmarkdown/rmd/h/bootstrap/shim/html5shiv.min.js"></script>
<script src="/Users/matthewbain/Library/R/arm64/4.3/library/rmarkdown/rmd/h/bootstrap/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="/Users/matthewbain/Library/R/arm64/4.3/library/rmarkdown/rmd/h/jqueryui/jquery-ui.min.js"></script>
<link href="/Users/matthewbain/Library/R/arm64/4.3/library/rmarkdown/rmd/h/tocify/jquery.tocify.css" rel="stylesheet" />
<script src="/Users/matthewbain/Library/R/arm64/4.3/library/rmarkdown/rmd/h/tocify/jquery.tocify.js"></script>
<script src="/Users/matthewbain/Library/R/arm64/4.3/library/rmarkdown/rmd/h/navigation-1.1/tabsets.js"></script>
<link href="/Users/matthewbain/Library/R/arm64/4.3/library/fontawesome/fontawesome/css/all.min.css" rel="stylesheet" />
<link href="/Users/matthewbain/Library/R/arm64/4.3/library/fontawesome/fontawesome/css/v4-shims.min.css" rel="stylesheet" />
<link rel="shortcut icon" href="favicon.jpg">

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>



<style type="text/css">
  code {
    white-space: pre;
  }
  .sourceCode {
    overflow: visible;
  }
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; } /* Alert */
code span.an { color: #008000; } /* Annotation */
code span.at { } /* Attribute */
code span.bu { } /* BuiltIn */
code span.cf { color: #0000ff; } /* ControlFlow */
code span.ch { color: #008080; } /* Char */
code span.cn { color: #585cf6; } /* Constant */
code span.co { color: #4c886b; } /* Comment */
code span.cv { color: #008000; } /* CommentVar */
code span.do { color: #008000; } /* Documentation */
code span.dv { color: #0000cd; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cd; } /* Float */
code span.im { } /* Import */
code span.in { color: #008000; } /* Information */
code span.kw { color: #0000ff; } /* Keyword */
code span.op { color: #687687; } /* Operator */
code span.ot { color: #ff4000; } /* Other */
code span.pp { color: #ff4000; } /* Preprocessor */
code span.sc { color: #008080; } /* SpecialChar */
code span.ss { color: #008080; } /* SpecialString */
code span.st { color: #036a07; } /* String */
code span.va { } /* Variable */
code span.vs { color: #008080; } /* VerbatimString */
code span.wa { color: #008000; font-weight: bold; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<link rel="stylesheet" href="generic-css.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">



<!--radix_placeholder_navigation_before_body-->
<header class="header header--fixed" role="banner">
<nav class="distill-site-nav distill-site-header">
<div class="nav-left">
<a href="index.html" class="title">data-driven-brain</a>
<div class="nav-dropdown">
<button class="nav-dropbtn">
data guides
 
<span class="down-arrow">&#x25BE;</span>
</button>
<div class="nav-dropdown-content">
<span class="nav-dropdown-header">--- tours ---</span>
<span class="nav-dropdown-header">Classification in R</span>
<span class="nav-dropdown-header">Classification in Python</span>
<span class="nav-dropdown-header">Frequentist hypothesis testing in R</span>
<span class="nav-dropdown-header">--- templates ---</span>
<a href="writing_temp_typora2rmd.html">Writing template</a>
<a href="stylesheet_tests.html">Plotting roadmap</a>
<span class="nav-dropdown-header">--- worked ---</span>
</div>
</div>
<div class="nav-dropdown">
<button class="nav-dropbtn">
data projects
 
<span class="down-arrow">&#x25BE;</span>
</button>
<div class="nav-dropdown-content">
<span class="nav-dropdown-header">[placeholder]</span>
</div>
</div>
<a href="music_page.html">original music</a>
<div class="nav-dropdown">
<button class="nav-dropbtn">
blog
 
<span class="down-arrow">&#x25BE;</span>
</button>
<div class="nav-dropdown-content">
<a href="math_gallery.html">Math</a>
<span class="nav-dropdown-header">Machines</span>
<span class="nav-dropdown-header">Art</span>
</div>
</div>
<input id="distill-search" class="nav-search hidden" type="text" placeholder="Search..."/>
</div>
<div class="nav-right">
<a href="https://github.com/mattlabcode">
<i class="fab fa-github fa-lg" aria-hidden="true"></i>
</a>
<a href="https://www.linkedin.com/in/matthew-bain314/">
<i class="fab fa-linkedin fa-lg" aria-hidden="true"></i>
</a>
<a href="https://www.youtube.com/@fujinai9/featured">
<i class="fa fa-youtube fa-lg" aria-hidden="true"></i>
</a>
<a href="https://soundcloud.com/user-752823440">
<i class="fa fa-brands fa-soundcloud" aria-hidden="true"></i>
</a>
<a href="javascript:void(0);" class="nav-toggle">&#9776;</a>
</div>
</nav>
</header>
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">data-driven-brain</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    data guides
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">--- tours ---</li>
    <li class="dropdown-header">Classification in R</li>
    <li class="dropdown-header">Classification in Python</li>
    <li class="dropdown-header">Frequentist hypothesis testing in R</li>
    <li class="dropdown-header">--- templates ---</li>
    <li>
      <a href="writing_temp_typora2rmd.html">Writing template</a>
    </li>
    <li>
      <a href="stylesheet_tests.html">Plotting roadmap</a>
    </li>
    <li class="dropdown-header">--- worked ---</li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    data projects
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">[placeholder]</li>
  </ul>
</li>
<li>
  <a href="music_page.html">original music</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    blog
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="math_gallery.html">Math</a>
    </li>
    <li class="dropdown-header">Machines</li>
    <li class="dropdown-header">Art</li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/mattlabcode">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://www.linkedin.com/in/matthew-bain314/">
    <span class="fab fa-linkedin fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://www.youtube.com/@fujinai9/featured">
    <span class="fa fa-youtube fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://soundcloud.com/user-752823440">
    <span class="fa fa-brands fa-soundcloud"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Two- &amp; multi-class classification in Python</h1>
<h4 class="author">Matthew Bain</h4>

</div>


<hr>
<em>This page is a placeholder.</em>
<hr>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">### load dependencies</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># essentials</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy.linalg <span class="im">as</span> LA           <span class="co"># linalg module of numpy</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd                 <span class="co"># pandas for data manipulation</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autograd.numpy <span class="im">as</span> np         <span class="co"># autograd-wrapped numpy</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># optimization</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> autograd <span class="im">import</span> grad           <span class="co"># module for computing gradient</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> autograd <span class="im">import</span> value_and_grad <span class="co"># returns grad &amp; val of input function</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># plotting</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt     <span class="co"># pyplot module of matplotlib</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co"># global plotting parameters</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>plt_colours <span class="op">=</span> (np.array([<span class="dv">94</span>,<span class="dv">255</span>,<span class="dv">231</span>])<span class="op">/</span><span class="dv">360</span>, np.array([<span class="dv">133</span>,<span class="dv">94</span>,<span class="dv">214</span>])<span class="op">/</span><span class="dv">360</span>,</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>               np.array([<span class="dv">110</span>,<span class="dv">250</span>,<span class="dv">152</span>])<span class="op">/</span><span class="dv">360</span>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>font_size   <span class="op">=</span> <span class="dv">14</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>font_name   <span class="op">=</span> {<span class="st">&#39;fontname&#39;</span>: <span class="st">&#39;Avenir&#39;</span>}</span></code></pre></div>
<div id="exercise-1-predicting-breast-cancer" class="section level1" number="1">
<h1><span class="header-section-number">1</span> <strong>Exercise 1</strong> Predicting breast cancer</h1>
<p>In this problem we examine the <a href="https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)">Breast Cancer Data Set</a>, obtained from the University of Wisconsin Hospitals, Madison from Dr. William H. Wolberg <a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>.</p>
<div id="softmax-perceptron-costs" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> Softmax &amp; perceptron costs</h2>
<p>In this exercise we implement the softmax and perceptron cost functions.</p>
<p><em>notes</em></p>
<ul>
<li>class labels are coded as <span class="math inline">\(1\)</span> for benign, <span class="math inline">\(-1\)</span> for malignant.</li>
<li>the dataset is arranged in columns, each corresponding to an individual &amp; each row a cellular measurement.</li>
<li>Class labels are stored in the final row.</li>
</ul>
<p>Below we import the dataset.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">### setup dataset</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># data input</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>csvname <span class="op">=</span> <span class="st">&#39;data/breast_cancer_data.csv&#39;</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.loadtxt(csvname, delimiter <span class="op">=</span> <span class="st">&#39;,&#39;</span>)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co"># get input and output of dataset</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> data[:<span class="op">-</span><span class="dv">1</span>, :]   <span class="co"># feature vectors</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data[<span class="op">-</span><span class="dv">1</span>:, :]   <span class="co"># class labels {1,-1}</span></span></code></pre></div>
<p>We now define our model and complete an implementation of the softmax and perceptron cost functions.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co">### define model and cost functions</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># define model (compute linear combination of input points)</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> model(x, w):</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    a <span class="op">=</span> w[<span class="dv">0</span>] <span class="op">+</span> np.dot(x.T, w[<span class="dv">1</span>:])</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> a.T</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co">## cost functions (`g`)</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co"># softmax cost implementation</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># note: x,y req. by cost but def. globally s.t. for given w compute cost</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="co"># across all x,y)</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> softmax(w):</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># note: equivalent to softnax aoprox to perceptron cost, below</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    cost <span class="op">=</span> np.<span class="bu">sum</span>(np.log(<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>y<span class="op">*</span>model(x, w))))</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> cost<span class="op">/</span><span class="bu">float</span>(np.size(y))</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="co"># perceptron cost implementation</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> perceptron(w):</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># sum of pair-wise maximum between 0, model values</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    cost <span class="op">=</span> np.<span class="bu">sum</span>(np.maximum(<span class="dv">0</span>, <span class="op">-</span>y<span class="op">*</span>model(x, w)))</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> cost<span class="op">/</span><span class="bu">float</span>(np.size(y))</span></code></pre></div>
</div>
<div id="minimizing-cost-functions" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> Minimizing cost functions</h2>
<p>We will now optimize these cost functions using gradient descent.</p>
<p>Below we define the standard gradient descent algorithm.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co">### GD function</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gradient_descent(g, alpha, max_its, w):</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  <span class="im">import</span> autograd.numpy <span class="im">as</span> np</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>  <span class="im">from</span> autograd <span class="im">import</span> grad</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># define alpha based on chosen cost function</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># alpha = 1.0 if g == softmax else .1</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> g <span class="op">==</span> softmax: alpha <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">elif</span> g <span class="op">==</span> perceptron: alpha <span class="op">=</span> <span class="fl">.1</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>  <span class="cf">elif</span> g <span class="op">==</span> cross_entropy: alpha <span class="op">=</span> <span class="fl">.6</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># compute gradient (wrt w, holding constant x,y)</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>  gradient <span class="op">=</span> grad(g)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>  <span class="co"># run GD loop</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>  weight_history <span class="op">=</span> [w] <span class="co"># weight history container</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>  cost_history <span class="op">=</span> [g(w)] <span class="co"># cost function history container</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(max_its):</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># evaluate the gradient</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>    grad_eval <span class="op">=</span> gradient(w)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># take gradient descent step</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>    w <span class="op">=</span> w <span class="op">-</span> alpha<span class="op">*</span>grad_eval</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># record weight and cost</span></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>    weight_history.append(w)</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>    cost_history.append(g(w))</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> weight_history, cost_history</span></code></pre></div>
<p>Below we define our parameters and then minimize both cost functions.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co">### optimize cost functions</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autograd.numpy <span class="im">as</span> np</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># define gradient descent (GD) parameters</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>max_its <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> <span class="fl">0.1</span><span class="op">*</span>np.random.randn(<span class="dv">9</span>, <span class="dv">1</span>) <span class="co"># initial starting weights</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co"># call GD (choose arb alpha for now bc based on chosen g)</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>weight_history_SM, cost_history_SM <span class="op">=</span> gradient_descent(softmax, <span class="dv">1</span>,</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>                                                      max_its, w)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>weight_history_PT, cost_history_PT <span class="op">=</span> gradient_descent(perceptron, <span class="dv">1</span>,</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>                                                      max_its, w)</span></code></pre></div>
</div>
<div id="misclassifications" class="section level2" number="1.3">
<h2><span class="header-section-number">1.3</span> Misclassifications</h2>
<p>We now compute the number of misclassifications for each iteration of gradient descent.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">### compute misclassification history</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autograd.numpy <span class="im">as</span> np</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># compute misclassification history</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> miscount(w, x, y):</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># +1 or -1 whether above or below fitted decision bound determined by w</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> np.sign(model(x, w))</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># pairwise compare vectors: 1 if model class pred == true class; sum</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    miscount_curr <span class="op">=</span> np.<span class="bu">sum</span>(y_pred <span class="op">!=</span> y)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> miscount_curr</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co"># compute miscount history for each cost function</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>miscount_history_SM <span class="op">=</span> [miscount(v, x, y) <span class="cf">for</span> v <span class="kw">in</span> weight_history_SM]</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>miscount_history_PT <span class="op">=</span> [miscount(v, x, y) <span class="cf">for</span> v <span class="kw">in</span> weight_history_PT]</span></code></pre></div>
</div>
<div id="plotting-cost-and-misclassifications" class="section level2" number="1.4">
<h2><span class="header-section-number">1.4</span> <strong>Plotting</strong>: cost and misclassifications</h2>
<p>Below we plot the cost and misclassification history for each cost function.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co">### define function for plotting cost and misclassification hist in same figure</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_cost_and_miscount(data):</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># store data</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    x_plt           <span class="op">=</span> data[<span class="st">&quot;x_plt&quot;</span>]</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    y_miscount_SM   <span class="op">=</span> data[<span class="st">&quot;y_miscount_SM&quot;</span>]</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    y_cost_SM       <span class="op">=</span> data[<span class="st">&quot;y_cost_SM&quot;</span>]</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    y_miscount_PT   <span class="op">=</span> data[<span class="st">&quot;y_miscount_PT&quot;</span>]</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    y_cost_PT       <span class="op">=</span> data[<span class="st">&quot;y_cost_PT&quot;</span>]</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># use seaborn style</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    sns.set_theme()</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># to prevent warning messages from appearing in the report</span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> warnings<span class="op">;</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>    warnings.filterwarnings(<span class="st">&#39;ignore&#39;</span>)</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># set inline figure format/quality, overall params</span></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># %config InlineBackend.figure_format = &#39;svg&#39;</span></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># setup plot &amp; subplots</span></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>    fig, axs <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>, figsize <span class="op">=</span> np.array([<span class="fl">6.5</span>, <span class="dv">8</span>]),</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>                            constrained_layout <span class="op">=</span> <span class="va">True</span>) <span class="co"># overall layout, size</span></span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># axs[0] = plt.subplot(1,3,(1,2), frameon = 1)</span></span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>] <span class="op">=</span> plt.subplot(<span class="dv">211</span>, frameon <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>] <span class="op">=</span> plt.subplot(<span class="dv">212</span>, frameon <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># set axis tick sizes</span></span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].xaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].yaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].xaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].yaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plot overlay of misclassifications &amp; costs for each cost over it</span></span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>    line_miscount_SM    <span class="op">=</span> axs[<span class="dv">0</span>].plot(x_plt, y_miscount_SM,</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>                                      color <span class="op">=</span> plt_colours[<span class="dv">0</span>],</span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>                                      linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>    line_miscount_PT    <span class="op">=</span> axs[<span class="dv">0</span>].plot(x_plt, y_miscount_PT,</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a>                                      color <span class="op">=</span> plt_colours[<span class="dv">1</span>],</span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>                                      linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>    line_cost_SM        <span class="op">=</span> axs[<span class="dv">1</span>].plot(x_plt, y_cost_SM,</span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>                                      color <span class="op">=</span> plt_colours[<span class="dv">0</span>],</span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>                                      linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a>    line_cost_PT        <span class="op">=</span> axs[<span class="dv">1</span>].plot(x_plt, y_cost_PT,</span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a>                                      color <span class="op">=</span> plt_colours[<span class="dv">1</span>],</span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>                                      linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a>    <span class="co"># add labels</span></span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a>    <span class="co"># axs[0].set_xlabel(&#39;iteration&#39;, fontsize = font_size, **font_name)</span></span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].set_xlabel(<span class="st">&#39;iteration&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].set_ylabel(<span class="st">&#39;misclassifications&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb7-56"><a href="#cb7-56" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].set_xlabel(<span class="st">&#39;iteration&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb7-57"><a href="#cb7-57" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].set_ylabel(<span class="st">&#39;cost&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb7-58"><a href="#cb7-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-59"><a href="#cb7-59" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plot legend</span></span>
<span id="cb7-60"><a href="#cb7-60" aria-hidden="true" tabindex="-1"></a>    leg_labels <span class="op">=</span> [<span class="st">&#39;softmax&#39;</span>, <span class="st">&#39;perceptron&#39;</span>]</span>
<span id="cb7-61"><a href="#cb7-61" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].legend([line_miscount_SM, line_miscount_PT], labels <span class="op">=</span> leg_labels,</span>
<span id="cb7-62"><a href="#cb7-62" aria-hidden="true" tabindex="-1"></a>    loc <span class="op">=</span> <span class="st">&#39;upper right&#39;</span>, frameon <span class="op">=</span> <span class="dv">1</span>, fontsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb7-63"><a href="#cb7-63" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].legend([line_cost_SM, line_cost_PT], labels <span class="op">=</span> leg_labels,</span>
<span id="cb7-64"><a href="#cb7-64" aria-hidden="true" tabindex="-1"></a>                  loc <span class="op">=</span> <span class="st">&#39;upper right&#39;</span>, frameon <span class="op">=</span> <span class="dv">1</span>, fontsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb7-65"><a href="#cb7-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-66"><a href="#cb7-66" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code></pre></div>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co">### store data and plot</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># store plotting data in data frame</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>plot_data <span class="op">=</span> pd.DataFrame(</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;x_plt&quot;</span>: np.arange(np.size(miscount_history_SM)),</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_miscount_SM&quot;</span>: miscount_history_SM,</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_cost_SM&quot;</span>: cost_history_SM,</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_miscount_PT&quot;</span>: miscount_history_PT,</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_cost_PT&quot;</span>: cost_history_PT</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="co"># plot</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>plot_cost_and_miscount(plot_data)</span></code></pre></div>
<p>Below we identify and return the minimum number of misclassifications for each cost function over all iterations of gradient descent.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co">### identify minima</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>min_misclass_SM <span class="op">=</span> <span class="bu">min</span>(miscount_history_SM)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>min_misclass_PT <span class="op">=</span> <span class="bu">min</span>(miscount_history_PT)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;softmax minimum misclassifications:    &quot;</span> <span class="op">+</span> <span class="bu">str</span>(min_misclass_SM))</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;perceptron minimum misclassifications: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(min_misclass_PT))</span></code></pre></div>
<p>Below we modify the <code>miscount</code> function to consider only misclassified malignant cases (i.e., cases corresponding to the class label <span class="math inline">\(-1\)</span>).</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co">#### define misclassification rate</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autograd.numpy <span class="im">as</span> np</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># compute misclassification history</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> miscount_neg(w, x, y):</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># +1 or -1 whether above or below fitted decision bound determined by w</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> np.sign(model(x, w))</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># consider only malignant cases</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    miscount_curr <span class="op">=</span> np.<span class="bu">sum</span>(y_pred[y <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>] <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> miscount_curr</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a><span class="co"># compute new miscount history for each cost function</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>miscount_history_SM_neg <span class="op">=</span> [miscount_neg(v, x, y) <span class="cf">for</span> v <span class="kw">in</span> weight_history_SM]</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>miscount_history_PT_neg <span class="op">=</span> [miscount_neg(v, x, y) <span class="cf">for</span> v <span class="kw">in</span> weight_history_PT]</span></code></pre></div>
<p>Below we again plot misclassification and cost history side-by-side, this time considering only misclassified malignant cases.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co">### store data and plot</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="co"># import pandas for data frame capabilities</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># store plotting data in data frame</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>plot_data <span class="op">=</span> pd.DataFrame(</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;x_plt&quot;</span>: np.arange(np.size(miscount_history_SM_neg)),</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_miscount_SM&quot;</span>: miscount_history_SM_neg,</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_cost_SM&quot;</span>: cost_history_SM,</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_miscount_PT&quot;</span>: miscount_history_PT_neg,</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_cost_PT&quot;</span>: cost_history_PT</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="co"># plot</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>plot_cost_and_miscount(plot_data)</span></code></pre></div>
</div>
<div id="logistic-regression-cross-entropy" class="section level2" number="1.5">
<h2><span class="header-section-number">1.5</span> Logistic regression &amp; cross-entropy</h2>
<p>In this exercise we compare the above results to those obtained using logistic regression with a cross entropy cost.</p>
<p>The provided code below converts our class labels <code>y</code> = <span class="math inline">\(\{-1, 1\}\)</span> to <span class="math inline">\(\{0, 1\}\)</span>.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co">### setup dataset</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>y_1 <span class="op">=</span> np.squeeze(y) <span class="co"># flatten y (one dimension)</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>y_ben <span class="op">=</span> np.argwhere(y_1 <span class="op">&gt;</span> <span class="fl">0.9</span>) <span class="co"># returns all indices where y meets condition</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>y_mal <span class="op">=</span> np.argwhere(y_1 <span class="op">&lt;</span> <span class="op">-</span><span class="fl">0.9</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>yc <span class="op">=</span> np.arange(<span class="dv">699</span>) <span class="co"># class labels (`y`) for CE (cross-entropy) cost</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>yc[y_ben] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>yc[y_mal] <span class="op">=</span> <span class="dv">0</span></span></code></pre></div>
<p>The code below (provided to us) implements the cross entropy cost function, with L2 regularization.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co">### define model and cross entropy cost</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="co"># define sigmoid function</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sigmoid(t):</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>t))</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co">## the (convex) cross-entropy cost function</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>lam <span class="op">=</span> <span class="dv">2</span><span class="op">*</span><span class="dv">10</span><span class="op">**</span>(<span class="op">-</span><span class="dv">3</span>) <span class="co"># regularization parameter</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> cross_entropy(w):</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute sigmoid of model</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    sig_eval <span class="op">=</span> sigmoid(model(x, w))</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute cost of label 0 points</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    ind_mal <span class="op">=</span> np.argwhere(yc <span class="op">==</span> <span class="dv">0</span>)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>    cost <span class="op">=</span> <span class="op">-</span>np.<span class="bu">sum</span>(np.log(<span class="dv">1</span> <span class="op">-</span> sig_eval[:, ind_mal]))</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># add (subtract) cost on label 1 points</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>    ind_ben <span class="op">=</span> np.argwhere(yc <span class="op">==</span> <span class="dv">1</span>)</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>    cost <span class="op">-=</span> np.<span class="bu">sum</span>(np.log(sig_eval[:, ind_ben]))</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># add regularizer (* regularization parameter)</span></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>    cost <span class="op">+=</span> lam<span class="op">*</span>np.<span class="bu">sum</span>(w[<span class="dv">1</span>:]<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute cross-entropy</span></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> cost<span class="op">/</span><span class="bu">float</span>(np.size(yc))</span></code></pre></div>
<p>Below we run gradient descent to optimize the cross entropy cost function for logistic regression.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co">### optimize cost function using GD</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autograd.numpy <span class="im">as</span> np</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># define gradient descent parameters</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>max_its <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> <span class="fl">0.1</span><span class="op">*</span>np.random.randn(<span class="dv">9</span>, <span class="dv">1</span>) <span class="co"># initial starting weights</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co"># call GD (choose arb alpha for now bc based on chosen g)</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>weight_history_CE, cost_history_CE <span class="op">=</span> gradient_descent(cross_entropy, <span class="dv">1</span>,</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>                                                      max_its, w)</span></code></pre></div>
<p>We now compute misclassification history. To do so we must modify <code>miscount</code> to compute misclassifications in a manner appropriate to logistic regression. Since the sigmoid function varies between 0 and 1 and is symmetric (about a <span class="math inline">\(180^{\circ}\)</span> rotation centered at <span class="math inline">\((0, 0.5)\)</span>), we can use <span class="math inline">\(y = 0.5\)</span> to effectively separate our predictions into the two classes labelled <span class="math inline">\(\{0, 1\}\)</span>. Then, as before, we can determine misclassiffications by comparing the predicted classes across <code>weight_history</code> with the true class labels.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co">### compute misclassification history</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autograd.numpy <span class="im">as</span> np</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co"># compute misclassification history</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> miscount_CE(w, x, y):</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> np.sign(model(x, w))        <span class="co"># 1 or 1 if eval &gt; .5</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># convert predictions to classes based on y = .5 threshold  value</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>    y_pred[y_pred <span class="op">&gt;=</span> <span class="fl">.5</span>]    <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    y_pred[y_pred <span class="op">&lt;</span> <span class="fl">.5</span>]     <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># pairwise compare vectors: 1 if model class pred == true class; sum</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>    miscount_curr <span class="op">=</span> np.<span class="bu">sum</span>(y_pred <span class="op">!=</span> y)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> miscount_curr</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a><span class="co"># compute new miscount history for cross entropy cost</span></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>miscount_history_CE <span class="op">=</span> [miscount_CE(v, x, yc) <span class="cf">for</span> v <span class="kw">in</span> weight_history_CE]</span></code></pre></div>
<p>And finally, below we plot cost and misclassification history for the logistic regression cross entropy cost, as we did above for the softmax and perceptron cost functions (alongside the results for the perceptron cost function). First we make a couple minor modifications to generalize our plotting function and allow us to plot cross entropy cost in addition to softmax cost.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co">### define plotting function</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_cost_and_miscount(data):</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># store data</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    x_plt           <span class="op">=</span> data[<span class="st">&quot;x_plt&quot;</span>]</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># y_miscount_1    = data[&quot;y_miscount_CE&quot;]</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># y_cost_1        = data[&quot;y_cost_CE&quot;]</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># y_miscount_2    = data[&quot;y_miscount_PT&quot;]</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># y_cost_2        = data[&quot;y_cost_PT&quot;]</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    y_miscount_1    <span class="op">=</span> data.iloc[:, <span class="dv">1</span>]</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>    y_cost_1        <span class="op">=</span> data.iloc[:, <span class="dv">2</span>]</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>    y_miscount_2    <span class="op">=</span> data.iloc[:, <span class="dv">3</span>]</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>    y_cost_2        <span class="op">=</span> data.iloc[:, <span class="dv">4</span>]</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># use seaborn style</span></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>    sns.set_theme()</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># to prevent warning messages from appearing in the report</span></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> warnings<span class="op">;</span></span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>    warnings.filterwarnings(<span class="st">&#39;ignore&#39;</span>)</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># set inline figure format/quality, overall params</span></span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># %config InlineBackend.figure_format = &#39;svg&#39;</span></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># setup plot &amp; subplots</span></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>    fig, axs <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>, figsize <span class="op">=</span> np.array([<span class="fl">6.5</span>, <span class="dv">8</span>]),</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>                            constrained_layout <span class="op">=</span> <span class="va">True</span>) <span class="co"># overall layout, size</span></span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># axs[0] = plt.subplot(1,3,(1,2), frameon = 1)</span></span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>] <span class="op">=</span> plt.subplot(<span class="dv">211</span>, frameon <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>] <span class="op">=</span> plt.subplot(<span class="dv">212</span>, frameon <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># set axis tick sizes</span></span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].xaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].yaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].xaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].yaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plot overlay of misclassifications &amp; costs for each cost over all it</span></span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a>    line_miscount_CE    <span class="op">=</span> axs[<span class="dv">0</span>].plot(x_plt, y_miscount_1,</span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a>                                      color <span class="op">=</span> plt_colours[<span class="dv">0</span>],</span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a>                                      linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a>    line_miscount_PT    <span class="op">=</span> axs[<span class="dv">0</span>].plot(x_plt, y_miscount_2,</span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a>                                      color <span class="op">=</span> plt_colours[<span class="dv">1</span>],</span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a>                                      linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a>    line_cost_CE        <span class="op">=</span> axs[<span class="dv">1</span>].plot(x_plt, y_cost_1,</span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a>                                      color <span class="op">=</span> plt_colours[<span class="dv">0</span>],</span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a>                                      linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb16-52"><a href="#cb16-52" aria-hidden="true" tabindex="-1"></a>    line_cost_PT        <span class="op">=</span> axs[<span class="dv">1</span>].plot(x_plt, y_cost_2,</span>
<span id="cb16-53"><a href="#cb16-53" aria-hidden="true" tabindex="-1"></a>                                      color <span class="op">=</span> plt_colours[<span class="dv">1</span>],</span>
<span id="cb16-54"><a href="#cb16-54" aria-hidden="true" tabindex="-1"></a>                                      linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb16-55"><a href="#cb16-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-56"><a href="#cb16-56" aria-hidden="true" tabindex="-1"></a>    <span class="co"># add labels</span></span>
<span id="cb16-57"><a href="#cb16-57" aria-hidden="true" tabindex="-1"></a>    <span class="co"># axs[0].set_xlabel(&#39;iteration&#39;, fontsize = font_size, **font_name)</span></span>
<span id="cb16-58"><a href="#cb16-58" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].set_xlabel(<span class="st">&#39;iteration&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb16-59"><a href="#cb16-59" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].set_ylabel(<span class="st">&#39;misclassifications&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb16-60"><a href="#cb16-60" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].set_xlabel(<span class="st">&#39;iteration&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb16-61"><a href="#cb16-61" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].set_ylabel(<span class="st">&#39;cost&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb16-62"><a href="#cb16-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-63"><a href="#cb16-63" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plot legend</span></span>
<span id="cb16-64"><a href="#cb16-64" aria-hidden="true" tabindex="-1"></a>    leg_labels <span class="op">=</span> [<span class="st">&#39;cross entropy&#39;</span>, <span class="st">&#39;perceptron&#39;</span>]</span>
<span id="cb16-65"><a href="#cb16-65" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">0</span>].legend([line_miscount_CE, line_miscount_PT], labels <span class="op">=</span> leg_labels,</span>
<span id="cb16-66"><a href="#cb16-66" aria-hidden="true" tabindex="-1"></a>                  loc <span class="op">=</span> <span class="st">&#39;upper right&#39;</span>, frameon <span class="op">=</span> <span class="dv">1</span>, fontsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb16-67"><a href="#cb16-67" aria-hidden="true" tabindex="-1"></a>    axs[<span class="dv">1</span>].legend([line_cost_CE, line_cost_PT], labels <span class="op">=</span> leg_labels,</span>
<span id="cb16-68"><a href="#cb16-68" aria-hidden="true" tabindex="-1"></a>                  loc <span class="op">=</span> <span class="st">&#39;upper right&#39;</span>, frameon <span class="op">=</span> <span class="dv">1</span>, fontsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb16-69"><a href="#cb16-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-70"><a href="#cb16-70" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code></pre></div>
<div class="sourceCode" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co">### store data and plot</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># store plotting data in data frame</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>plot_data <span class="op">=</span> pd.DataFrame(</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;x_plt&quot;</span>: np.arange(np.size(miscount_history_CE)),</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_miscount_CE&quot;</span>: miscount_history_CE,</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_cost_CE&quot;</span>: cost_history_CE,</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_miscount_PT&quot;</span>: miscount_history_PT,</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_cost_PT&quot;</span>: cost_history_PT</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="co"># plot</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>plot_cost_and_miscount(plot_data)</span></code></pre></div>
</div>
</div>
<div id="exercise-2-spam-detection" class="section level1" number="2">
<h1><span class="header-section-number">2</span> <strong>Exercise 2</strong> Spam detection</h1>
<p>In this problem we examinine the <a href="https://archive.ics.uci.edu/ml/datasets/Spambase">Spambase Data Set</a> <a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>, containing measurements of spam and non-spam emails. Using the two-class classification methods we explored in the above exercises, we build a classifier to determine if an email is likely to be spam.</p>
<p><em>notes</em></p>
<p>Class labels (1 for spam, -1 for not spam) are again stored in the final row (<span class="math inline">\(N = 58\)</span>) of the dataset, with each other row <span class="math inline">\(n\)</span> representing a feature (word/character frequencies, etc.) and each column <span class="math inline">\(p\)</span> a sample (<span class="math inline">\(P = 4601\)</span>).</p>
<p>Below we import the dataset.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co">### import dataset</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co"># data input</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>csvname <span class="op">=</span> <span class="st">&#39;data/spambase_data.csv&#39;</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.loadtxt(csvname, delimiter <span class="op">=</span> <span class="st">&#39;,&#39;</span>)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co"># get input and output of dataset</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> data[:<span class="op">-</span><span class="dv">1</span>, :]    <span class="co"># feature vectors</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data[<span class="op">-</span><span class="dv">1</span>:, :]    <span class="co"># class labels {1,-1}</span></span></code></pre></div>
<div id="some-basic-preprocessing" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Some basic preprocessing</h2>
<p>We now perform some preproc`essing to prepare the dataset for our analysis. We standard normalize each feature (s.t. <span class="math inline">\(\mu_n = 0\)</span> and <span class="math inline">\(\sigma_n = 1\)</span>, where <span class="math inline">\(\mu\)</span> represents the mean and <span class="math inline">\(\sigma\)</span> the standard deviation) so that they can be treated equally by our classifier. To do so, for each observation <span class="math inline">\(x_{n,p}\)</span> we subtract the corresponding mean <span class="math inline">\(\mu_n\)</span> and divide by the corresponding standard deviation <span class="math inline">\(\sigma_n\)</span>.</p>
<p>To deal with missing observations for a given feature (represented as <code>NaN</code>), we replace <code>NaN</code> with the corresponding feature mean <span class="math inline">\(\mu_n\)</span>.</p>
<p>The following function (provided to us) executes the above.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co">### perform standard normalization and fill in missing data</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> standard_normalizer(x):</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute the mean and standard deviation of each feature</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    x_means <span class="op">=</span> np.nanmean(x, axis <span class="op">=</span> <span class="dv">1</span>)[:, np.newaxis]</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    x_stds  <span class="op">=</span> np.nanstd(x, axis <span class="op">=</span> <span class="dv">1</span>)[:, np.newaxis]</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># check to make sure that x_stds &gt; small threshold; for those not</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># divide by 1 instead of original standard deviation</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>    ind <span class="op">=</span> np.argwhere(x_stds <span class="op">&lt;</span> <span class="dv">10</span><span class="op">**</span>(<span class="op">-</span><span class="dv">2</span>))</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(ind) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>        ind <span class="op">=</span> [v[<span class="dv">0</span>] <span class="cf">for</span> v <span class="kw">in</span> ind] <span class="co"># just keep row index</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>        adjust <span class="op">=</span> np.zeros((x_stds.shape)) <span class="co"># array of indices to replace with 1</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>        adjust[ind] <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>        x_stds <span class="op">+=</span> adjust</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># fill in any nan values with corresponding feature mean</span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>    ind <span class="op">=</span> np.argwhere(np.isnan(x) <span class="op">==</span> <span class="va">True</span>)</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> ind:</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>        x[i[<span class="dv">0</span>], i[<span class="dv">1</span>]] <span class="op">=</span> x_means[i[<span class="dv">0</span>]]</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># create standard normalizer function</span></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>    normalizer <span class="op">=</span> <span class="kw">lambda</span> data: (data <span class="op">-</span> x_means)<span class="op">/</span>x_stds</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># create inverse standard normalizer</span></span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>    inverse_normalizer <span class="op">=</span> <span class="kw">lambda</span> data: data<span class="op">*</span>x_stds <span class="op">+</span> x_means</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># return (inverse) normalizer</span></span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> normalizer, inverse_normalizer</span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a><span class="co">## standard normalize dataset</span></span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>normalizer, inverse_normalizer <span class="op">=</span> standard_normalizer(x) <span class="co"># get std norm functions</span></span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> normalizer(x)</span></code></pre></div>
</div>
<div id="email-classification-with-perceptron" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Email classification with perceptron</h2>
<p>In this exercise we classify emails using the softmax and perceptron cost functions.</p>
<p><strong>Steps:</strong></p>
<p>We carry out the same sequence of steps covered in detail in exercise 1:</p>
<ol style="list-style-type: decimal">
<li><p>Identify optimal decision boundary (determined by weights <span class="math inline">\(w\)</span>):</p>
<ul>
<li>run gradient descent to identify <span class="math inline">\(w\)</span> that minimizes cost functions</li>
<li>softmax: <span class="math inline">\(\alpha = 1.0\)</span>; perceptron: <span class="math inline">\(\alpha = 0.1\)</span></li>
<li>other parameters: <code>max its = 1000</code>; <code>w = 0.1*np.random.randn(N + 1, 1)</code>, where <span class="math inline">\(N = 57\)</span></li>
</ul></li>
<li><p>Compute misclassification histories</p></li>
<li><p>Plot cost and misclassification as a function of gradient descent iteration</p></li>
</ol>
<div class="sourceCode" id="cb20"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co">### 1) optimize softmax and perceptron costs over `spambase` dataset</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autograd.numpy <span class="im">as</span> np</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="co"># define gradient descent parameters</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>max_its <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> <span class="fl">0.1</span><span class="op">*</span>np.random.randn(np.shape(x)[<span class="dv">0</span>] <span class="op">+</span> <span class="dv">1</span>, <span class="dv">1</span>) <span class="co"># initial starting weights</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="co"># call GD (choose arb alpha for now bc based on chosen g)</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>weight_history_SM_spam, cost_history_SM_spam <span class="op">=</span> gradient_descent(softmax, <span class="dv">1</span>,</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>                                                        max_its, w)</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>weight_history_PT_spam, cost_history_PT_spam <span class="op">=</span> gradient_descent(perceptron, <span class="dv">1</span>,</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>                                                        max_its, w)</span></code></pre></div>
<div class="sourceCode" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co">### 2) compute misclassification history for each cost function</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>miscount_history_SM_spam <span class="op">=</span> [miscount(v, x, y) <span class="cf">for</span> v <span class="kw">in</span> weight_history_SM_spam]</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>miscount_history_PT_spam <span class="op">=</span> [miscount(v, x, y) <span class="cf">for</span> v <span class="kw">in</span> weight_history_PT_spam]</span></code></pre></div>
<div class="sourceCode" id="cb22"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co">### 3) for each cost, plot cost and misclassification as a function of iteration</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="co">## store data and plot</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="co"># store plotting data in data frame</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>plot_data <span class="op">=</span> pd.DataFrame(</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;x_plt&quot;</span>: np.arange(np.size(miscount_history_SM_spam)),</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_miscount_SM&quot;</span>: miscount_history_SM_spam,</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_cost_SM&quot;</span>: cost_history_SM_spam,</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_miscount_PT&quot;</span>: miscount_history_PT_spam,</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;y_cost_PT&quot;</span>: cost_history_PT_spam</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="co">## plot</span></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>plot_cost_and_miscount(plot_data)</span></code></pre></div>
<p>The plots above reveal some interesting results. The perceptron cost appears to attain a stable minimum cost, but its misclassification history appears to fluctuate rapidly between ~250 and 750 misclassifications. On the other hand, the softmax cost appears to attain a stable, albeit higher, minimum cost, but its misclassification history reaches a similar minimum to the softmax cost and is stable (does not fluctate rapidly). This suggests that the perceptron cost function is not perfectly flat at the identified minimum, causing minor perturbations in weight to produce large deviations from the minimum. It is possible that different (non-standard) gradient descent schemes (e.g., fully normalized) would eliminate this behaviour.</p>
</div>
<div id="accuracy" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> Accuracy</h2>
<p>In this exercise we determine the misclassification minimum and convert it to accuracy.</p>
<p><em>Recall</em>: we define accuracy, <span class="math inline">\(\mathcal{A}\)</span> as</p>
<p><span class="math display">\[
\mathcal{A} = 1 - \frac{1}{P} \sum\limits_{p = 1}^P I(\hat{y}_p, y_p) ,
\]</span></p>
<p>where <span class="math inline">\(\sum\limits_{p = 1}^P I\)</span> represents total misclassifications, which we average over all samples <span class="math inline">\(P\)</span> and subtract from 1.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co">### determine minimum misclassifications for each cost and convert to accuracy</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="co"># identify minima</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>min_misclass_SM_spam <span class="op">=</span> <span class="bu">min</span>(miscount_history_SM_spam)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>min_misclass_PT_spam <span class="op">=</span> <span class="bu">min</span>(miscount_history_PT_spam)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;softmax minimum misclassifications:    &quot;</span> <span class="op">+</span> <span class="bu">str</span>(min_misclass_SM_spam))</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;perceptron minimum misclassifications: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(min_misclass_PT_spam))</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="co"># convert to accuracies</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>accuracy_SM_spam <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> (min_misclass_SM_spam)<span class="op">/</span>np.shape(x)[<span class="dv">1</span>]</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>accuracy_PT_spam <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> (min_misclass_PT_spam)<span class="op">/</span>np.shape(x)[<span class="dv">1</span>]</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">softmax accuracy:    &quot;</span> <span class="op">+</span> <span class="bu">str</span>(accuracy_SM_spam))</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;perceptron accuracy: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(accuracy_PT_spam))</span></code></pre></div>
<p>As we can see above, both classifiers, trained using a softmax and perceptron cost, respectively, appear to perform relatively well, with accuracies above 90%. However, softmax cost performs slighly better, with 3 fewer misclassifications than the perceptron. This result reflects our expectations based on the misclassification and cost histories plotted above.</p>
</div>
<div id="confusion-matrix" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> Confusion matrix</h2>
<p>In this exercise we identify the optimal <code>w</code> found by the softmax cost and construct the corresponding confusion matrix <a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co">### construct confusion matrix for optimal softmax `w`</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="co">## define model again (compute linear combination of input points)</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> model(x, w):</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    a <span class="op">=</span> w[<span class="dv">0</span>] <span class="op">+</span> np.dot(x.T, w[<span class="dv">1</span>:])</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> a.T</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a><span class="co">## identify optimal `w` for cost</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>w_optimal_SM_spam <span class="op">=</span> weight_history_SM_spam[np.argmin(miscount_history_SM_spam)]</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a><span class="co"># w_optimal_PT_spam = weight_history_PT_spam[np.argmin(miscount_history_PT_spam)]</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a><span class="co">### function for plotting confusion matrix</span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_confusion_matrix(w, x, y):</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># +1 or -1 whether above or below fitted decision bound determined by w</span></span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> np.sign(model(x, w))</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>    <span class="co">## determine confusion matrix values (true pos/neg, false pos/neg)</span></span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>    TP <span class="op">=</span> np.<span class="bu">sum</span>(y_pred[y <span class="op">==</span> <span class="dv">1</span>] <span class="op">==</span> <span class="dv">1</span>)</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>    TN <span class="op">=</span> np.<span class="bu">sum</span>(y_pred[y <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>] <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>    FP <span class="op">=</span> np.<span class="bu">sum</span>(y_pred[y <span class="op">==</span> <span class="op">-</span><span class="dv">1</span>] <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>    FN <span class="op">=</span> np.<span class="bu">sum</span>(y_pred[y <span class="op">==</span> <span class="dv">1</span>] <span class="op">!=</span> <span class="dv">1</span>)</span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># store values in dictionary, matrix for plotting</span></span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>    confusion_matrix_OP <span class="op">=</span> {<span class="st">&quot;TP&quot;</span>: TP, <span class="st">&quot;TN&quot;</span>: TN, <span class="st">&quot;FP&quot;</span>: FP, <span class="st">&quot;FN&quot;</span>: FN}</span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># confusion_matrix_OP[&quot;TN&quot;] = TN</span></span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a>    conf_matrix <span class="op">=</span> np.array([[TP, FN],</span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a>                            [FP, TN]])</span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a>    <span class="co">## plot confusion matrix</span></span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># set annotations for tiles based on counts</span></span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a>    group_names <span class="op">=</span> [<span class="st">&#39;TP&#39;</span>, <span class="st">&#39;FN&#39;</span>, <span class="st">&#39;FP&#39;</span>, <span class="st">&#39;TN&#39;</span>]</span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a>    group_counts <span class="op">=</span> [<span class="st">&quot;</span><span class="sc">{0:0.0f}</span><span class="st">&quot;</span>.<span class="bu">format</span>(value) <span class="cf">for</span> value <span class="kw">in</span> conf_matrix.flatten()]</span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a>    group_percentages <span class="op">=</span> [<span class="st">&quot;</span><span class="sc">{0:.2%}</span><span class="st">&quot;</span>.<span class="bu">format</span>(value) <span class="cf">for</span> value <span class="kw">in</span></span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a>                         conf_matrix.flatten()<span class="op">/</span>np.<span class="bu">sum</span>(conf_matrix)]</span>
<span id="cb24-39"><a href="#cb24-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-40"><a href="#cb24-40" aria-hidden="true" tabindex="-1"></a>    tile_labels <span class="op">=</span> [<span class="ss">f&quot;</span><span class="sc">{</span>v1<span class="sc">}</span><span class="ch">\n</span><span class="sc">{</span>v2<span class="sc">}</span><span class="ch">\n</span><span class="sc">{</span>v3<span class="sc">}</span><span class="ss">&quot;</span> <span class="cf">for</span> v1, v2, v3 <span class="kw">in</span></span>
<span id="cb24-41"><a href="#cb24-41" aria-hidden="true" tabindex="-1"></a>                   <span class="bu">zip</span>(group_names, group_counts, group_percentages)]</span>
<span id="cb24-42"><a href="#cb24-42" aria-hidden="true" tabindex="-1"></a>    tile_labels <span class="op">=</span> np.asarray(tile_labels).reshape(<span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb24-43"><a href="#cb24-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-44"><a href="#cb24-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plot</span></span>
<span id="cb24-45"><a href="#cb24-45" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> sns.heatmap(conf_matrix, annot <span class="op">=</span> tile_labels, fmt <span class="op">=</span> <span class="st">&#39;&#39;</span>, cmap <span class="op">=</span> <span class="st">&#39;Blues&#39;</span>)</span>
<span id="cb24-46"><a href="#cb24-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-47"><a href="#cb24-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># labels</span></span>
<span id="cb24-48"><a href="#cb24-48" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">Predicted Values&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb24-49"><a href="#cb24-49" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">&#39;Actual Values</span><span class="ch">\n</span><span class="st">&#39;</span>, fontsize <span class="op">=</span> font_size)<span class="op">;</span></span>
<span id="cb24-50"><a href="#cb24-50" aria-hidden="true" tabindex="-1"></a>    ax.xaxis.set_ticklabels([<span class="st">&#39;Spam&#39;</span>, <span class="st">&#39;Not spam&#39;</span>], fontsize <span class="op">=</span> font_size)</span>
<span id="cb24-51"><a href="#cb24-51" aria-hidden="true" tabindex="-1"></a>    ax.yaxis.set_ticklabels([<span class="st">&#39;Spam&#39;</span>, <span class="st">&#39;Not spam&#39;</span>], fontsize <span class="op">=</span> font_size)</span>
<span id="cb24-52"><a href="#cb24-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-53"><a href="#cb24-53" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb24-54"><a href="#cb24-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-55"><a href="#cb24-55" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> confusion_matrix_OP</span>
<span id="cb24-56"><a href="#cb24-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-57"><a href="#cb24-57" aria-hidden="true" tabindex="-1"></a><span class="co">## plot confusion matrix for softmax and optimal weight</span></span>
<span id="cb24-58"><a href="#cb24-58" aria-hidden="true" tabindex="-1"></a>confusion_matrix <span class="op">=</span> plot_confusion_matrix(w_optimal_SM_spam, x, y)</span></code></pre></div>
</div>
</div>
<div id="exercise-3-credit-check" class="section level1" number="3">
<h1><span class="header-section-number">3</span> <strong>Exercise 3</strong> Credit check</h1>
<p>In this problem we examinine a dataset containing credit ratings, described in Example 6.11 of <em>Machine Learning Refined</em>.</p>
<p><em>notes</em></p>
<ul>
<li>Class labels (1 for good rating, -1 for bad rating) are again stored in the final row of the dataset (<span class="math inline">\(N = 20\)</span>), with each other row <span class="math inline">\(n\)</span> representing a feature (account balance, duration of previous credit, etc.) and each column <span class="math inline">\(p\)</span> a sample (<span class="math inline">\(P = 1000\)</span>).</li>
</ul>
<p>Below we import the dataset.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co">### import dataset</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="co"># data input</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>csvname <span class="op">=</span> <span class="st">&#39;data/credit_dataset.csv&#39;</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.loadtxt(csvname, delimiter <span class="op">=</span> <span class="st">&#39;,&#39;</span>)</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="co"># get input and output of dataset</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> data[:<span class="op">-</span><span class="dv">1</span>, :]    <span class="co"># feature vectors</span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data[<span class="op">-</span><span class="dv">1</span>:, :]    <span class="co"># class labels {1,-1}</span></span></code></pre></div>
<div id="standard-normalization" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Standard normalization</h2>
<p>Below we standard normalize the dataset so that features can be compared.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co">### perform standard normalization</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>normalizer, inverse_normalizer <span class="op">=</span> standard_normalizer(x) <span class="co"># get std norm functions</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> normalizer(x)</span></code></pre></div>
</div>
<div id="fitting-perceptron-based-classifier" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Fitting perceptron-based classifier</h2>
<p>Below we fit a binary classifier using a perceptron cost.</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co">### optimize perceptron cost over `credit rating` dataset</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autograd.numpy <span class="im">as</span> np</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="co"># define gradient descent parameters</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>max_its <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> <span class="fl">0.1</span><span class="op">*</span>np.random.randn(np.shape(x)[<span class="dv">0</span>] <span class="op">+</span> <span class="dv">1</span>, <span class="dv">1</span>) <span class="co"># initial starting weights</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="co"># call GD (choose arb alpha for now bc based on chosen g)</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>weight_history_PT_cred, cost_history_PT_cred <span class="op">=</span> gradient_descent(perceptron, <span class="dv">1</span>,</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>                                                        max_its, w)</span></code></pre></div>
<div class="sourceCode" id="cb28"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co">### compute misclassification history</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>miscount_history_PT_cred <span class="op">=</span> [miscount(v, x, y) <span class="cf">for</span> v <span class="kw">in</span> weight_history_PT_cred]</span></code></pre></div>
<div class="sourceCode" id="cb29"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co">### store data for plotting</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="co"># store plotting data</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>x_plt <span class="op">=</span> np.arange(np.size(miscount_history_PT_cred))</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>y_miscount_PT <span class="op">=</span> miscount_history_PT_cred</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>y_cost_PT <span class="op">=</span> cost_history_PT_cred</span></code></pre></div>
<div class="sourceCode" id="cb30"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co">### plot cost and misclassification history for perceptron cost</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a><span class="co"># use seaborn style</span></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>sns.set_theme()</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a><span class="co"># to prevent warning messages from appearing in the report</span></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings<span class="op">;</span></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">&#39;ignore&#39;</span>)</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a><span class="co"># set inline figure format/quality, overall params</span></span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a><span class="co"># %config InlineBackend.figure_format = &#39;svg&#39;</span></span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a><span class="co"># setup plot &amp; subplots</span></span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>, figsize <span class="op">=</span> np.array([<span class="fl">6.5</span>, <span class="dv">8</span>]),</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>                        constrained_layout <span class="op">=</span> <span class="va">True</span>) <span class="co"># overall layout, size</span></span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a><span class="co"># axs[0] = plt.subplot(1,3,(1,2), frameon = 1)</span></span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>] <span class="op">=</span> plt.subplot(<span class="dv">211</span>, frameon <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>] <span class="op">=</span> plt.subplot(<span class="dv">212</span>, frameon <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a><span class="co"># set axis tick sizes</span></span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].xaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].yaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].xaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].yaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb30-29"><a href="#cb30-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-30"><a href="#cb30-30" aria-hidden="true" tabindex="-1"></a><span class="co"># plot overlay of misclassifications &amp; costs for each cost over all it</span></span>
<span id="cb30-31"><a href="#cb30-31" aria-hidden="true" tabindex="-1"></a>line_miscount_CE    <span class="op">=</span> axs[<span class="dv">0</span>].plot(x_plt, y_miscount_PT,</span>
<span id="cb30-32"><a href="#cb30-32" aria-hidden="true" tabindex="-1"></a>                                  color <span class="op">=</span> plt_colours[<span class="dv">0</span>],</span>
<span id="cb30-33"><a href="#cb30-33" aria-hidden="true" tabindex="-1"></a>                                  linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb30-34"><a href="#cb30-34" aria-hidden="true" tabindex="-1"></a>line_cost_CE        <span class="op">=</span> axs[<span class="dv">1</span>].plot(x_plt, y_cost_PT,</span>
<span id="cb30-35"><a href="#cb30-35" aria-hidden="true" tabindex="-1"></a>                                  color <span class="op">=</span> plt_colours[<span class="dv">0</span>],</span>
<span id="cb30-36"><a href="#cb30-36" aria-hidden="true" tabindex="-1"></a>                                  linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb30-37"><a href="#cb30-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-38"><a href="#cb30-38" aria-hidden="true" tabindex="-1"></a><span class="co"># add labels</span></span>
<span id="cb30-39"><a href="#cb30-39" aria-hidden="true" tabindex="-1"></a><span class="co"># axs[0].set_xlabel(&#39;iteration&#39;, fontsize = font_size, **font_name)</span></span>
<span id="cb30-40"><a href="#cb30-40" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].set_xlabel(<span class="st">&#39;iteration&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb30-41"><a href="#cb30-41" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">0</span>].set_ylabel(<span class="st">&#39;misclassifications&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb30-42"><a href="#cb30-42" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].set_xlabel(<span class="st">&#39;iteration&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb30-43"><a href="#cb30-43" aria-hidden="true" tabindex="-1"></a>axs[<span class="dv">1</span>].set_ylabel(<span class="st">&#39;cost&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb30-44"><a href="#cb30-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-45"><a href="#cb30-45" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="sourceCode" id="cb31"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co">### compute and output perceptron accuracy</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>min_misclass_PT_cred <span class="op">=</span> <span class="bu">min</span>(miscount_history_PT_cred)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>accuracy_PT_cred <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> (min_misclass_PT_cred)<span class="op">/</span>np.shape(x)[<span class="dv">1</span>]</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;perceptron accuracy: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(accuracy_PT_cred))</span></code></pre></div>
<p>The perceptron achieves a classification accuracy of ~76%, which is within the range of the accuracy achieved in <em>Machine Learning Refined</em>.</p>
</div>
<div id="confusion-matrix-1" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Confusion matrix</h2>
<p>We now plot the confusion matrix corresponding to the optimal weight identified by the perceptron.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co">### plot confusion matrix for perceptron and optimal weight</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>w_optimal_PT_cred <span class="op">=</span> weight_history_PT_cred[np.argmin(miscount_history_PT_cred)]</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>confusion_matrix <span class="op">=</span> plot_confusion_matrix(w_optimal_PT_cred, x, y)</span></code></pre></div>
</div>
</div>
<div id="exercise-4-three-class-classification" class="section level1" number="4">
<h1><span class="header-section-number">4</span> <strong>Exercise 4</strong> Three-class classification</h1>
<p>In this problem we examine a three-class toy dataset, shown in Fig. 7.9 of <em>Machine Learning Refined</em>, using the multi-class perceptron. Additional resources (including plotting functions) are provided in the official MLR git repository <a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>.</p>
<div id="fitting-multi-class-perceptron" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Fitting multi-class perceptron</h2>
<p>Below we fit the multi-class perceptron to the dataset.</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co">### import dataset &amp; standard normalize</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="co"># data input</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>csvname <span class="op">=</span> <span class="st">&#39;data/3class_data.csv&#39;</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> np.loadtxt(csvname, delimiter <span class="op">=</span> <span class="st">&#39;,&#39;</span>)</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="co"># get input and output of dataset</span></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> data[:<span class="op">-</span><span class="dv">1</span>, :]    <span class="co"># feature vectors</span></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data[<span class="op">-</span><span class="dv">1</span>:, :]    <span class="co"># class labels {1,-1}</span></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a><span class="co">## normalize</span></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>normalizer, inverse_normalizer <span class="op">=</span> standard_normalizer(x) <span class="co"># get std norm functions</span></span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> normalizer(x)</span></code></pre></div>
<div class="sourceCode" id="cb34"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co">### define model and multi-class perceptron (*provided code*)</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="co">## compute C linear combinations of input point, one per classifier</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> model(x, w):</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>    a <span class="op">=</span> w[<span class="dv">0</span>] <span class="op">+</span> np.dot(x.T, w[<span class="dv">1</span>:])</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> a.T</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a><span class="co">## multi-class perceptron</span></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>lam <span class="op">=</span> <span class="dv">10</span><span class="op">**-</span><span class="dv">5</span>  <span class="co"># regularization paramter</span></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> multiclass_perceptron(w):</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># pre-compute predictions on all points</span></span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>    all_evals <span class="op">=</span> model(x, w)</span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute maximum across data points</span></span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a>    a <span class="op">=</span> np.<span class="bu">max</span>(all_evals, axis <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute cost in compact form using numpy broadcasting</span></span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a>    b <span class="op">=</span> all_evals[y.astype(<span class="bu">int</span>).flatten(), np.arange(np.size(y))]</span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a>    cost <span class="op">=</span> np.<span class="bu">sum</span>(a <span class="op">-</span> b)</span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># add regularizer</span></span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a>    cost <span class="op">=</span> cost <span class="op">+</span> lam<span class="op">*</span>np.linalg.norm(w[<span class="dv">1</span>:, :], <span class="st">&#39;fro&#39;</span>)<span class="op">**</span><span class="dv">2</span></span>
<span id="cb34-23"><a href="#cb34-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-24"><a href="#cb34-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># return average</span></span>
<span id="cb34-25"><a href="#cb34-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> cost<span class="op">/</span><span class="bu">float</span>(np.size(y))</span></code></pre></div>
<div class="sourceCode" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co">### fit multi-class perceptron</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> autograd.numpy <span class="im">as</span> np</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="co"># define gradient descent parameters</span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>max_its <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> <span class="fl">0.1</span><span class="op">*</span>np.random.randn(<span class="dv">3</span>, <span class="dv">3</span>) <span class="co"># initial starting weights</span></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a><span class="co"># call GD (choose arb alpha for now bc based on chosen g)</span></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>weight_history_3CPT, cost_history_3CPT <span class="op">=</span> gradient_descent(</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>    multiclass_perceptron, <span class="fl">.1</span>, max_its, w)</span></code></pre></div>
<div class="sourceCode" id="cb36"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co">### plot cost history</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="co">## store data</span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>x_plt <span class="op">=</span> np.arange(np.shape(weight_history_3CPT)[<span class="dv">0</span>])</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>y_cost_3CPT <span class="op">=</span> cost_history_3CPT</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a><span class="co">## plot</span></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_cost_history(x, y):</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># use seaborn style</span></span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a>    sns.set_theme()</span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># setup plot</span></span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">1</span>, figsize <span class="op">=</span> np.array([<span class="dv">5</span>, <span class="dv">5</span>]),</span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a>                            constrained_layout <span class="op">=</span> <span class="va">True</span>) <span class="co"># overall layout, size</span></span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> plt.subplot(<span class="dv">111</span>, frameon <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb36-20"><a href="#cb36-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-21"><a href="#cb36-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># set axis tick sizes</span></span>
<span id="cb36-22"><a href="#cb36-22" aria-hidden="true" tabindex="-1"></a>    ax.xaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb36-23"><a href="#cb36-23" aria-hidden="true" tabindex="-1"></a>    ax.yaxis.set_tick_params(labelsize <span class="op">=</span> font_size <span class="op">-</span> <span class="dv">4</span>)</span>
<span id="cb36-24"><a href="#cb36-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-25"><a href="#cb36-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># plot cost history</span></span>
<span id="cb36-26"><a href="#cb36-26" aria-hidden="true" tabindex="-1"></a>    y_cost_3CPT <span class="op">=</span> ax.plot(x, y, color <span class="op">=</span> plt_colours[<span class="dv">0</span>],</span>
<span id="cb36-27"><a href="#cb36-27" aria-hidden="true" tabindex="-1"></a>                        linestyle <span class="op">=</span> <span class="st">&#39;-&#39;</span>, linewidth <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb36-28"><a href="#cb36-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-29"><a href="#cb36-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># add labels</span></span>
<span id="cb36-30"><a href="#cb36-30" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="st">&#39;iteration&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb36-31"><a href="#cb36-31" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">&#39;cost&#39;</span>, fontsize <span class="op">=</span> font_size)</span>
<span id="cb36-32"><a href="#cb36-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-33"><a href="#cb36-33" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb36-34"><a href="#cb36-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-35"><a href="#cb36-35" aria-hidden="true" tabindex="-1"></a>plot_cost_history(x_plt, y_cost_3CPT)</span></code></pre></div>
<div class="sourceCode" id="cb37"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>weight_history_3CPT[<span class="dv">1</span>]</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>model(x, w)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>np.shape(model(x, w))</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>all_evals <span class="op">=</span> model(x, weight_history_3CPT[<span class="dv">1</span>])</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>np.shape(all_evals)</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>np.shape(np.<span class="bu">max</span>(all_evals, axis <span class="op">=</span> <span class="dv">0</span>))</span></code></pre></div>
<div class="sourceCode" id="cb38"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co">### define new function to compute multi-class misclassification history</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> miscount_3CPT(w, x, y):</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 0-2 based on weight that maximizes prediction</span></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># y_pred = np.argmax(np.abs(model(x, w), axis = 0), axis = 0)</span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># compute prediction for all points</span></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>    all_evals <span class="op">=</span> model(x, w)</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># assign point class of DB that maximumizes distance to DB</span></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> np.argmax(all_evals, axis <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># pairwise compare vectors: 1 if model class pred == true class; sum</span></span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>    miscount_curr <span class="op">=</span> np.<span class="bu">sum</span>(y_pred <span class="op">!=</span> y)</span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> miscount_curr</span></code></pre></div>
<div class="sourceCode" id="cb39"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co">### compute accuracy for optimal weight (minimum misclassifications)</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="co"># compute misclassifications</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>miscount_history_3CPT <span class="op">=</span> [miscount_3CPT(v, x, y) <span class="cf">for</span> v <span class="kw">in</span> weight_history_3CPT]</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="co"># find minimum misclassifications and convert to accuracy</span></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>min_misclass_3CPT <span class="op">=</span> <span class="bu">min</span>(miscount_history_3CPT)</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;multi-class perceptron minimum misclassifications: &quot;</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>      <span class="op">+</span> <span class="bu">str</span>(min_misclass_3CPT))</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a><span class="co"># convert to accuracies</span></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>accuracy_3CPT <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> (min_misclass_3CPT)<span class="op">/</span>np.shape(x)[<span class="dv">1</span>]</span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;multi-class perceptron accuracy: &quot;</span> <span class="op">+</span> <span class="bu">str</span>(accuracy_3CPT))</span></code></pre></div>
</div>
<div id="plotting-the-decision-boundary" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Plotting the decision boundary</h2>
<p>Below we plot the data in the plane, along with the decision boundary obtained by the multi-class perceptron.</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># code to clone library from git repo subdirectory</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="co"># (from Ciro Santilli @ https://stackoverflow.com/questions/600079/how-do-i-clone-a-subdirectory-only-of-a-git-repository)</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="co"># git clone \</span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="co">#     --depth 1  \</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a><span class="co">#     --filter=blob:none  \</span></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a><span class="co">#     --sparse \</span></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a><span class="co">#     https://github.com/jermwatt/machine_learning_refined \</span></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a><span class="co"># ;</span></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a><span class="co"># cd machine_learning_refined</span></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a><span class="co"># git sparse-checkout set mlrefined_libraries</span></span></code></pre></div>
<div class="sourceCode" id="cb41"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co">### plot data and decision boundary</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="co"># import relevant MLR plotting libraries (store lib in current dir)</span></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mlrefined_libraries <span class="im">import</span> superlearn_library <span class="im">as</span> superlearn</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mlrefined_libraries <span class="im">import</span> math_optimization_library <span class="im">as</span> optlib</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>optimizers      <span class="op">=</span> optlib.optimizers</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>classif_plotter <span class="op">=</span> superlearn.multi_lin_classification_demo</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>cost_lib        <span class="op">=</span> superlearn.cost_functions</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>normalizers     <span class="op">=</span> superlearn.normalizers</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a><span class="co"># store std. normalized dataset to pass to function (colours = class labels)</span></span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>data_norm <span class="op">=</span> np.append(x, y, axis <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>data_norm[<span class="op">-</span><span class="dv">1</span>,<span class="dv">0</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a><span class="co"># plot individual data points in plane</span></span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a>demo <span class="op">=</span> superlearn.multiclass_illustrator.Visualizer(data_norm)</span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a>demo.show_dataset()</span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a><span class="co"># add DBs (pass weights defining 3 class DBs that give perfect accuracy)</span></span>
<span id="cb41-20"><a href="#cb41-20" aria-hidden="true" tabindex="-1"></a>demo.show_complete_coloring([weight_history_3CPT[<span class="op">-</span><span class="dv">1</span>]], cost <span class="op">=</span> </span>
<span id="cb41-21"><a href="#cb41-21" aria-hidden="true" tabindex="-1"></a>                            multiclass_perceptron)</span></code></pre></div>
<p>The multi-class perceptron achieves a classification accuracy of 100%, yielding results that are comparable to those shown in <em>Machine Learning Refined</em>.</p>
<div style="page-break-after: always;"></div>
</div>
</div>
<div id="references" class="section level1" number="5">
<h1><span class="header-section-number">5</span> References</h1>
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>Wolberg, W. H., Street, W. N., &amp; Mangasarian, O. L. (1992). Breast Cancer Dataset. <em>University of Wisconsin Hospitals, Madison</em>.<a href="#fnref1" class="footnote-back"></a></p></li>
<li id="fn2"><p>Dua, D. and Graff, C. (2019). UCI Machine Learning Repository <a href="http://archive.ics.uci.edu/ml%5D.">[http://archive.ics.uci.edu/ml].</a> Irvine, CA: University of California, School of Information and Computer Science.<br />
<a href="#fnref2" class="footnote-back"></a></p></li>
<li id="fn3"><p>Watt, J., Borhani, R., &amp; Katsaggelos, A. K. (2020). Machine learning refined: Foundations, algorithms, and applications. Cambridge University Press.<a href="#fnref3" class="footnote-back"></a></p></li>
<li id="fn4"><p><a href="https://github.com/jermwatt/machine_learning_refined/tree/gh-pages/notes/7_Linear_multiclass_classification" class="uri">https://github.com/jermwatt/machine_learning_refined/tree/gh-pages/notes/7_Linear_multiclass_classification</a><a href="#fnref4" class="footnote-back"></a></p></li>
</ol>
</div>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
